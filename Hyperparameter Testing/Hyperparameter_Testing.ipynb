{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##### Testing and Finding the most appropriate hyperparameters for bodyfat.csv"
      ],
      "metadata": {
        "id": "zfXhw7MGr6WI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEL-0ZfE9zIg",
        "outputId": "dec47d7c-4dd1-4ad8-91e7-1de7a1b8e56b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version: 2.8.2\n",
            "Keras version: 2.8.0\n"
          ]
        }
      ],
      "source": [
        "#importing necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "print(f\"Tensorflow version: {tf.__version__}\")\n",
        "print(f\"Keras version: {tf.keras.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndyqT43191jx"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ba2GMC31920A",
        "outputId": "7ca0a377-7d19-4c9a-8732-bd4e5e0f30e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Density  BodyFat  Age  Weight  Height  Neck  Chest  Abdomen    Hip  Thigh  \\\n",
              "0   1.0708     12.3   23  154.25   67.75  36.2   93.1     85.2   94.5   59.0   \n",
              "1   1.0853      6.1   22  173.25   72.25  38.5   93.6     83.0   98.7   58.7   \n",
              "2   1.0414     25.3   22  154.00   66.25  34.0   95.8     87.9   99.2   59.6   \n",
              "3   1.0751     10.4   26  184.75   72.25  37.4  101.8     86.4  101.2   60.1   \n",
              "4   1.0340     28.7   24  184.25   71.25  34.4   97.3    100.0  101.9   63.2   \n",
              "\n",
              "   Knee  Ankle  Biceps  Forearm  Wrist  \n",
              "0  37.3   21.9    32.0     27.4   17.1  \n",
              "1  37.3   23.4    30.5     28.9   18.2  \n",
              "2  38.9   24.0    28.8     25.2   16.6  \n",
              "3  37.3   22.8    32.4     29.4   18.2  \n",
              "4  42.2   24.0    32.2     27.7   17.7  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ecd98952-ecb9-4798-a60b-e758c9e7114d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Density</th>\n",
              "      <th>BodyFat</th>\n",
              "      <th>Age</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Height</th>\n",
              "      <th>Neck</th>\n",
              "      <th>Chest</th>\n",
              "      <th>Abdomen</th>\n",
              "      <th>Hip</th>\n",
              "      <th>Thigh</th>\n",
              "      <th>Knee</th>\n",
              "      <th>Ankle</th>\n",
              "      <th>Biceps</th>\n",
              "      <th>Forearm</th>\n",
              "      <th>Wrist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0708</td>\n",
              "      <td>12.3</td>\n",
              "      <td>23</td>\n",
              "      <td>154.25</td>\n",
              "      <td>67.75</td>\n",
              "      <td>36.2</td>\n",
              "      <td>93.1</td>\n",
              "      <td>85.2</td>\n",
              "      <td>94.5</td>\n",
              "      <td>59.0</td>\n",
              "      <td>37.3</td>\n",
              "      <td>21.9</td>\n",
              "      <td>32.0</td>\n",
              "      <td>27.4</td>\n",
              "      <td>17.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0853</td>\n",
              "      <td>6.1</td>\n",
              "      <td>22</td>\n",
              "      <td>173.25</td>\n",
              "      <td>72.25</td>\n",
              "      <td>38.5</td>\n",
              "      <td>93.6</td>\n",
              "      <td>83.0</td>\n",
              "      <td>98.7</td>\n",
              "      <td>58.7</td>\n",
              "      <td>37.3</td>\n",
              "      <td>23.4</td>\n",
              "      <td>30.5</td>\n",
              "      <td>28.9</td>\n",
              "      <td>18.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0414</td>\n",
              "      <td>25.3</td>\n",
              "      <td>22</td>\n",
              "      <td>154.00</td>\n",
              "      <td>66.25</td>\n",
              "      <td>34.0</td>\n",
              "      <td>95.8</td>\n",
              "      <td>87.9</td>\n",
              "      <td>99.2</td>\n",
              "      <td>59.6</td>\n",
              "      <td>38.9</td>\n",
              "      <td>24.0</td>\n",
              "      <td>28.8</td>\n",
              "      <td>25.2</td>\n",
              "      <td>16.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0751</td>\n",
              "      <td>10.4</td>\n",
              "      <td>26</td>\n",
              "      <td>184.75</td>\n",
              "      <td>72.25</td>\n",
              "      <td>37.4</td>\n",
              "      <td>101.8</td>\n",
              "      <td>86.4</td>\n",
              "      <td>101.2</td>\n",
              "      <td>60.1</td>\n",
              "      <td>37.3</td>\n",
              "      <td>22.8</td>\n",
              "      <td>32.4</td>\n",
              "      <td>29.4</td>\n",
              "      <td>18.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0340</td>\n",
              "      <td>28.7</td>\n",
              "      <td>24</td>\n",
              "      <td>184.25</td>\n",
              "      <td>71.25</td>\n",
              "      <td>34.4</td>\n",
              "      <td>97.3</td>\n",
              "      <td>100.0</td>\n",
              "      <td>101.9</td>\n",
              "      <td>63.2</td>\n",
              "      <td>42.2</td>\n",
              "      <td>24.0</td>\n",
              "      <td>32.2</td>\n",
              "      <td>27.7</td>\n",
              "      <td>17.7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ecd98952-ecb9-4798-a60b-e758c9e7114d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ecd98952-ecb9-4798-a60b-e758c9e7114d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ecd98952-ecb9-4798-a60b-e758c9e7114d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df = pd.read_csv(\"bodyfat.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pz3mor2B94Bo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ade853c-8317-4eae-89e4-4ec0cce381cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 252 entries, 0 to 251\n",
            "Data columns (total 15 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   Density  252 non-null    float64\n",
            " 1   BodyFat  252 non-null    float64\n",
            " 2   Age      252 non-null    int64  \n",
            " 3   Weight   252 non-null    float64\n",
            " 4   Height   252 non-null    float64\n",
            " 5   Neck     252 non-null    float64\n",
            " 6   Chest    252 non-null    float64\n",
            " 7   Abdomen  252 non-null    float64\n",
            " 8   Hip      252 non-null    float64\n",
            " 9   Thigh    252 non-null    float64\n",
            " 10  Knee     252 non-null    float64\n",
            " 11  Ankle    252 non-null    float64\n",
            " 12  Biceps   252 non-null    float64\n",
            " 13  Forearm  252 non-null    float64\n",
            " 14  Wrist    252 non-null    float64\n",
            "dtypes: float64(14), int64(1)\n",
            "memory usage: 29.7 KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xTOjpUt95pw"
      },
      "outputs": [],
      "source": [
        "columns = df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4lL-ofr9_hn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "103fc094-3ab4-438b-e1f1-ee1aab68d4af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(252, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yC-_MGwu-Aq4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "outputId": "2df8e5fe-83cb-4848-f8bb-8d093ed35745"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Density     BodyFat         Age      Weight      Height        Neck  \\\n",
              "count  252.000000  252.000000  252.000000  252.000000  252.000000  252.000000   \n",
              "mean     1.055574   19.150794   44.884921  178.924405   70.148810   37.992063   \n",
              "std      0.019031    8.368740   12.602040   29.389160    3.662856    2.430913   \n",
              "min      0.995000    0.000000   22.000000  118.500000   29.500000   31.100000   \n",
              "25%      1.041400   12.475000   35.750000  159.000000   68.250000   36.400000   \n",
              "50%      1.054900   19.200000   43.000000  176.500000   70.000000   38.000000   \n",
              "75%      1.070400   25.300000   54.000000  197.000000   72.250000   39.425000   \n",
              "max      1.108900   47.500000   81.000000  363.150000   77.750000   51.200000   \n",
              "\n",
              "            Chest     Abdomen         Hip       Thigh        Knee       Ankle  \\\n",
              "count  252.000000  252.000000  252.000000  252.000000  252.000000  252.000000   \n",
              "mean   100.824206   92.555952   99.904762   59.405952   38.590476   23.102381   \n",
              "std      8.430476   10.783077    7.164058    5.249952    2.411805    1.694893   \n",
              "min     79.300000   69.400000   85.000000   47.200000   33.000000   19.100000   \n",
              "25%     94.350000   84.575000   95.500000   56.000000   36.975000   22.000000   \n",
              "50%     99.650000   90.950000   99.300000   59.000000   38.500000   22.800000   \n",
              "75%    105.375000   99.325000  103.525000   62.350000   39.925000   24.000000   \n",
              "max    136.200000  148.100000  147.700000   87.300000   49.100000   33.900000   \n",
              "\n",
              "           Biceps     Forearm       Wrist  \n",
              "count  252.000000  252.000000  252.000000  \n",
              "mean    32.273413   28.663889   18.229762  \n",
              "std      3.021274    2.020691    0.933585  \n",
              "min     24.800000   21.000000   15.800000  \n",
              "25%     30.200000   27.300000   17.600000  \n",
              "50%     32.050000   28.700000   18.300000  \n",
              "75%     34.325000   30.000000   18.800000  \n",
              "max     45.000000   34.900000   21.400000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1ae3a225-1d65-4866-84a1-4bb618077fc6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Density</th>\n",
              "      <th>BodyFat</th>\n",
              "      <th>Age</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Height</th>\n",
              "      <th>Neck</th>\n",
              "      <th>Chest</th>\n",
              "      <th>Abdomen</th>\n",
              "      <th>Hip</th>\n",
              "      <th>Thigh</th>\n",
              "      <th>Knee</th>\n",
              "      <th>Ankle</th>\n",
              "      <th>Biceps</th>\n",
              "      <th>Forearm</th>\n",
              "      <th>Wrist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>252.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>252.000000</td>\n",
              "      <td>252.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1.055574</td>\n",
              "      <td>19.150794</td>\n",
              "      <td>44.884921</td>\n",
              "      <td>178.924405</td>\n",
              "      <td>70.148810</td>\n",
              "      <td>37.992063</td>\n",
              "      <td>100.824206</td>\n",
              "      <td>92.555952</td>\n",
              "      <td>99.904762</td>\n",
              "      <td>59.405952</td>\n",
              "      <td>38.590476</td>\n",
              "      <td>23.102381</td>\n",
              "      <td>32.273413</td>\n",
              "      <td>28.663889</td>\n",
              "      <td>18.229762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.019031</td>\n",
              "      <td>8.368740</td>\n",
              "      <td>12.602040</td>\n",
              "      <td>29.389160</td>\n",
              "      <td>3.662856</td>\n",
              "      <td>2.430913</td>\n",
              "      <td>8.430476</td>\n",
              "      <td>10.783077</td>\n",
              "      <td>7.164058</td>\n",
              "      <td>5.249952</td>\n",
              "      <td>2.411805</td>\n",
              "      <td>1.694893</td>\n",
              "      <td>3.021274</td>\n",
              "      <td>2.020691</td>\n",
              "      <td>0.933585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.995000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>118.500000</td>\n",
              "      <td>29.500000</td>\n",
              "      <td>31.100000</td>\n",
              "      <td>79.300000</td>\n",
              "      <td>69.400000</td>\n",
              "      <td>85.000000</td>\n",
              "      <td>47.200000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>19.100000</td>\n",
              "      <td>24.800000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>15.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>1.041400</td>\n",
              "      <td>12.475000</td>\n",
              "      <td>35.750000</td>\n",
              "      <td>159.000000</td>\n",
              "      <td>68.250000</td>\n",
              "      <td>36.400000</td>\n",
              "      <td>94.350000</td>\n",
              "      <td>84.575000</td>\n",
              "      <td>95.500000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>36.975000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>30.200000</td>\n",
              "      <td>27.300000</td>\n",
              "      <td>17.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1.054900</td>\n",
              "      <td>19.200000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>176.500000</td>\n",
              "      <td>70.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>99.650000</td>\n",
              "      <td>90.950000</td>\n",
              "      <td>99.300000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>38.500000</td>\n",
              "      <td>22.800000</td>\n",
              "      <td>32.050000</td>\n",
              "      <td>28.700000</td>\n",
              "      <td>18.300000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.070400</td>\n",
              "      <td>25.300000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>197.000000</td>\n",
              "      <td>72.250000</td>\n",
              "      <td>39.425000</td>\n",
              "      <td>105.375000</td>\n",
              "      <td>99.325000</td>\n",
              "      <td>103.525000</td>\n",
              "      <td>62.350000</td>\n",
              "      <td>39.925000</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>34.325000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>18.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.108900</td>\n",
              "      <td>47.500000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>363.150000</td>\n",
              "      <td>77.750000</td>\n",
              "      <td>51.200000</td>\n",
              "      <td>136.200000</td>\n",
              "      <td>148.100000</td>\n",
              "      <td>147.700000</td>\n",
              "      <td>87.300000</td>\n",
              "      <td>49.100000</td>\n",
              "      <td>33.900000</td>\n",
              "      <td>45.000000</td>\n",
              "      <td>34.900000</td>\n",
              "      <td>21.400000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1ae3a225-1d65-4866-84a1-4bb618077fc6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1ae3a225-1d65-4866-84a1-4bb618077fc6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1ae3a225-1d65-4866-84a1-4bb618077fc6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAO6GbuH-CKw"
      },
      "outputs": [],
      "source": [
        "#scaling the dataset \n",
        "scale = MinMaxScaler()\n",
        "scalled = scale.fit_transform(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_OurKMf-DgY"
      },
      "outputs": [],
      "source": [
        "i = 0\n",
        "for col in columns:\n",
        "    df[col] = scalled[:,i]\n",
        "    i += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A073y6g9-E64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "89eeacd5-96ef-4c1f-f461-d03eb8352bd1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Density   BodyFat       Age    Weight    Height      Neck     Chest  \\\n",
              "0  0.665496  0.258947  0.016949  0.146127  0.792746  0.253731  0.242531   \n",
              "1  0.792801  0.128421  0.000000  0.223789  0.886010  0.368159  0.251318   \n",
              "2  0.407375  0.532632  0.000000  0.145105  0.761658  0.144279  0.289982   \n",
              "3  0.703248  0.218947  0.067797  0.270795  0.886010  0.313433  0.395431   \n",
              "4  0.342406  0.604211  0.033898  0.268751  0.865285  0.164179  0.316344   \n",
              "\n",
              "    Abdomen       Hip     Thigh      Knee     Ankle    Biceps   Forearm  \\\n",
              "0  0.200762  0.151515  0.294264  0.267081  0.189189  0.356436  0.460432   \n",
              "1  0.172808  0.218501  0.286783  0.267081  0.290541  0.282178  0.568345   \n",
              "2  0.235070  0.226475  0.309227  0.366460  0.331081  0.198020  0.302158   \n",
              "3  0.216010  0.258373  0.321696  0.267081  0.250000  0.376238  0.604317   \n",
              "4  0.388818  0.269537  0.399002  0.571429  0.331081  0.366337  0.482014   \n",
              "\n",
              "      Wrist  \n",
              "0  0.232143  \n",
              "1  0.428571  \n",
              "2  0.142857  \n",
              "3  0.428571  \n",
              "4  0.339286  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1e3a9892-5a85-40a1-b9ee-bb7797251d24\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Density</th>\n",
              "      <th>BodyFat</th>\n",
              "      <th>Age</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Height</th>\n",
              "      <th>Neck</th>\n",
              "      <th>Chest</th>\n",
              "      <th>Abdomen</th>\n",
              "      <th>Hip</th>\n",
              "      <th>Thigh</th>\n",
              "      <th>Knee</th>\n",
              "      <th>Ankle</th>\n",
              "      <th>Biceps</th>\n",
              "      <th>Forearm</th>\n",
              "      <th>Wrist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.665496</td>\n",
              "      <td>0.258947</td>\n",
              "      <td>0.016949</td>\n",
              "      <td>0.146127</td>\n",
              "      <td>0.792746</td>\n",
              "      <td>0.253731</td>\n",
              "      <td>0.242531</td>\n",
              "      <td>0.200762</td>\n",
              "      <td>0.151515</td>\n",
              "      <td>0.294264</td>\n",
              "      <td>0.267081</td>\n",
              "      <td>0.189189</td>\n",
              "      <td>0.356436</td>\n",
              "      <td>0.460432</td>\n",
              "      <td>0.232143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.792801</td>\n",
              "      <td>0.128421</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.223789</td>\n",
              "      <td>0.886010</td>\n",
              "      <td>0.368159</td>\n",
              "      <td>0.251318</td>\n",
              "      <td>0.172808</td>\n",
              "      <td>0.218501</td>\n",
              "      <td>0.286783</td>\n",
              "      <td>0.267081</td>\n",
              "      <td>0.290541</td>\n",
              "      <td>0.282178</td>\n",
              "      <td>0.568345</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.407375</td>\n",
              "      <td>0.532632</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.145105</td>\n",
              "      <td>0.761658</td>\n",
              "      <td>0.144279</td>\n",
              "      <td>0.289982</td>\n",
              "      <td>0.235070</td>\n",
              "      <td>0.226475</td>\n",
              "      <td>0.309227</td>\n",
              "      <td>0.366460</td>\n",
              "      <td>0.331081</td>\n",
              "      <td>0.198020</td>\n",
              "      <td>0.302158</td>\n",
              "      <td>0.142857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.703248</td>\n",
              "      <td>0.218947</td>\n",
              "      <td>0.067797</td>\n",
              "      <td>0.270795</td>\n",
              "      <td>0.886010</td>\n",
              "      <td>0.313433</td>\n",
              "      <td>0.395431</td>\n",
              "      <td>0.216010</td>\n",
              "      <td>0.258373</td>\n",
              "      <td>0.321696</td>\n",
              "      <td>0.267081</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.376238</td>\n",
              "      <td>0.604317</td>\n",
              "      <td>0.428571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.342406</td>\n",
              "      <td>0.604211</td>\n",
              "      <td>0.033898</td>\n",
              "      <td>0.268751</td>\n",
              "      <td>0.865285</td>\n",
              "      <td>0.164179</td>\n",
              "      <td>0.316344</td>\n",
              "      <td>0.388818</td>\n",
              "      <td>0.269537</td>\n",
              "      <td>0.399002</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.331081</td>\n",
              "      <td>0.366337</td>\n",
              "      <td>0.482014</td>\n",
              "      <td>0.339286</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e3a9892-5a85-40a1-b9ee-bb7797251d24')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1e3a9892-5a85-40a1-b9ee-bb7797251d24 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1e3a9892-5a85-40a1-b9ee-bb7797251d24');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_C3-V1D-Gag"
      },
      "outputs": [],
      "source": [
        "epochs = [10,20,30,40]\n",
        "lr = [1, 0.3, 0.1, 0.01,0.03,0.001,0.0001,0.00001]\n",
        "reg = ['l1','l2','None']\n",
        "act = ['sigmoid','relu']\n",
        "layers = [1,2,3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BG9Aw9jA-H9I"
      },
      "outputs": [],
      "source": [
        "y = df['BodyFat']\n",
        "x = df.drop('BodyFat', axis = 1)\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#defining global variables\n",
        "result_list = []\n",
        "parameter_list = []\n",
        "k = 0"
      ],
      "metadata": {
        "id": "825UhnTIHuYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48-x3w98-vQB"
      },
      "outputs": [],
      "source": [
        "def model_layer1(epochs,lr,act,reg):#reg\n",
        "  if(reg == 'l1'):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.InputLayer(input_shape=14, name='inputLayer'))\n",
        "    model.add(tf.keras.layers.Dense(128,activation=act,kernel_regularizer=tf.keras.regularizers.L1(0.01), name='hiddenLayer-1'))\n",
        "    model.add(tf.keras.layers.Dense(1,name='outputLayer'))\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    model.compile(loss = \"mse\", optimizer = opt, metrics = [tf.keras.metrics.RootMeanSquaredError()])\n",
        "    history = model.fit(x_train,y_train,epochs=epochs,validation_split=0.15)\n",
        "    result_list.append(model.evaluate(x_test, y_test))\n",
        "    print('MODEL EVALUATION: ', model.evaluate(x_test, y_test))\n",
        "  elif(reg == 'l2'):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.InputLayer(input_shape=14, name='inputLayer'))\n",
        "    model.add(tf.keras.layers.Dense(128,activation=act,kernel_regularizer=tf.keras.regularizers.L2(0.01), name='hiddenLayer-1'))\n",
        "    model.add(tf.keras.layers.Dense(1,name='outputLayer'))\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    model.compile(loss = \"mse\", optimizer = opt, metrics = [tf.keras.metrics.RootMeanSquaredError()])\n",
        "    history = model.fit(x_train,y_train,epochs=epochs,validation_split=0.15)\n",
        "    result_list.append(model.evaluate(x_test, y_test))\n",
        "    print('MODEL EVALUATION: ', model.evaluate(x_test, y_test))\n",
        "  elif(reg == 'None'):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.InputLayer(input_shape=14, name='inputLayer'))\n",
        "    model.add(tf.keras.layers.Dense(128,activation=act, name='hiddenLayer-1'))\n",
        "    model.add(tf.keras.layers.Dense(1,name='outputLayer'))\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    model.compile(loss = \"mse\", optimizer = opt, metrics = [tf.keras.metrics.RootMeanSquaredError()])\n",
        "    history = model.fit(x_train,y_train,epochs=epochs,validation_split=0.15)\n",
        "    result_list.append(model.evaluate(x_test, y_test))\n",
        "    print('MODEL EVALUATION: ', model.evaluate(x_test, y_test))\n",
        "  #acc = history.history['root_mean_squared_error']\n",
        "  #print(acc)\n",
        "  #k = k+1\n",
        "  #result_dict.update({result_dict[k]:acc})\n",
        "      \n",
        "  #sns.set_style(\"darkgrid\")\n",
        "  ##get the details form the history object\n",
        "  #acc = history.history['root_mean_squared_error']\n",
        "  #val_acc = history.history['val_root_mean_squared_error']\n",
        "  #loss = history.history['loss']\n",
        "  #val_loss = history.history['val_loss']\n",
        "  #epochs = range(1, len(acc) + 1)\n",
        "  #plt.figure()\n",
        "  ##Train and validation loss\n",
        "  #plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "  #plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "  #plt.xlabel('Epoch #')\n",
        "  #plt.ylabel('loss')\n",
        "  #plt.title('Training and Validation loss')\n",
        "  #plt.legend()\n",
        "  #plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CgTFmvnECjj-"
      },
      "outputs": [],
      "source": [
        "def model_layer2(epochs,lr,act,reg):#reg,\n",
        "  if(reg == 'l1'):\n",
        "    model1 = tf.keras.Sequential()\n",
        "    model1.add(tf.keras.layers.InputLayer(input_shape=14, name='inputLayer'))\n",
        "    model1.add(tf.keras.layers.Dense(128,activation=act,kernel_regularizer=tf.keras.regularizers.L1(0.01), name='hiddenLayer-1'))\n",
        "    model1.add(tf.keras.layers.Dense(64,activation=act,kernel_regularizer=tf.keras.regularizers.L1(0.01), name='hiddenLayer-2'))\n",
        "    model1.add(tf.keras.layers.Dense(1,name='outputLayer'))\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    model1.compile(loss = \"mse\", optimizer = opt, metrics = [tf.keras.metrics.RootMeanSquaredError()])\n",
        "    history = model1.fit(x_train,y_train,epochs=epochs,validation_split=0.15)\n",
        "    result_list.append(model1.evaluate(x_test, y_test))\n",
        "    print('MODEL EVALUATION: ', model1.evaluate(x_test, y_test))\n",
        "  elif(reg == 'l2'):\n",
        "    model1 = tf.keras.Sequential()\n",
        "    model1.add(tf.keras.layers.InputLayer(input_shape=14, name='inputLayer'))\n",
        "    model1.add(tf.keras.layers.Dense(128,activation=act,kernel_regularizer=tf.keras.regularizers.L2(0.01), name='hiddenLayer-1'))\n",
        "    model1.add(tf.keras.layers.Dense(64,activation=act,kernel_regularizer=tf.keras.regularizers.L2(0.01), name='hiddenLayer-2'))\n",
        "    model1.add(tf.keras.layers.Dense(1,name='outputLayer'))\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    model1.compile(loss = \"mse\", optimizer = opt, metrics = [tf.keras.metrics.RootMeanSquaredError()])\n",
        "    history = model1.fit(x_train,y_train,epochs=epochs,validation_split=0.15)\n",
        "    result_list.append(model1.evaluate(x_test, y_test))\n",
        "    print('MODEL EVALUATION: ', model1.evaluate(x_test, y_test))\n",
        "  elif(reg == 'None'):\n",
        "    model1 = tf.keras.Sequential()\n",
        "    model1.add(tf.keras.layers.InputLayer(input_shape=14, name='inputLayer'))\n",
        "    model1.add(tf.keras.layers.Dense(128,activation=act, name='hiddenLayer-1'))\n",
        "    model1.add(tf.keras.layers.Dense(64,activation=act, name='hiddenLayer-2'))\n",
        "    model1.add(tf.keras.layers.Dense(1,name='outputLayer'))\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    model1.compile(loss = \"mse\", optimizer = opt, metrics = [tf.keras.metrics.RootMeanSquaredError()])\n",
        "    history = model1.fit(x_train,y_train,epochs=epochs,validation_split=0.15)\n",
        "    result_list.append(model1.evaluate(x_test, y_test))\n",
        "    print('MODEL EVALUATION: ', model1.evaluate(x_test, y_test))\n",
        "\n",
        "  #print the models    \n",
        "  #sns.set_style(\"darkgrid\")\n",
        "  #get the details form the history object\n",
        "  #acc = history.history['root_mean_squared_error']\n",
        "  #val_acc = history.history['val_root_mean_squared_error']\n",
        "  #loss = history.history['loss']\n",
        "  #val_loss = history.history['val_loss']\n",
        "  #epochs = range(1, len(acc) + 1)\n",
        "  #plt.figure()\n",
        "  ##Train and validation loss\n",
        "  #plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "  #plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "  #plt.xlabel('Epoch #')\n",
        "  #plt.ylabel('loss')\n",
        "  #plt.title('Training and Validation loss')\n",
        "  #plt.legend()\n",
        "  #plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_layer3(epochs,lr,act,reg):#reg,\n",
        "  if(reg == 'l1'):\n",
        "    model2 = tf.keras.Sequential()\n",
        "    model2.add(tf.keras.layers.InputLayer(input_shape=14, name='inputLayer'))\n",
        "    model2.add(tf.keras.layers.Dense(128,activation=act,kernel_regularizer=tf.keras.regularizers.L1(0.01), name='hiddenLayer-1'))\n",
        "    model2.add(tf.keras.layers.Dense(64,activation=act,kernel_regularizer=tf.keras.regularizers.L1(0.01), name='hiddenLayer-2'))\n",
        "    model2.add(tf.keras.layers.Dense(32,activation =act,kernel_regularizer=tf.keras.regularizers.L1(0.01), name='hiddenLayer-3'))\n",
        "    model2.add(tf.keras.layers.Dense(1,name='outputLayer'))\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    model2.compile(loss = \"mse\", optimizer = opt, metrics = [tf.keras.metrics.RootMeanSquaredError()])\n",
        "    history = model2.fit(x_train,y_train,epochs=epochs,validation_split=0.15)\n",
        "    result_list.append(model2.evaluate(x_test, y_test))\n",
        "    print('MODEL EVALUATION: ', model2.evaluate(x_test, y_test))\n",
        "  elif(reg == 'l2'):\n",
        "    model2 = tf.keras.Sequential()\n",
        "    model2.add(tf.keras.layers.InputLayer(input_shape=14,name='inputLayer'))\n",
        "    model2.add(tf.keras.layers.Dense(128,activation=act,kernel_regularizer=tf.keras.regularizers.L2(0.01), name='hiddenLayer-1'))\n",
        "    model2.add(tf.keras.layers.Dense(64,activation=act,kernel_regularizer=tf.keras.regularizers.L2(0.01), name='hiddenLayer-2'))\n",
        "    model2.add(tf.keras.layers.Dense(32,activation =act,kernel_regularizer=tf.keras.regularizers.L2(0.01), name='hiddenLayer-3'))\n",
        "    model2.add(tf.keras.layers.Dense(1,name='outputLayer'))\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    model2.compile(loss = \"mse\", optimizer = opt, metrics = [tf.keras.metrics.RootMeanSquaredError()])\n",
        "    history = model2.fit(x_train,y_train,epochs=epochs,validation_split=0.15)\n",
        "    result_list.append(model2.evaluate(x_test, y_test))\n",
        "    print('MODEL EVALUATION: ', model2.evaluate(x_test, y_test))\n",
        "  elif(reg == 'None'):\n",
        "    model2 = tf.keras.Sequential()\n",
        "    model2.add(tf.keras.layers.InputLayer(input_shape=14, name='inputLayer'))\n",
        "    model2.add(tf.keras.layers.Dense(128,activation=act, name='hiddenLayer-1'))\n",
        "    model2.add(tf.keras.layers.Dense(64,activation=act, name='hiddenLayer-2'))\n",
        "    model2.add(tf.keras.layers.Dense(32,activation =act, name='hiddenLayer-3'))\n",
        "    model2.add(tf.keras.layers.Dense(1,name='outputLayer'))\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    model2.compile(loss = \"mse\", optimizer = opt, metrics = [tf.keras.metrics.RootMeanSquaredError()])\n",
        "    history = model2.fit(x_train,y_train,epochs=epochs,validation_split=0.15)\n",
        "    result_list.append(model2.evaluate(x_test, y_test))\n",
        "    print('MODEL EVALUATION: ', model2.evaluate(x_test, y_test))\n",
        "\n",
        "  ##print the models    \n",
        "  #sns.set_style(\"darkgrid\")\n",
        "  ##get the details form the history object\n",
        "  #acc = history.history['root_mean_squared_error']\n",
        "  #val_acc = history.history['val_root_mean_squared_error']\n",
        "  #loss = history.history['loss']\n",
        "  #val_loss = history.history['val_loss']\n",
        "  #epochs = range(1, len(acc) + 1)\n",
        "  #plt.figure()\n",
        "  ##Train and validation loss\n",
        "  #plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "  #plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "  #plt.xlabel('Epoch #')\n",
        "  #plt.ylabel('loss')\n",
        "  #plt.title('Training and Validation loss')\n",
        "  #plt.legend()\n",
        "  #plt.show()"
      ],
      "metadata": {
        "id": "OUpSmvGIbylL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 0\n",
        "for l in layers:\n",
        "  for i in epochs:\n",
        "    for j in lr:\n",
        "      for c in act:\n",
        "        for r in reg:\n",
        "          k = k + 1\n",
        "          if (l == 1):\n",
        "            model_layer1(i,j, c,r)\n",
        "            print(\"Model number: \",k)\n",
        "            parameter_list.append(\"Hidden Layes: 1 \"+\"Number of epochs: \"+ str(i) + \" learning rate: \"+ str(j) + \" Activation Function: \" + c+ \"Regularizer: \"+ str(r))\n",
        "            print(\"Number of epochs: \"+ str(i) + \" learning rate: \"+ str(j) + \" Activation Function: \" + c)  \n",
        "          elif (l == 2):\n",
        "            model_layer2(i,j, c,r)\n",
        "            #k = k + 1\n",
        "            print(\"Model number: \",k)\n",
        "            parameter_list.append(\"Hidden Layers: 2 \"+\"Number of epochs: \"+ str(i) + \" learning rate: \"+ str(j) + \" Activation Function: \" + c+\" Regulizer: \"+ str(r))\n",
        "            print(\"Number of epochs: \"+ str(i) + \" learning rate: \"+ str(j)+ \" Activation Function: \" + c)\n",
        "          elif (l == 3):\n",
        "            model_layer3(i,j, c,r)\n",
        "            #k = k + 1\n",
        "            parameter_list.append(\"hidden layers: 3 \"+\"Number of epochs: \"+ str(i) + \" learning rate: \"+ str(j) + \" Activation Function: \" + c+\" Regularizer: \"+ str(r))\n",
        "            print(\"Number of epochs: \"+ str(i) + \" learning rate: \"+ str(j)+\" Activation Function: \" + c)\n",
        "            print(\"Model number: \",k)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ6ytBsc6aMz",
        "outputId": "4939c9ad-9522-49bf-9d5d-8d58d7702fbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.7136 - root_mean_squared_error: 0.1803 - val_loss: 0.6397 - val_root_mean_squared_error: 0.1660\n",
            "Epoch 29/30\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.6062 - root_mean_squared_error: 0.1810 - val_loss: 0.5465 - val_root_mean_squared_error: 0.1667\n",
            "Epoch 30/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5223 - root_mean_squared_error: 0.1817 - val_loss: 0.4734 - val_root_mean_squared_error: 0.1674\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4632 - root_mean_squared_error: 0.1335\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4632 - root_mean_squared_error: 0.1335\n",
            "MODEL EVALUATION:  [0.4632444381713867, 0.13347163796424866]\n",
            "Number of epochs: 30 learning rate: 0.001 Activation Function: relu\n",
            "Model number:  514\n",
            "Epoch 1/30\n",
            "6/6 [==============================] - 1s 57ms/step - loss: 1.6613 - root_mean_squared_error: 0.4332 - val_loss: 1.4539 - val_root_mean_squared_error: 0.1863\n",
            "Epoch 2/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4139 - root_mean_squared_error: 0.1726 - val_loss: 1.3643 - val_root_mean_squared_error: 0.1869\n",
            "Epoch 3/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3284 - root_mean_squared_error: 0.1859 - val_loss: 1.2699 - val_root_mean_squared_error: 0.1757\n",
            "Epoch 4/30\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2280 - root_mean_squared_error: 0.1525 - val_loss: 1.1673 - val_root_mean_squared_error: 0.1219\n",
            "Epoch 5/30\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.1418 - root_mean_squared_error: 0.1473 - val_loss: 1.0849 - val_root_mean_squared_error: 0.1167\n",
            "Epoch 6/30\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.0599 - root_mean_squared_error: 0.1361 - val_loss: 1.0113 - val_root_mean_squared_error: 0.1241\n",
            "Epoch 7/30\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.9858 - root_mean_squared_error: 0.1340 - val_loss: 0.9402 - val_root_mean_squared_error: 0.1227\n",
            "Epoch 8/30\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.9149 - root_mean_squared_error: 0.1273 - val_loss: 0.8704 - val_root_mean_squared_error: 0.1076\n",
            "Epoch 9/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.8504 - root_mean_squared_error: 0.1267 - val_loss: 0.8082 - val_root_mean_squared_error: 0.1041\n",
            "Epoch 10/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.7904 - root_mean_squared_error: 0.1247 - val_loss: 0.7534 - val_root_mean_squared_error: 0.1129\n",
            "Epoch 11/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7339 - root_mean_squared_error: 0.1194 - val_loss: 0.6984 - val_root_mean_squared_error: 0.1037\n",
            "Epoch 12/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6820 - root_mean_squared_error: 0.1179 - val_loss: 0.6485 - val_root_mean_squared_error: 0.0995\n",
            "Epoch 13/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6340 - root_mean_squared_error: 0.1158 - val_loss: 0.6044 - val_root_mean_squared_error: 0.1060\n",
            "Epoch 14/30\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.5892 - root_mean_squared_error: 0.1131 - val_loss: 0.5598 - val_root_mean_squared_error: 0.0944\n",
            "Epoch 15/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5477 - root_mean_squared_error: 0.1109 - val_loss: 0.5219 - val_root_mean_squared_error: 0.0991\n",
            "Epoch 16/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5096 - root_mean_squared_error: 0.1085 - val_loss: 0.4857 - val_root_mean_squared_error: 0.0981\n",
            "Epoch 17/30\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4741 - root_mean_squared_error: 0.1065 - val_loss: 0.4513 - val_root_mean_squared_error: 0.0928\n",
            "Epoch 18/30\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4413 - root_mean_squared_error: 0.1046 - val_loss: 0.4207 - val_root_mean_squared_error: 0.0942\n",
            "Epoch 19/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4112 - root_mean_squared_error: 0.1033 - val_loss: 0.3919 - val_root_mean_squared_error: 0.0928\n",
            "Epoch 20/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3833 - root_mean_squared_error: 0.1024 - val_loss: 0.3641 - val_root_mean_squared_error: 0.0850\n",
            "Epoch 21/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3573 - root_mean_squared_error: 0.1004 - val_loss: 0.3422 - val_root_mean_squared_error: 0.0983\n",
            "Epoch 22/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3334 - root_mean_squared_error: 0.0995 - val_loss: 0.3169 - val_root_mean_squared_error: 0.0845\n",
            "Epoch 23/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3115 - root_mean_squared_error: 0.0998 - val_loss: 0.2965 - val_root_mean_squared_error: 0.0866\n",
            "Epoch 24/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2908 - root_mean_squared_error: 0.0974 - val_loss: 0.2781 - val_root_mean_squared_error: 0.0919\n",
            "Epoch 25/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2720 - root_mean_squared_error: 0.0972 - val_loss: 0.2585 - val_root_mean_squared_error: 0.0824\n",
            "Epoch 26/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2545 - root_mean_squared_error: 0.0961 - val_loss: 0.2430 - val_root_mean_squared_error: 0.0872\n",
            "Epoch 27/30\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2383 - root_mean_squared_error: 0.0947 - val_loss: 0.2272 - val_root_mean_squared_error: 0.0842\n",
            "Epoch 28/30\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2233 - root_mean_squared_error: 0.0939 - val_loss: 0.2125 - val_root_mean_squared_error: 0.0812\n",
            "Epoch 29/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2095 - root_mean_squared_error: 0.0934 - val_loss: 0.2001 - val_root_mean_squared_error: 0.0851\n",
            "Epoch 30/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1967 - root_mean_squared_error: 0.0928 - val_loss: 0.1880 - val_root_mean_squared_error: 0.0856\n",
            "2/2 [==============================] - 0s 3ms/step - loss: 0.1882 - root_mean_squared_error: 0.0863\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1882 - root_mean_squared_error: 0.0863\n",
            "MODEL EVALUATION:  [0.18816393613815308, 0.08626881241798401]\n",
            "Number of epochs: 30 learning rate: 0.001 Activation Function: relu\n",
            "Model number:  515\n",
            "Epoch 1/30\n",
            "6/6 [==============================] - 1s 45ms/step - loss: 0.0961 - root_mean_squared_error: 0.3100 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1700\n",
            "Epoch 2/30\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0416 - root_mean_squared_error: 0.2038 - val_loss: 0.0436 - val_root_mean_squared_error: 0.2088\n",
            "Epoch 3/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0312 - root_mean_squared_error: 0.1765 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1274\n",
            "Epoch 4/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0207 - root_mean_squared_error: 0.1439 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1049\n",
            "Epoch 5/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0141 - root_mean_squared_error: 0.1186 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1059\n",
            "Epoch 6/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0121 - root_mean_squared_error: 0.1098 - val_loss: 0.0076 - val_root_mean_squared_error: 0.0872\n",
            "Epoch 7/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0094 - root_mean_squared_error: 0.0968 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0701\n",
            "Epoch 8/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0086 - root_mean_squared_error: 0.0929 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0944\n",
            "Epoch 9/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0075 - root_mean_squared_error: 0.0864 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0705\n",
            "Epoch 10/30\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0066 - root_mean_squared_error: 0.0814 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0734\n",
            "Epoch 11/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0059 - root_mean_squared_error: 0.0769 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0763\n",
            "Epoch 12/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0053 - root_mean_squared_error: 0.0725 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0669\n",
            "Epoch 13/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0047 - root_mean_squared_error: 0.0687 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0688\n",
            "Epoch 14/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0048 - root_mean_squared_error: 0.0691 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0596\n",
            "Epoch 15/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0049 - root_mean_squared_error: 0.0698 - val_loss: 0.0052 - val_root_mean_squared_error: 0.0722\n",
            "Epoch 16/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0041 - root_mean_squared_error: 0.0641 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0569\n",
            "Epoch 17/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0038 - root_mean_squared_error: 0.0618 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0701\n",
            "Epoch 18/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0036 - root_mean_squared_error: 0.0597 - val_loss: 0.0029 - val_root_mean_squared_error: 0.0534\n",
            "Epoch 19/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0034 - root_mean_squared_error: 0.0580 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0717\n",
            "Epoch 20/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0029 - root_mean_squared_error: 0.0542 - val_loss: 0.0026 - val_root_mean_squared_error: 0.0513\n",
            "Epoch 21/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0027 - root_mean_squared_error: 0.0518 - val_loss: 0.0035 - val_root_mean_squared_error: 0.0593\n",
            "Epoch 22/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0503\n",
            "Epoch 23/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0023 - root_mean_squared_error: 0.0483 - val_loss: 0.0028 - val_root_mean_squared_error: 0.0526\n",
            "Epoch 24/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0022 - root_mean_squared_error: 0.0469 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0494\n",
            "Epoch 25/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0021 - root_mean_squared_error: 0.0460 - val_loss: 0.0027 - val_root_mean_squared_error: 0.0521\n",
            "Epoch 26/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0022 - root_mean_squared_error: 0.0468 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0434\n",
            "Epoch 27/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0021 - root_mean_squared_error: 0.0455 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0484\n",
            "Epoch 28/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0019 - root_mean_squared_error: 0.0434 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0437\n",
            "Epoch 29/30\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0019 - root_mean_squared_error: 0.0433 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0401\n",
            "Epoch 30/30\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0017 - root_mean_squared_error: 0.0409 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0451\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0019 - root_mean_squared_error: 0.0432\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0019 - root_mean_squared_error: 0.0432\n",
            "MODEL EVALUATION:  [0.0018651754362508655, 0.04318767786026001]\n",
            "Number of epochs: 30 learning rate: 0.001 Activation Function: relu\n",
            "Model number:  516\n",
            "Epoch 1/30\n",
            "6/6 [==============================] - 1s 51ms/step - loss: 12.3732 - root_mean_squared_error: 0.8440 - val_loss: 12.2809 - val_root_mean_squared_error: 0.8064\n",
            "Epoch 2/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 12.2450 - root_mean_squared_error: 0.7963 - val_loss: 12.1570 - val_root_mean_squared_error: 0.7596\n",
            "Epoch 3/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 12.1234 - root_mean_squared_error: 0.7507 - val_loss: 12.0388 - val_root_mean_squared_error: 0.7146\n",
            "Epoch 4/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 12.0068 - root_mean_squared_error: 0.7068 - val_loss: 11.9261 - val_root_mean_squared_error: 0.6720\n",
            "Epoch 5/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.8956 - root_mean_squared_error: 0.6652 - val_loss: 11.8187 - val_root_mean_squared_error: 0.6320\n",
            "Epoch 6/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.7896 - root_mean_squared_error: 0.6264 - val_loss: 11.7161 - val_root_mean_squared_error: 0.5947\n",
            "Epoch 7/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.6885 - root_mean_squared_error: 0.5905 - val_loss: 11.6179 - val_root_mean_squared_error: 0.5601\n",
            "Epoch 8/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.5914 - root_mean_squared_error: 0.5572 - val_loss: 11.5235 - val_root_mean_squared_error: 0.5283\n",
            "Epoch 9/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.4981 - root_mean_squared_error: 0.5266 - val_loss: 11.4326 - val_root_mean_squared_error: 0.4990\n",
            "Epoch 10/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.4080 - root_mean_squared_error: 0.4985 - val_loss: 11.3446 - val_root_mean_squared_error: 0.4719\n",
            "Epoch 11/30\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 11.3207 - root_mean_squared_error: 0.4724 - val_loss: 11.2593 - val_root_mean_squared_error: 0.4470\n",
            "Epoch 12/30\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 11.2360 - root_mean_squared_error: 0.4485 - val_loss: 11.1763 - val_root_mean_squared_error: 0.4241\n",
            "Epoch 13/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.1535 - root_mean_squared_error: 0.4265 - val_loss: 11.0955 - val_root_mean_squared_error: 0.4031\n",
            "Epoch 14/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.0732 - root_mean_squared_error: 0.4063 - val_loss: 11.0164 - val_root_mean_squared_error: 0.3836\n",
            "Epoch 15/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.9946 - root_mean_squared_error: 0.3877 - val_loss: 10.9389 - val_root_mean_squared_error: 0.3653\n",
            "Epoch 16/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.9174 - root_mean_squared_error: 0.3701 - val_loss: 10.8631 - val_root_mean_squared_error: 0.3489\n",
            "Epoch 17/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 10.8418 - root_mean_squared_error: 0.3543 - val_loss: 10.7886 - val_root_mean_squared_error: 0.3336\n",
            "Epoch 18/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.7678 - root_mean_squared_error: 0.3399 - val_loss: 10.7153 - val_root_mean_squared_error: 0.3194\n",
            "Epoch 19/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.6948 - root_mean_squared_error: 0.3264 - val_loss: 10.6432 - val_root_mean_squared_error: 0.3065\n",
            "Epoch 20/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.6230 - root_mean_squared_error: 0.3143 - val_loss: 10.5722 - val_root_mean_squared_error: 0.2946\n",
            "Epoch 21/30\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 10.5520 - root_mean_squared_error: 0.3029 - val_loss: 10.5021 - val_root_mean_squared_error: 0.2842\n",
            "Epoch 22/30\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 10.4823 - root_mean_squared_error: 0.2931 - val_loss: 10.4328 - val_root_mean_squared_error: 0.2743\n",
            "Epoch 23/30\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 10.4132 - root_mean_squared_error: 0.2838 - val_loss: 10.3642 - val_root_mean_squared_error: 0.2652\n",
            "Epoch 24/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 10.3448 - root_mean_squared_error: 0.2752 - val_loss: 10.2966 - val_root_mean_squared_error: 0.2573\n",
            "Epoch 25/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 10.2773 - root_mean_squared_error: 0.2679 - val_loss: 10.2294 - val_root_mean_squared_error: 0.2500\n",
            "Epoch 26/30\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 10.2102 - root_mean_squared_error: 0.2610 - val_loss: 10.1629 - val_root_mean_squared_error: 0.2435\n",
            "Epoch 27/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 10.1438 - root_mean_squared_error: 0.2548 - val_loss: 10.0969 - val_root_mean_squared_error: 0.2375\n",
            "Epoch 28/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.0780 - root_mean_squared_error: 0.2493 - val_loss: 10.0314 - val_root_mean_squared_error: 0.2320\n",
            "Epoch 29/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.0126 - root_mean_squared_error: 0.2441 - val_loss: 9.9666 - val_root_mean_squared_error: 0.2275\n",
            "Epoch 30/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 9.9479 - root_mean_squared_error: 0.2399 - val_loss: 9.9020 - val_root_mean_squared_error: 0.2229\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.8800 - root_mean_squared_error: 0.1666\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 9.8800 - root_mean_squared_error: 0.1666\n",
            "MODEL EVALUATION:  [9.880043983459473, 0.1665683537721634]\n",
            "Number of epochs: 30 learning rate: 0.0001 Activation Function: sigmoid\n",
            "Model number:  517\n",
            "Epoch 1/30\n",
            "6/6 [==============================] - 1s 52ms/step - loss: 1.5643 - root_mean_squared_error: 0.1844 - val_loss: 1.5512 - val_root_mean_squared_error: 0.1697\n",
            "Epoch 2/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5509 - root_mean_squared_error: 0.1833 - val_loss: 1.5381 - val_root_mean_squared_error: 0.1695\n",
            "Epoch 3/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5378 - root_mean_squared_error: 0.1832 - val_loss: 1.5250 - val_root_mean_squared_error: 0.1695\n",
            "Epoch 4/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5247 - root_mean_squared_error: 0.1833 - val_loss: 1.5120 - val_root_mean_squared_error: 0.1695\n",
            "Epoch 5/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5118 - root_mean_squared_error: 0.1833 - val_loss: 1.4990 - val_root_mean_squared_error: 0.1695\n",
            "Epoch 6/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4989 - root_mean_squared_error: 0.1832 - val_loss: 1.4864 - val_root_mean_squared_error: 0.1697\n",
            "Epoch 7/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4862 - root_mean_squared_error: 0.1832 - val_loss: 1.4738 - val_root_mean_squared_error: 0.1698\n",
            "Epoch 8/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4737 - root_mean_squared_error: 0.1836 - val_loss: 1.4613 - val_root_mean_squared_error: 0.1700\n",
            "Epoch 9/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4611 - root_mean_squared_error: 0.1833 - val_loss: 1.4487 - val_root_mean_squared_error: 0.1697\n",
            "Epoch 10/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4486 - root_mean_squared_error: 0.1832 - val_loss: 1.4363 - val_root_mean_squared_error: 0.1695\n",
            "Epoch 11/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4363 - root_mean_squared_error: 0.1832 - val_loss: 1.4239 - val_root_mean_squared_error: 0.1694\n",
            "Epoch 12/30\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.4240 - root_mean_squared_error: 0.1833 - val_loss: 1.4117 - val_root_mean_squared_error: 0.1694\n",
            "Epoch 13/30\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.4119 - root_mean_squared_error: 0.1833 - val_loss: 1.3996 - val_root_mean_squared_error: 0.1695\n",
            "Epoch 14/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3997 - root_mean_squared_error: 0.1832 - val_loss: 1.3876 - val_root_mean_squared_error: 0.1696\n",
            "Epoch 15/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3878 - root_mean_squared_error: 0.1833 - val_loss: 1.3757 - val_root_mean_squared_error: 0.1696\n",
            "Epoch 16/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3759 - root_mean_squared_error: 0.1832 - val_loss: 1.3638 - val_root_mean_squared_error: 0.1696\n",
            "Epoch 17/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3641 - root_mean_squared_error: 0.1832 - val_loss: 1.3521 - val_root_mean_squared_error: 0.1695\n",
            "Epoch 18/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3524 - root_mean_squared_error: 0.1833 - val_loss: 1.3404 - val_root_mean_squared_error: 0.1694\n",
            "Epoch 19/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3408 - root_mean_squared_error: 0.1833 - val_loss: 1.3290 - val_root_mean_squared_error: 0.1695\n",
            "Epoch 20/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.3294 - root_mean_squared_error: 0.1833 - val_loss: 1.3175 - val_root_mean_squared_error: 0.1695\n",
            "Epoch 21/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3180 - root_mean_squared_error: 0.1833 - val_loss: 1.3062 - val_root_mean_squared_error: 0.1695\n",
            "Epoch 22/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3067 - root_mean_squared_error: 0.1833 - val_loss: 1.2950 - val_root_mean_squared_error: 0.1696\n",
            "Epoch 23/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2955 - root_mean_squared_error: 0.1834 - val_loss: 1.2839 - val_root_mean_squared_error: 0.1695\n",
            "Epoch 24/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2844 - root_mean_squared_error: 0.1833 - val_loss: 1.2729 - val_root_mean_squared_error: 0.1695\n",
            "Epoch 25/30\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.2734 - root_mean_squared_error: 0.1833 - val_loss: 1.2619 - val_root_mean_squared_error: 0.1695\n",
            "Epoch 26/30\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.2625 - root_mean_squared_error: 0.1833 - val_loss: 1.2511 - val_root_mean_squared_error: 0.1695\n",
            "Epoch 27/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2517 - root_mean_squared_error: 0.1834 - val_loss: 1.2403 - val_root_mean_squared_error: 0.1695\n",
            "Epoch 28/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2410 - root_mean_squared_error: 0.1833 - val_loss: 1.2296 - val_root_mean_squared_error: 0.1696\n",
            "Epoch 29/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2304 - root_mean_squared_error: 0.1834 - val_loss: 1.2191 - val_root_mean_squared_error: 0.1697\n",
            "Epoch 30/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2198 - root_mean_squared_error: 0.1833 - val_loss: 1.2086 - val_root_mean_squared_error: 0.1696\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.1989 - root_mean_squared_error: 0.1381\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1989 - root_mean_squared_error: 0.1381\n",
            "MODEL EVALUATION:  [1.1988849639892578, 0.13813498616218567]\n",
            "Number of epochs: 30 learning rate: 0.0001 Activation Function: sigmoid\n",
            "Model number:  518\n",
            "Epoch 1/30\n",
            "6/6 [==============================] - 1s 45ms/step - loss: 0.3195 - root_mean_squared_error: 0.5652 - val_loss: 0.2625 - val_root_mean_squared_error: 0.5124\n",
            "Epoch 2/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2451 - root_mean_squared_error: 0.4951 - val_loss: 0.1973 - val_root_mean_squared_error: 0.4442\n",
            "Epoch 3/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1838 - root_mean_squared_error: 0.4288 - val_loss: 0.1445 - val_root_mean_squared_error: 0.3801\n",
            "Epoch 4/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1361 - root_mean_squared_error: 0.3690 - val_loss: 0.1035 - val_root_mean_squared_error: 0.3218\n",
            "Epoch 5/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0990 - root_mean_squared_error: 0.3146 - val_loss: 0.0740 - val_root_mean_squared_error: 0.2721\n",
            "Epoch 6/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0729 - root_mean_squared_error: 0.2699 - val_loss: 0.0541 - val_root_mean_squared_error: 0.2325\n",
            "Epoch 7/30\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0553 - root_mean_squared_error: 0.2352 - val_loss: 0.0415 - val_root_mean_squared_error: 0.2038\n",
            "Epoch 8/30\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0443 - root_mean_squared_error: 0.2104 - val_loss: 0.0343 - val_root_mean_squared_error: 0.1853\n",
            "Epoch 9/30\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0384 - root_mean_squared_error: 0.1960 - val_loss: 0.0307 - val_root_mean_squared_error: 0.1751\n",
            "Epoch 10/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0353 - root_mean_squared_error: 0.1879 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1705\n",
            "Epoch 11/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0340 - root_mean_squared_error: 0.1843 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1691\n",
            "Epoch 12/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0337 - root_mean_squared_error: 0.1836 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1690\n",
            "Epoch 13/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1692\n",
            "Epoch 14/30\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0335 - root_mean_squared_error: 0.1830 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1693\n",
            "Epoch 15/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0335 - root_mean_squared_error: 0.1830 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1693\n",
            "Epoch 16/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1692\n",
            "Epoch 17/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0334 - root_mean_squared_error: 0.1829 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1690\n",
            "Epoch 18/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0334 - root_mean_squared_error: 0.1828 - val_loss: 0.0285 - val_root_mean_squared_error: 0.1690\n",
            "Epoch 19/30\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0285 - val_root_mean_squared_error: 0.1689\n",
            "Epoch 20/30\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0285 - val_root_mean_squared_error: 0.1688\n",
            "Epoch 21/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0333 - root_mean_squared_error: 0.1826 - val_loss: 0.0285 - val_root_mean_squared_error: 0.1687\n",
            "Epoch 22/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0333 - root_mean_squared_error: 0.1825 - val_loss: 0.0284 - val_root_mean_squared_error: 0.1686\n",
            "Epoch 23/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0333 - root_mean_squared_error: 0.1825 - val_loss: 0.0284 - val_root_mean_squared_error: 0.1686\n",
            "Epoch 24/30\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0333 - root_mean_squared_error: 0.1825 - val_loss: 0.0284 - val_root_mean_squared_error: 0.1685\n",
            "Epoch 25/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0333 - root_mean_squared_error: 0.1824 - val_loss: 0.0284 - val_root_mean_squared_error: 0.1685\n",
            "Epoch 26/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0333 - root_mean_squared_error: 0.1824 - val_loss: 0.0284 - val_root_mean_squared_error: 0.1684\n",
            "Epoch 27/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0332 - root_mean_squared_error: 0.1823 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1684\n",
            "Epoch 28/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0333 - root_mean_squared_error: 0.1824 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1683\n",
            "Epoch 29/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0332 - root_mean_squared_error: 0.1822 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1682\n",
            "Epoch 30/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0332 - root_mean_squared_error: 0.1823 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1682\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0186 - root_mean_squared_error: 0.1363\n",
            "MODEL EVALUATION:  [0.018566885963082314, 0.13626036047935486]\n",
            "Number of epochs: 30 learning rate: 0.0001 Activation Function: sigmoid\n",
            "Model number:  519\n",
            "Epoch 1/30\n",
            "6/6 [==============================] - 1s 45ms/step - loss: 11.8705 - root_mean_squared_error: 0.5596 - val_loss: 11.8092 - val_root_mean_squared_error: 0.5361\n",
            "Epoch 2/30\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 11.7635 - root_mean_squared_error: 0.5146 - val_loss: 11.7023 - val_root_mean_squared_error: 0.4895\n",
            "Epoch 3/30\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 11.6663 - root_mean_squared_error: 0.4762 - val_loss: 11.6045 - val_root_mean_squared_error: 0.4486\n",
            "Epoch 4/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 11.5754 - root_mean_squared_error: 0.4424 - val_loss: 11.5147 - val_root_mean_squared_error: 0.4143\n",
            "Epoch 5/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.4899 - root_mean_squared_error: 0.4132 - val_loss: 11.4300 - val_root_mean_squared_error: 0.3847\n",
            "Epoch 6/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 11.4088 - root_mean_squared_error: 0.3882 - val_loss: 11.3486 - val_root_mean_squared_error: 0.3576\n",
            "Epoch 7/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.3295 - root_mean_squared_error: 0.3646 - val_loss: 11.2702 - val_root_mean_squared_error: 0.3335\n",
            "Epoch 8/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 11.2530 - root_mean_squared_error: 0.3439 - val_loss: 11.1942 - val_root_mean_squared_error: 0.3120\n",
            "Epoch 9/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.1779 - root_mean_squared_error: 0.3248 - val_loss: 11.1201 - val_root_mean_squared_error: 0.2928\n",
            "Epoch 10/30\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 11.1047 - root_mean_squared_error: 0.3079 - val_loss: 11.0476 - val_root_mean_squared_error: 0.2755\n",
            "Epoch 11/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 11.0327 - root_mean_squared_error: 0.2926 - val_loss: 10.9762 - val_root_mean_squared_error: 0.2599\n",
            "Epoch 12/30\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 10.9619 - root_mean_squared_error: 0.2789 - val_loss: 10.9058 - val_root_mean_squared_error: 0.2452\n",
            "Epoch 13/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.8918 - root_mean_squared_error: 0.2663 - val_loss: 10.8362 - val_root_mean_squared_error: 0.2320\n",
            "Epoch 14/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.8223 - root_mean_squared_error: 0.2543 - val_loss: 10.7675 - val_root_mean_squared_error: 0.2203\n",
            "Epoch 15/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.7536 - root_mean_squared_error: 0.2438 - val_loss: 10.6996 - val_root_mean_squared_error: 0.2100\n",
            "Epoch 16/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 10.6857 - root_mean_squared_error: 0.2346 - val_loss: 10.6322 - val_root_mean_squared_error: 0.2004\n",
            "Epoch 17/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.6183 - root_mean_squared_error: 0.2261 - val_loss: 10.5653 - val_root_mean_squared_error: 0.1918\n",
            "Epoch 18/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 10.5512 - root_mean_squared_error: 0.2182 - val_loss: 10.4989 - val_root_mean_squared_error: 0.1842\n",
            "Epoch 19/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.4849 - root_mean_squared_error: 0.2114 - val_loss: 10.4330 - val_root_mean_squared_error: 0.1772\n",
            "Epoch 20/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.4187 - root_mean_squared_error: 0.2048 - val_loss: 10.3675 - val_root_mean_squared_error: 0.1713\n",
            "Epoch 21/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.3531 - root_mean_squared_error: 0.1993 - val_loss: 10.3024 - val_root_mean_squared_error: 0.1659\n",
            "Epoch 22/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.2880 - root_mean_squared_error: 0.1943 - val_loss: 10.2377 - val_root_mean_squared_error: 0.1610\n",
            "Epoch 23/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.2230 - root_mean_squared_error: 0.1896 - val_loss: 10.1732 - val_root_mean_squared_error: 0.1572\n",
            "Epoch 24/30\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 10.1583 - root_mean_squared_error: 0.1858 - val_loss: 10.1090 - val_root_mean_squared_error: 0.1539\n",
            "Epoch 25/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.0939 - root_mean_squared_error: 0.1825 - val_loss: 10.0450 - val_root_mean_squared_error: 0.1508\n",
            "Epoch 26/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.0298 - root_mean_squared_error: 0.1794 - val_loss: 9.9812 - val_root_mean_squared_error: 0.1479\n",
            "Epoch 27/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 9.9659 - root_mean_squared_error: 0.1764 - val_loss: 9.9177 - val_root_mean_squared_error: 0.1456\n",
            "Epoch 28/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 9.9022 - root_mean_squared_error: 0.1739 - val_loss: 9.8544 - val_root_mean_squared_error: 0.1436\n",
            "Epoch 29/30\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 9.8388 - root_mean_squared_error: 0.1717 - val_loss: 9.7914 - val_root_mean_squared_error: 0.1417\n",
            "Epoch 30/30\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 9.7756 - root_mean_squared_error: 0.1696 - val_loss: 9.7285 - val_root_mean_squared_error: 0.1401\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 9.7226 - root_mean_squared_error: 0.1172\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.7226 - root_mean_squared_error: 0.1172\n",
            "MODEL EVALUATION:  [9.72256088256836, 0.1171860471367836]\n",
            "Number of epochs: 30 learning rate: 0.0001 Activation Function: relu\n",
            "Model number:  520\n",
            "Epoch 1/30\n",
            "6/6 [==============================] - 1s 50ms/step - loss: 1.9015 - root_mean_squared_error: 0.6050 - val_loss: 1.8589 - val_root_mean_squared_error: 0.5736\n",
            "Epoch 2/30\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.8410 - root_mean_squared_error: 0.5611 - val_loss: 1.8003 - val_root_mean_squared_error: 0.5289\n",
            "Epoch 3/30\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.7866 - root_mean_squared_error: 0.5194 - val_loss: 1.7486 - val_root_mean_squared_error: 0.4873\n",
            "Epoch 4/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.7382 - root_mean_squared_error: 0.4803 - val_loss: 1.7020 - val_root_mean_squared_error: 0.4475\n",
            "Epoch 5/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6951 - root_mean_squared_error: 0.4438 - val_loss: 1.6586 - val_root_mean_squared_error: 0.4077\n",
            "Epoch 6/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6549 - root_mean_squared_error: 0.4076 - val_loss: 1.6166 - val_root_mean_squared_error: 0.3654\n",
            "Epoch 7/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6139 - root_mean_squared_error: 0.3666 - val_loss: 1.5765 - val_root_mean_squared_error: 0.3204\n",
            "Epoch 8/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5773 - root_mean_squared_error: 0.3271 - val_loss: 1.5414 - val_root_mean_squared_error: 0.2770\n",
            "Epoch 9/30\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 1.5445 - root_mean_squared_error: 0.2889 - val_loss: 1.5120 - val_root_mean_squared_error: 0.2377\n",
            "Epoch 10/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5156 - root_mean_squared_error: 0.2524 - val_loss: 1.4889 - val_root_mean_squared_error: 0.2067\n",
            "Epoch 11/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4939 - root_mean_squared_error: 0.2266 - val_loss: 1.4702 - val_root_mean_squared_error: 0.1827\n",
            "Epoch 12/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4755 - root_mean_squared_error: 0.2056 - val_loss: 1.4553 - val_root_mean_squared_error: 0.1669\n",
            "Epoch 13/30\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 1.4603 - root_mean_squared_error: 0.1912 - val_loss: 1.4429 - val_root_mean_squared_error: 0.1578\n",
            "Epoch 14/30\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.4475 - root_mean_squared_error: 0.1822 - val_loss: 1.4319 - val_root_mean_squared_error: 0.1531\n",
            "Epoch 15/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4360 - root_mean_squared_error: 0.1766 - val_loss: 1.4217 - val_root_mean_squared_error: 0.1506\n",
            "Epoch 16/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4250 - root_mean_squared_error: 0.1725 - val_loss: 1.4116 - val_root_mean_squared_error: 0.1492\n",
            "Epoch 17/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.4142 - root_mean_squared_error: 0.1692 - val_loss: 1.4016 - val_root_mean_squared_error: 0.1478\n",
            "Epoch 18/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4040 - root_mean_squared_error: 0.1672 - val_loss: 1.3917 - val_root_mean_squared_error: 0.1465\n",
            "Epoch 19/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3936 - root_mean_squared_error: 0.1647 - val_loss: 1.3816 - val_root_mean_squared_error: 0.1447\n",
            "Epoch 20/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3834 - root_mean_squared_error: 0.1627 - val_loss: 1.3716 - val_root_mean_squared_error: 0.1429\n",
            "Epoch 21/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3734 - root_mean_squared_error: 0.1610 - val_loss: 1.3617 - val_root_mean_squared_error: 0.1413\n",
            "Epoch 22/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3634 - root_mean_squared_error: 0.1591 - val_loss: 1.3518 - val_root_mean_squared_error: 0.1393\n",
            "Epoch 23/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3535 - root_mean_squared_error: 0.1574 - val_loss: 1.3419 - val_root_mean_squared_error: 0.1375\n",
            "Epoch 24/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3436 - root_mean_squared_error: 0.1556 - val_loss: 1.3322 - val_root_mean_squared_error: 0.1357\n",
            "Epoch 25/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3338 - root_mean_squared_error: 0.1540 - val_loss: 1.3226 - val_root_mean_squared_error: 0.1343\n",
            "Epoch 26/30\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3241 - root_mean_squared_error: 0.1524 - val_loss: 1.3129 - val_root_mean_squared_error: 0.1324\n",
            "Epoch 27/30\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3145 - root_mean_squared_error: 0.1509 - val_loss: 1.3033 - val_root_mean_squared_error: 0.1308\n",
            "Epoch 28/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3050 - root_mean_squared_error: 0.1495 - val_loss: 1.2939 - val_root_mean_squared_error: 0.1295\n",
            "Epoch 29/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2955 - root_mean_squared_error: 0.1480 - val_loss: 1.2846 - val_root_mean_squared_error: 0.1282\n",
            "Epoch 30/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2862 - root_mean_squared_error: 0.1467 - val_loss: 1.2752 - val_root_mean_squared_error: 0.1268\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2742 - root_mean_squared_error: 0.1227\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2742 - root_mean_squared_error: 0.1227\n",
            "MODEL EVALUATION:  [1.2742373943328857, 0.12273101508617401]\n",
            "Number of epochs: 30 learning rate: 0.0001 Activation Function: relu\n",
            "Model number:  521\n",
            "Epoch 1/30\n",
            "6/6 [==============================] - 1s 48ms/step - loss: 0.2228 - root_mean_squared_error: 0.4720 - val_loss: 0.1882 - val_root_mean_squared_error: 0.4339\n",
            "Epoch 2/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1817 - root_mean_squared_error: 0.4262 - val_loss: 0.1475 - val_root_mean_squared_error: 0.3840\n",
            "Epoch 3/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1451 - root_mean_squared_error: 0.3809 - val_loss: 0.1126 - val_root_mean_squared_error: 0.3355\n",
            "Epoch 4/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1143 - root_mean_squared_error: 0.3381 - val_loss: 0.0840 - val_root_mean_squared_error: 0.2898\n",
            "Epoch 5/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0882 - root_mean_squared_error: 0.2970 - val_loss: 0.0613 - val_root_mean_squared_error: 0.2477\n",
            "Epoch 6/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0677 - root_mean_squared_error: 0.2602 - val_loss: 0.0450 - val_root_mean_squared_error: 0.2121\n",
            "Epoch 7/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0527 - root_mean_squared_error: 0.2297 - val_loss: 0.0334 - val_root_mean_squared_error: 0.1828\n",
            "Epoch 8/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0411 - root_mean_squared_error: 0.2027 - val_loss: 0.0255 - val_root_mean_squared_error: 0.1596\n",
            "Epoch 9/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0336 - root_mean_squared_error: 0.1832 - val_loss: 0.0202 - val_root_mean_squared_error: 0.1421\n",
            "Epoch 10/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0282 - root_mean_squared_error: 0.1680 - val_loss: 0.0171 - val_root_mean_squared_error: 0.1309\n",
            "Epoch 11/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0247 - root_mean_squared_error: 0.1573 - val_loss: 0.0157 - val_root_mean_squared_error: 0.1252\n",
            "Epoch 12/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0225 - root_mean_squared_error: 0.1500 - val_loss: 0.0151 - val_root_mean_squared_error: 0.1229\n",
            "Epoch 13/30\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0213 - root_mean_squared_error: 0.1460 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1221\n",
            "Epoch 14/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0204 - root_mean_squared_error: 0.1428 - val_loss: 0.0148 - val_root_mean_squared_error: 0.1215\n",
            "Epoch 15/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0198 - root_mean_squared_error: 0.1406 - val_loss: 0.0147 - val_root_mean_squared_error: 0.1211\n",
            "Epoch 16/30\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0192 - root_mean_squared_error: 0.1385 - val_loss: 0.0144 - val_root_mean_squared_error: 0.1198\n",
            "Epoch 17/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0186 - root_mean_squared_error: 0.1364 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1181\n",
            "Epoch 18/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0181 - root_mean_squared_error: 0.1345 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1164\n",
            "Epoch 19/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0175 - root_mean_squared_error: 0.1323 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1143\n",
            "Epoch 20/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0170 - root_mean_squared_error: 0.1302 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1120\n",
            "Epoch 21/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0165 - root_mean_squared_error: 0.1283 - val_loss: 0.0119 - val_root_mean_squared_error: 0.1091\n",
            "Epoch 22/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0159 - root_mean_squared_error: 0.1260 - val_loss: 0.0113 - val_root_mean_squared_error: 0.1064\n",
            "Epoch 23/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0153 - root_mean_squared_error: 0.1236 - val_loss: 0.0107 - val_root_mean_squared_error: 0.1033\n",
            "Epoch 24/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0146 - root_mean_squared_error: 0.1209 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1009\n",
            "Epoch 25/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0141 - root_mean_squared_error: 0.1186 - val_loss: 0.0097 - val_root_mean_squared_error: 0.0982\n",
            "Epoch 26/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0136 - root_mean_squared_error: 0.1165 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0965\n",
            "Epoch 27/30\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0131 - root_mean_squared_error: 0.1146 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0951\n",
            "Epoch 28/30\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0127 - root_mean_squared_error: 0.1126 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0943\n",
            "Epoch 29/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0123 - root_mean_squared_error: 0.1111 - val_loss: 0.0088 - val_root_mean_squared_error: 0.0936\n",
            "Epoch 30/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0120 - root_mean_squared_error: 0.1095 - val_loss: 0.0085 - val_root_mean_squared_error: 0.0923\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0087 - root_mean_squared_error: 0.0930\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0087 - root_mean_squared_error: 0.0930\n",
            "MODEL EVALUATION:  [0.008656986057758331, 0.09304292500019073]\n",
            "Number of epochs: 30 learning rate: 0.0001 Activation Function: relu\n",
            "Model number:  522\n",
            "Epoch 1/30\n",
            "6/6 [==============================] - 1s 46ms/step - loss: 14.8826 - root_mean_squared_error: 1.7938 - val_loss: 14.8449 - val_root_mean_squared_error: 1.7838\n",
            "Epoch 2/30\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 14.8574 - root_mean_squared_error: 1.7877 - val_loss: 14.8198 - val_root_mean_squared_error: 1.7777\n",
            "Epoch 3/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 14.8323 - root_mean_squared_error: 1.7815 - val_loss: 14.7949 - val_root_mean_squared_error: 1.7715\n",
            "Epoch 4/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 14.8074 - root_mean_squared_error: 1.7754 - val_loss: 14.7700 - val_root_mean_squared_error: 1.7654\n",
            "Epoch 5/30\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 14.7825 - root_mean_squared_error: 1.7692 - val_loss: 14.7453 - val_root_mean_squared_error: 1.7592\n",
            "Epoch 6/30\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 14.7578 - root_mean_squared_error: 1.7631 - val_loss: 14.7206 - val_root_mean_squared_error: 1.7531\n",
            "Epoch 7/30\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 14.7330 - root_mean_squared_error: 1.7570 - val_loss: 14.6961 - val_root_mean_squared_error: 1.7470\n",
            "Epoch 8/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.7085 - root_mean_squared_error: 1.7509 - val_loss: 14.6717 - val_root_mean_squared_error: 1.7409\n",
            "Epoch 9/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.6841 - root_mean_squared_error: 1.7448 - val_loss: 14.6473 - val_root_mean_squared_error: 1.7348\n",
            "Epoch 10/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.6597 - root_mean_squared_error: 1.7387 - val_loss: 14.6231 - val_root_mean_squared_error: 1.7287\n",
            "Epoch 11/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 14.6356 - root_mean_squared_error: 1.7327 - val_loss: 14.5990 - val_root_mean_squared_error: 1.7227\n",
            "Epoch 12/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.6114 - root_mean_squared_error: 1.7266 - val_loss: 14.5751 - val_root_mean_squared_error: 1.7166\n",
            "Epoch 13/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.5875 - root_mean_squared_error: 1.7206 - val_loss: 14.5512 - val_root_mean_squared_error: 1.7106\n",
            "Epoch 14/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.5635 - root_mean_squared_error: 1.7146 - val_loss: 14.5274 - val_root_mean_squared_error: 1.7046\n",
            "Epoch 15/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.5398 - root_mean_squared_error: 1.7086 - val_loss: 14.5038 - val_root_mean_squared_error: 1.6986\n",
            "Epoch 16/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 14.5161 - root_mean_squared_error: 1.7026 - val_loss: 14.4803 - val_root_mean_squared_error: 1.6927\n",
            "Epoch 17/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.4925 - root_mean_squared_error: 1.6967 - val_loss: 14.4568 - val_root_mean_squared_error: 1.6867\n",
            "Epoch 18/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.4691 - root_mean_squared_error: 1.6907 - val_loss: 14.4335 - val_root_mean_squared_error: 1.6808\n",
            "Epoch 19/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.4458 - root_mean_squared_error: 1.6848 - val_loss: 14.4103 - val_root_mean_squared_error: 1.6748\n",
            "Epoch 20/30\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 14.4226 - root_mean_squared_error: 1.6789 - val_loss: 14.3871 - val_root_mean_squared_error: 1.6689\n",
            "Epoch 21/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.3995 - root_mean_squared_error: 1.6730 - val_loss: 14.3641 - val_root_mean_squared_error: 1.6630\n",
            "Epoch 22/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 14.3764 - root_mean_squared_error: 1.6671 - val_loss: 14.3413 - val_root_mean_squared_error: 1.6572\n",
            "Epoch 23/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.3535 - root_mean_squared_error: 1.6612 - val_loss: 14.3185 - val_root_mean_squared_error: 1.6513\n",
            "Epoch 24/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.3307 - root_mean_squared_error: 1.6554 - val_loss: 14.2958 - val_root_mean_squared_error: 1.6455\n",
            "Epoch 25/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.3079 - root_mean_squared_error: 1.6495 - val_loss: 14.2732 - val_root_mean_squared_error: 1.6396\n",
            "Epoch 26/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.2853 - root_mean_squared_error: 1.6437 - val_loss: 14.2507 - val_root_mean_squared_error: 1.6338\n",
            "Epoch 27/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 14.2628 - root_mean_squared_error: 1.6379 - val_loss: 14.2283 - val_root_mean_squared_error: 1.6280\n",
            "Epoch 28/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.2404 - root_mean_squared_error: 1.6321 - val_loss: 14.2060 - val_root_mean_squared_error: 1.6222\n",
            "Epoch 29/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.2181 - root_mean_squared_error: 1.6263 - val_loss: 14.1838 - val_root_mean_squared_error: 1.6164\n",
            "Epoch 30/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 14.1959 - root_mean_squared_error: 1.6205 - val_loss: 14.1617 - val_root_mean_squared_error: 1.6106\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.0221 - root_mean_squared_error: 1.5667\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 14.0221 - root_mean_squared_error: 1.5667\n",
            "MODEL EVALUATION:  [14.022122383117676, 1.5666983127593994]\n",
            "Number of epochs: 30 learning rate: 1e-05 Activation Function: sigmoid\n",
            "Model number:  523\n",
            "Epoch 1/30\n",
            "6/6 [==============================] - 1s 49ms/step - loss: 1.6360 - root_mean_squared_error: 0.3310 - val_loss: 1.6258 - val_root_mean_squared_error: 0.3159\n",
            "Epoch 2/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6318 - root_mean_squared_error: 0.3257 - val_loss: 1.6217 - val_root_mean_squared_error: 0.3104\n",
            "Epoch 3/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6277 - root_mean_squared_error: 0.3204 - val_loss: 1.6176 - val_root_mean_squared_error: 0.3051\n",
            "Epoch 4/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6235 - root_mean_squared_error: 0.3151 - val_loss: 1.6137 - val_root_mean_squared_error: 0.2999\n",
            "Epoch 5/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6196 - root_mean_squared_error: 0.3100 - val_loss: 1.6099 - val_root_mean_squared_error: 0.2948\n",
            "Epoch 6/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6158 - root_mean_squared_error: 0.3051 - val_loss: 1.6062 - val_root_mean_squared_error: 0.2897\n",
            "Epoch 7/30\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.6120 - root_mean_squared_error: 0.3002 - val_loss: 1.6026 - val_root_mean_squared_error: 0.2849\n",
            "Epoch 8/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6084 - root_mean_squared_error: 0.2955 - val_loss: 1.5991 - val_root_mean_squared_error: 0.2801\n",
            "Epoch 9/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6049 - root_mean_squared_error: 0.2909 - val_loss: 1.5957 - val_root_mean_squared_error: 0.2754\n",
            "Epoch 10/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6015 - root_mean_squared_error: 0.2865 - val_loss: 1.5923 - val_root_mean_squared_error: 0.2709\n",
            "Epoch 11/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5982 - root_mean_squared_error: 0.2820 - val_loss: 1.5892 - val_root_mean_squared_error: 0.2666\n",
            "Epoch 12/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5950 - root_mean_squared_error: 0.2779 - val_loss: 1.5861 - val_root_mean_squared_error: 0.2624\n",
            "Epoch 13/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5918 - root_mean_squared_error: 0.2737 - val_loss: 1.5831 - val_root_mean_squared_error: 0.2584\n",
            "Epoch 14/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5888 - root_mean_squared_error: 0.2699 - val_loss: 1.5802 - val_root_mean_squared_error: 0.2543\n",
            "Epoch 15/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5858 - root_mean_squared_error: 0.2659 - val_loss: 1.5773 - val_root_mean_squared_error: 0.2505\n",
            "Epoch 16/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5830 - root_mean_squared_error: 0.2622 - val_loss: 1.5746 - val_root_mean_squared_error: 0.2468\n",
            "Epoch 17/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5802 - root_mean_squared_error: 0.2586 - val_loss: 1.5719 - val_root_mean_squared_error: 0.2432\n",
            "Epoch 18/30\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 1.5775 - root_mean_squared_error: 0.2552 - val_loss: 1.5693 - val_root_mean_squared_error: 0.2397\n",
            "Epoch 19/30\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.5749 - root_mean_squared_error: 0.2518 - val_loss: 1.5668 - val_root_mean_squared_error: 0.2364\n",
            "Epoch 20/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5723 - root_mean_squared_error: 0.2486 - val_loss: 1.5643 - val_root_mean_squared_error: 0.2331\n",
            "Epoch 21/30\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.5699 - root_mean_squared_error: 0.2456 - val_loss: 1.5619 - val_root_mean_squared_error: 0.2300\n",
            "Epoch 22/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5675 - root_mean_squared_error: 0.2426 - val_loss: 1.5596 - val_root_mean_squared_error: 0.2270\n",
            "Epoch 23/30\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.5651 - root_mean_squared_error: 0.2397 - val_loss: 1.5573 - val_root_mean_squared_error: 0.2241\n",
            "Epoch 24/30\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.5628 - root_mean_squared_error: 0.2369 - val_loss: 1.5551 - val_root_mean_squared_error: 0.2214\n",
            "Epoch 25/30\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.5606 - root_mean_squared_error: 0.2343 - val_loss: 1.5530 - val_root_mean_squared_error: 0.2188\n",
            "Epoch 26/30\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.5585 - root_mean_squared_error: 0.2319 - val_loss: 1.5509 - val_root_mean_squared_error: 0.2163\n",
            "Epoch 27/30\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.5564 - root_mean_squared_error: 0.2294 - val_loss: 1.5489 - val_root_mean_squared_error: 0.2139\n",
            "Epoch 28/30\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.5543 - root_mean_squared_error: 0.2271 - val_loss: 1.5469 - val_root_mean_squared_error: 0.2116\n",
            "Epoch 29/30\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.5523 - root_mean_squared_error: 0.2250 - val_loss: 1.5449 - val_root_mean_squared_error: 0.2094\n",
            "Epoch 30/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5503 - root_mean_squared_error: 0.2228 - val_loss: 1.5431 - val_root_mean_squared_error: 0.2075\n",
            "2/2 [==============================] - 0s 12ms/step - loss: 1.5230 - root_mean_squared_error: 0.1514\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.5230 - root_mean_squared_error: 0.1514\n",
            "MODEL EVALUATION:  [1.5229620933532715, 0.15143118798732758]\n",
            "Number of epochs: 30 learning rate: 1e-05 Activation Function: sigmoid\n",
            "Model number:  524\n",
            "Epoch 1/30\n",
            "6/6 [==============================] - 1s 47ms/step - loss: 2.1567 - root_mean_squared_error: 1.4686 - val_loss: 2.1260 - val_root_mean_squared_error: 1.4581\n",
            "Epoch 2/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.1382 - root_mean_squared_error: 1.4623 - val_loss: 2.1076 - val_root_mean_squared_error: 1.4518\n",
            "Epoch 3/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.1198 - root_mean_squared_error: 1.4560 - val_loss: 2.0893 - val_root_mean_squared_error: 1.4454\n",
            "Epoch 4/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.1015 - root_mean_squared_error: 1.4496 - val_loss: 2.0711 - val_root_mean_squared_error: 1.4391\n",
            "Epoch 5/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.0831 - root_mean_squared_error: 1.4433 - val_loss: 2.0530 - val_root_mean_squared_error: 1.4328\n",
            "Epoch 6/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.0651 - root_mean_squared_error: 1.4370 - val_loss: 2.0350 - val_root_mean_squared_error: 1.4265\n",
            "Epoch 7/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.0471 - root_mean_squared_error: 1.4308 - val_loss: 2.0171 - val_root_mean_squared_error: 1.4202\n",
            "Epoch 8/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.0291 - root_mean_squared_error: 1.4245 - val_loss: 1.9993 - val_root_mean_squared_error: 1.4140\n",
            "Epoch 9/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.0114 - root_mean_squared_error: 1.4182 - val_loss: 1.9816 - val_root_mean_squared_error: 1.4077\n",
            "Epoch 10/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.9936 - root_mean_squared_error: 1.4120 - val_loss: 1.9640 - val_root_mean_squared_error: 1.4014\n",
            "Epoch 11/30\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.9760 - root_mean_squared_error: 1.4057 - val_loss: 1.9466 - val_root_mean_squared_error: 1.3952\n",
            "Epoch 12/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.9585 - root_mean_squared_error: 1.3995 - val_loss: 1.9292 - val_root_mean_squared_error: 1.3890\n",
            "Epoch 13/30\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.9411 - root_mean_squared_error: 1.3932 - val_loss: 1.9120 - val_root_mean_squared_error: 1.3827\n",
            "Epoch 14/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.9240 - root_mean_squared_error: 1.3871 - val_loss: 1.8948 - val_root_mean_squared_error: 1.3765\n",
            "Epoch 15/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.9067 - root_mean_squared_error: 1.3808 - val_loss: 1.8778 - val_root_mean_squared_error: 1.3703\n",
            "Epoch 16/30\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.8897 - root_mean_squared_error: 1.3747 - val_loss: 1.8609 - val_root_mean_squared_error: 1.3641\n",
            "Epoch 17/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.8728 - root_mean_squared_error: 1.3685 - val_loss: 1.8440 - val_root_mean_squared_error: 1.3579\n",
            "Epoch 18/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.8559 - root_mean_squared_error: 1.3623 - val_loss: 1.8273 - val_root_mean_squared_error: 1.3518\n",
            "Epoch 19/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.8392 - root_mean_squared_error: 1.3562 - val_loss: 1.8107 - val_root_mean_squared_error: 1.3456\n",
            "Epoch 20/30\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.8226 - root_mean_squared_error: 1.3500 - val_loss: 1.7942 - val_root_mean_squared_error: 1.3395\n",
            "Epoch 21/30\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.8061 - root_mean_squared_error: 1.3439 - val_loss: 1.7778 - val_root_mean_squared_error: 1.3333\n",
            "Epoch 22/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.7896 - root_mean_squared_error: 1.3378 - val_loss: 1.7615 - val_root_mean_squared_error: 1.3272\n",
            "Epoch 23/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.7734 - root_mean_squared_error: 1.3317 - val_loss: 1.7453 - val_root_mean_squared_error: 1.3211\n",
            "Epoch 24/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7572 - root_mean_squared_error: 1.3256 - val_loss: 1.7292 - val_root_mean_squared_error: 1.3150\n",
            "Epoch 25/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7410 - root_mean_squared_error: 1.3195 - val_loss: 1.7133 - val_root_mean_squared_error: 1.3089\n",
            "Epoch 26/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7251 - root_mean_squared_error: 1.3134 - val_loss: 1.6974 - val_root_mean_squared_error: 1.3029\n",
            "Epoch 27/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7092 - root_mean_squared_error: 1.3074 - val_loss: 1.6817 - val_root_mean_squared_error: 1.2968\n",
            "Epoch 28/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6935 - root_mean_squared_error: 1.3013 - val_loss: 1.6660 - val_root_mean_squared_error: 1.2907\n",
            "Epoch 29/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6777 - root_mean_squared_error: 1.2953 - val_loss: 1.6504 - val_root_mean_squared_error: 1.2847\n",
            "Epoch 30/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6622 - root_mean_squared_error: 1.2893 - val_loss: 1.6350 - val_root_mean_squared_error: 1.2787\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5198 - root_mean_squared_error: 1.2328\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.5198 - root_mean_squared_error: 1.2328\n",
            "MODEL EVALUATION:  [1.5198121070861816, 1.2328065633773804]\n",
            "Number of epochs: 30 learning rate: 1e-05 Activation Function: sigmoid\n",
            "Model number:  525\n",
            "Epoch 1/30\n",
            "6/6 [==============================] - 1s 57ms/step - loss: 11.7144 - root_mean_squared_error: 0.3529 - val_loss: 11.6943 - val_root_mean_squared_error: 0.3289\n",
            "Epoch 2/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.7057 - root_mean_squared_error: 0.3493 - val_loss: 11.6856 - val_root_mean_squared_error: 0.3250\n",
            "Epoch 3/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.6972 - root_mean_squared_error: 0.3459 - val_loss: 11.6768 - val_root_mean_squared_error: 0.3211\n",
            "Epoch 4/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 11.6885 - root_mean_squared_error: 0.3424 - val_loss: 11.6681 - val_root_mean_squared_error: 0.3172\n",
            "Epoch 5/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.6800 - root_mean_squared_error: 0.3390 - val_loss: 11.6595 - val_root_mean_squared_error: 0.3134\n",
            "Epoch 6/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 11.6715 - root_mean_squared_error: 0.3356 - val_loss: 11.6509 - val_root_mean_squared_error: 0.3096\n",
            "Epoch 7/30\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 11.6630 - root_mean_squared_error: 0.3323 - val_loss: 11.6424 - val_root_mean_squared_error: 0.3059\n",
            "Epoch 8/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 11.6545 - root_mean_squared_error: 0.3290 - val_loss: 11.6339 - val_root_mean_squared_error: 0.3023\n",
            "Epoch 9/30\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 11.6461 - root_mean_squared_error: 0.3257 - val_loss: 11.6255 - val_root_mean_squared_error: 0.2987\n",
            "Epoch 10/30\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 11.6378 - root_mean_squared_error: 0.3226 - val_loss: 11.6171 - val_root_mean_squared_error: 0.2951\n",
            "Epoch 11/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.6295 - root_mean_squared_error: 0.3193 - val_loss: 11.6087 - val_root_mean_squared_error: 0.2916\n",
            "Epoch 12/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.6212 - root_mean_squared_error: 0.3162 - val_loss: 11.6005 - val_root_mean_squared_error: 0.2882\n",
            "Epoch 13/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 11.6129 - root_mean_squared_error: 0.3130 - val_loss: 11.5923 - val_root_mean_squared_error: 0.2849\n",
            "Epoch 14/30\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 11.6048 - root_mean_squared_error: 0.3101 - val_loss: 11.5841 - val_root_mean_squared_error: 0.2815\n",
            "Epoch 15/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 11.5966 - root_mean_squared_error: 0.3071 - val_loss: 11.5759 - val_root_mean_squared_error: 0.2782\n",
            "Epoch 16/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.5884 - root_mean_squared_error: 0.3040 - val_loss: 11.5678 - val_root_mean_squared_error: 0.2750\n",
            "Epoch 17/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.5804 - root_mean_squared_error: 0.3012 - val_loss: 11.5597 - val_root_mean_squared_error: 0.2719\n",
            "Epoch 18/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.5723 - root_mean_squared_error: 0.2983 - val_loss: 11.5517 - val_root_mean_squared_error: 0.2687\n",
            "Epoch 19/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 11.5643 - root_mean_squared_error: 0.2954 - val_loss: 11.5437 - val_root_mean_squared_error: 0.2656\n",
            "Epoch 20/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.5563 - root_mean_squared_error: 0.2927 - val_loss: 11.5357 - val_root_mean_squared_error: 0.2625\n",
            "Epoch 21/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.5483 - root_mean_squared_error: 0.2899 - val_loss: 11.5278 - val_root_mean_squared_error: 0.2596\n",
            "Epoch 22/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.5404 - root_mean_squared_error: 0.2873 - val_loss: 11.5199 - val_root_mean_squared_error: 0.2567\n",
            "Epoch 23/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.5325 - root_mean_squared_error: 0.2847 - val_loss: 11.5120 - val_root_mean_squared_error: 0.2538\n",
            "Epoch 24/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.5246 - root_mean_squared_error: 0.2821 - val_loss: 11.5042 - val_root_mean_squared_error: 0.2511\n",
            "Epoch 25/30\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 11.5168 - root_mean_squared_error: 0.2796 - val_loss: 11.4964 - val_root_mean_squared_error: 0.2483\n",
            "Epoch 26/30\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 11.5090 - root_mean_squared_error: 0.2771 - val_loss: 11.4886 - val_root_mean_squared_error: 0.2457\n",
            "Epoch 27/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 11.5012 - root_mean_squared_error: 0.2746 - val_loss: 11.4809 - val_root_mean_squared_error: 0.2431\n",
            "Epoch 28/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.4934 - root_mean_squared_error: 0.2722 - val_loss: 11.4732 - val_root_mean_squared_error: 0.2406\n",
            "Epoch 29/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.4857 - root_mean_squared_error: 0.2699 - val_loss: 11.4656 - val_root_mean_squared_error: 0.2381\n",
            "Epoch 30/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.4780 - root_mean_squared_error: 0.2676 - val_loss: 11.4579 - val_root_mean_squared_error: 0.2355\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.4441 - root_mean_squared_error: 0.2042\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.4441 - root_mean_squared_error: 0.2042\n",
            "MODEL EVALUATION:  [11.444098472595215, 0.20417118072509766]\n",
            "Number of epochs: 30 learning rate: 1e-05 Activation Function: relu\n",
            "Model number:  526\n",
            "Epoch 1/30\n",
            "6/6 [==============================] - 1s 49ms/step - loss: 1.8500 - root_mean_squared_error: 0.5611 - val_loss: 1.8468 - val_root_mean_squared_error: 0.5588\n",
            "Epoch 2/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.8449 - root_mean_squared_error: 0.5574 - val_loss: 1.8415 - val_root_mean_squared_error: 0.5549\n",
            "Epoch 3/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.8398 - root_mean_squared_error: 0.5537 - val_loss: 1.8362 - val_root_mean_squared_error: 0.5511\n",
            "Epoch 4/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.8350 - root_mean_squared_error: 0.5503 - val_loss: 1.8309 - val_root_mean_squared_error: 0.5472\n",
            "Epoch 5/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.8300 - root_mean_squared_error: 0.5467 - val_loss: 1.8258 - val_root_mean_squared_error: 0.5434\n",
            "Epoch 6/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.8252 - root_mean_squared_error: 0.5433 - val_loss: 1.8207 - val_root_mean_squared_error: 0.5397\n",
            "Epoch 7/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.8205 - root_mean_squared_error: 0.5399 - val_loss: 1.8158 - val_root_mean_squared_error: 0.5361\n",
            "Epoch 8/30\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.8160 - root_mean_squared_error: 0.5366 - val_loss: 1.8109 - val_root_mean_squared_error: 0.5325\n",
            "Epoch 9/30\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.8114 - root_mean_squared_error: 0.5333 - val_loss: 1.8062 - val_root_mean_squared_error: 0.5290\n",
            "Epoch 10/30\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.8070 - root_mean_squared_error: 0.5301 - val_loss: 1.8016 - val_root_mean_squared_error: 0.5256\n",
            "Epoch 11/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.8027 - root_mean_squared_error: 0.5270 - val_loss: 1.7971 - val_root_mean_squared_error: 0.5223\n",
            "Epoch 12/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.7984 - root_mean_squared_error: 0.5239 - val_loss: 1.7927 - val_root_mean_squared_error: 0.5190\n",
            "Epoch 13/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7943 - root_mean_squared_error: 0.5209 - val_loss: 1.7883 - val_root_mean_squared_error: 0.5157\n",
            "Epoch 14/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7901 - root_mean_squared_error: 0.5179 - val_loss: 1.7839 - val_root_mean_squared_error: 0.5125\n",
            "Epoch 15/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.7862 - root_mean_squared_error: 0.5151 - val_loss: 1.7796 - val_root_mean_squared_error: 0.5093\n",
            "Epoch 16/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7821 - root_mean_squared_error: 0.5121 - val_loss: 1.7755 - val_root_mean_squared_error: 0.5062\n",
            "Epoch 17/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.7782 - root_mean_squared_error: 0.5093 - val_loss: 1.7714 - val_root_mean_squared_error: 0.5032\n",
            "Epoch 18/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.7745 - root_mean_squared_error: 0.5066 - val_loss: 1.7674 - val_root_mean_squared_error: 0.5002\n",
            "Epoch 19/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.7707 - root_mean_squared_error: 0.5039 - val_loss: 1.7635 - val_root_mean_squared_error: 0.4973\n",
            "Epoch 20/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.7670 - root_mean_squared_error: 0.5013 - val_loss: 1.7596 - val_root_mean_squared_error: 0.4944\n",
            "Epoch 21/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7634 - root_mean_squared_error: 0.4986 - val_loss: 1.7558 - val_root_mean_squared_error: 0.4916\n",
            "Epoch 22/30\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.7598 - root_mean_squared_error: 0.4961 - val_loss: 1.7520 - val_root_mean_squared_error: 0.4888\n",
            "Epoch 23/30\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.7563 - root_mean_squared_error: 0.4936 - val_loss: 1.7484 - val_root_mean_squared_error: 0.4861\n",
            "Epoch 24/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7528 - root_mean_squared_error: 0.4911 - val_loss: 1.7447 - val_root_mean_squared_error: 0.4834\n",
            "Epoch 25/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7494 - root_mean_squared_error: 0.4887 - val_loss: 1.7412 - val_root_mean_squared_error: 0.4808\n",
            "Epoch 26/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.7461 - root_mean_squared_error: 0.4863 - val_loss: 1.7376 - val_root_mean_squared_error: 0.4782\n",
            "Epoch 27/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.7426 - root_mean_squared_error: 0.4838 - val_loss: 1.7341 - val_root_mean_squared_error: 0.4756\n",
            "Epoch 28/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.7394 - root_mean_squared_error: 0.4815 - val_loss: 1.7307 - val_root_mean_squared_error: 0.4731\n",
            "Epoch 29/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7361 - root_mean_squared_error: 0.4791 - val_loss: 1.7273 - val_root_mean_squared_error: 0.4706\n",
            "Epoch 30/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7328 - root_mean_squared_error: 0.4768 - val_loss: 1.7240 - val_root_mean_squared_error: 0.4681\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.6721 - root_mean_squared_error: 0.4089\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 1.6721 - root_mean_squared_error: 0.4089\n",
            "MODEL EVALUATION:  [1.6720514297485352, 0.40888962149620056]\n",
            "Number of epochs: 30 learning rate: 1e-05 Activation Function: relu\n",
            "Model number:  527\n",
            "Epoch 1/30\n",
            "6/6 [==============================] - 1s 42ms/step - loss: 0.1111 - root_mean_squared_error: 0.3333 - val_loss: 0.0970 - val_root_mean_squared_error: 0.3115\n",
            "Epoch 2/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1084 - root_mean_squared_error: 0.3292 - val_loss: 0.0943 - val_root_mean_squared_error: 0.3071\n",
            "Epoch 3/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1057 - root_mean_squared_error: 0.3252 - val_loss: 0.0917 - val_root_mean_squared_error: 0.3027\n",
            "Epoch 4/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1030 - root_mean_squared_error: 0.3210 - val_loss: 0.0891 - val_root_mean_squared_error: 0.2986\n",
            "Epoch 5/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1005 - root_mean_squared_error: 0.3171 - val_loss: 0.0866 - val_root_mean_squared_error: 0.2943\n",
            "Epoch 6/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0980 - root_mean_squared_error: 0.3131 - val_loss: 0.0842 - val_root_mean_squared_error: 0.2902\n",
            "Epoch 7/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0956 - root_mean_squared_error: 0.3092 - val_loss: 0.0818 - val_root_mean_squared_error: 0.2860\n",
            "Epoch 8/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0932 - root_mean_squared_error: 0.3052 - val_loss: 0.0795 - val_root_mean_squared_error: 0.2820\n",
            "Epoch 9/30\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0909 - root_mean_squared_error: 0.3015 - val_loss: 0.0772 - val_root_mean_squared_error: 0.2779\n",
            "Epoch 10/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0886 - root_mean_squared_error: 0.2977 - val_loss: 0.0750 - val_root_mean_squared_error: 0.2739\n",
            "Epoch 11/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0865 - root_mean_squared_error: 0.2941 - val_loss: 0.0728 - val_root_mean_squared_error: 0.2699\n",
            "Epoch 12/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0843 - root_mean_squared_error: 0.2903 - val_loss: 0.0708 - val_root_mean_squared_error: 0.2660\n",
            "Epoch 13/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0822 - root_mean_squared_error: 0.2868 - val_loss: 0.0687 - val_root_mean_squared_error: 0.2622\n",
            "Epoch 14/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0802 - root_mean_squared_error: 0.2832 - val_loss: 0.0667 - val_root_mean_squared_error: 0.2584\n",
            "Epoch 15/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0782 - root_mean_squared_error: 0.2797 - val_loss: 0.0648 - val_root_mean_squared_error: 0.2546\n",
            "Epoch 16/30\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0763 - root_mean_squared_error: 0.2762 - val_loss: 0.0629 - val_root_mean_squared_error: 0.2508\n",
            "Epoch 17/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0744 - root_mean_squared_error: 0.2728 - val_loss: 0.0611 - val_root_mean_squared_error: 0.2471\n",
            "Epoch 18/30\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0727 - root_mean_squared_error: 0.2696 - val_loss: 0.0592 - val_root_mean_squared_error: 0.2434\n",
            "Epoch 19/30\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0708 - root_mean_squared_error: 0.2661 - val_loss: 0.0575 - val_root_mean_squared_error: 0.2398\n",
            "Epoch 20/30\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0690 - root_mean_squared_error: 0.2627 - val_loss: 0.0559 - val_root_mean_squared_error: 0.2364\n",
            "Epoch 21/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0674 - root_mean_squared_error: 0.2596 - val_loss: 0.0542 - val_root_mean_squared_error: 0.2329\n",
            "Epoch 22/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0658 - root_mean_squared_error: 0.2565 - val_loss: 0.0526 - val_root_mean_squared_error: 0.2294\n",
            "Epoch 23/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0642 - root_mean_squared_error: 0.2534 - val_loss: 0.0511 - val_root_mean_squared_error: 0.2261\n",
            "Epoch 24/30\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0626 - root_mean_squared_error: 0.2502 - val_loss: 0.0497 - val_root_mean_squared_error: 0.2229\n",
            "Epoch 25/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0611 - root_mean_squared_error: 0.2473 - val_loss: 0.0483 - val_root_mean_squared_error: 0.2197\n",
            "Epoch 26/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0597 - root_mean_squared_error: 0.2443 - val_loss: 0.0469 - val_root_mean_squared_error: 0.2165\n",
            "Epoch 27/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0583 - root_mean_squared_error: 0.2414 - val_loss: 0.0455 - val_root_mean_squared_error: 0.2133\n",
            "Epoch 28/30\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0568 - root_mean_squared_error: 0.2384 - val_loss: 0.0442 - val_root_mean_squared_error: 0.2103\n",
            "Epoch 29/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0555 - root_mean_squared_error: 0.2356 - val_loss: 0.0429 - val_root_mean_squared_error: 0.2072\n",
            "Epoch 30/30\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0542 - root_mean_squared_error: 0.2328 - val_loss: 0.0417 - val_root_mean_squared_error: 0.2042\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0274 - root_mean_squared_error: 0.1654\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0274 - root_mean_squared_error: 0.1654\n",
            "MODEL EVALUATION:  [0.027365468442440033, 0.165425106883049]\n",
            "Number of epochs: 30 learning rate: 1e-05 Activation Function: relu\n",
            "Model number:  528\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 46ms/step - loss: 188.0850 - root_mean_squared_error: 9.0318 - val_loss: 149.0090 - val_root_mean_squared_error: 2.3752\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 164.6745 - root_mean_squared_error: 4.0125 - val_loss: 170.8513 - val_root_mean_squared_error: 4.6773\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 157.7772 - root_mean_squared_error: 3.1617 - val_loss: 144.5795 - val_root_mean_squared_error: 0.5113\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 139.8414 - root_mean_squared_error: 0.8617 - val_loss: 127.8545 - val_root_mean_squared_error: 0.4220\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 127.4462 - root_mean_squared_error: 2.1534 - val_loss: 115.1170 - val_root_mean_squared_error: 0.2268\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 109.0835 - root_mean_squared_error: 0.8598 - val_loss: 99.1686 - val_root_mean_squared_error: 0.8476\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 92.0134 - root_mean_squared_error: 0.7501 - val_loss: 80.3131 - val_root_mean_squared_error: 0.5478\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 74.2611 - root_mean_squared_error: 0.7786 - val_loss: 65.6108 - val_root_mean_squared_error: 0.3201\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 61.9242 - root_mean_squared_error: 0.9698 - val_loss: 57.1958 - val_root_mean_squared_error: 1.5787\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 53.0709 - root_mean_squared_error: 1.2480 - val_loss: 47.1310 - val_root_mean_squared_error: 0.2399\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 45.9626 - root_mean_squared_error: 0.2556 - val_loss: 45.1103 - val_root_mean_squared_error: 1.0348\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 44.4096 - root_mean_squared_error: 0.6882 - val_loss: 44.0213 - val_root_mean_squared_error: 0.9603\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 41.9817 - root_mean_squared_error: 0.6214 - val_loss: 38.8552 - val_root_mean_squared_error: 0.1725\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 37.8621 - root_mean_squared_error: 0.2982 - val_loss: 36.0869 - val_root_mean_squared_error: 0.1766\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 34.7072 - root_mean_squared_error: 0.1909 - val_loss: 32.2585 - val_root_mean_squared_error: 0.1725\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 31.1861 - root_mean_squared_error: 0.1910 - val_loss: 29.4492 - val_root_mean_squared_error: 0.2163\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 28.2166 - root_mean_squared_error: 0.2416 - val_loss: 26.5586 - val_root_mean_squared_error: 0.2032\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 26.3353 - root_mean_squared_error: 0.4806 - val_loss: 25.7359 - val_root_mean_squared_error: 0.3012\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 25.1002 - root_mean_squared_error: 0.2755 - val_loss: 23.8840 - val_root_mean_squared_error: 0.2328\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 23.4352 - root_mean_squared_error: 0.2870 - val_loss: 22.3618 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 21.5098 - root_mean_squared_error: 0.2108 - val_loss: 20.1971 - val_root_mean_squared_error: 0.1962\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 19.6123 - root_mean_squared_error: 0.2042 - val_loss: 18.5541 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 18.1751 - root_mean_squared_error: 0.3171 - val_loss: 17.4456 - val_root_mean_squared_error: 0.1710\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 17.2204 - root_mean_squared_error: 0.1958 - val_loss: 16.7034 - val_root_mean_squared_error: 0.1733\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 16.3265 - root_mean_squared_error: 0.2613 - val_loss: 15.5625 - val_root_mean_squared_error: 0.2062\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 15.2174 - root_mean_squared_error: 0.2435 - val_loss: 14.8076 - val_root_mean_squared_error: 0.3904\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.3433 - root_mean_squared_error: 0.2452 - val_loss: 13.8034 - val_root_mean_squared_error: 0.1773\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 13.7573 - root_mean_squared_error: 0.3551 - val_loss: 13.7000 - val_root_mean_squared_error: 0.3699\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.0368 - root_mean_squared_error: 0.6714 - val_loss: 14.3017 - val_root_mean_squared_error: 0.8643\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.2543 - root_mean_squared_error: 0.5931 - val_loss: 14.1462 - val_root_mean_squared_error: 0.5261\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 13.8847 - root_mean_squared_error: 0.3238 - val_loss: 13.7073 - val_root_mean_squared_error: 0.1711\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 13.6966 - root_mean_squared_error: 0.2430 - val_loss: 13.5847 - val_root_mean_squared_error: 0.2666\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 13.3349 - root_mean_squared_error: 0.2966 - val_loss: 13.2494 - val_root_mean_squared_error: 0.4538\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 13.3358 - root_mean_squared_error: 0.3415 - val_loss: 13.2253 - val_root_mean_squared_error: 0.3179\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 13.1572 - root_mean_squared_error: 0.2564 - val_loss: 12.7670 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 12.8386 - root_mean_squared_error: 0.3267 - val_loss: 12.8784 - val_root_mean_squared_error: 0.4308\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 12.8011 - root_mean_squared_error: 0.4460 - val_loss: 12.4289 - val_root_mean_squared_error: 0.2636\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 12.7730 - root_mean_squared_error: 0.5188 - val_loss: 12.7313 - val_root_mean_squared_error: 0.2674\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 12.6899 - root_mean_squared_error: 0.4111 - val_loss: 12.4710 - val_root_mean_squared_error: 0.4529\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 12.5651 - root_mean_squared_error: 0.3299 - val_loss: 12.5629 - val_root_mean_squared_error: 0.2639\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.5692 - root_mean_squared_error: 0.2756\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 12.5692 - root_mean_squared_error: 0.2756\n",
            "MODEL EVALUATION:  [12.569160461425781, 0.27560925483703613]\n",
            "Number of epochs: 40 learning rate: 1 Activation Function: sigmoid\n",
            "Model number:  529\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 49ms/step - loss: 149.6459 - root_mean_squared_error: 9.5400 - val_loss: 77.2401 - val_root_mean_squared_error: 4.4863\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 98.2007 - root_mean_squared_error: 6.5307 - val_loss: 115.0717 - val_root_mean_squared_error: 5.4382\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 115.6540 - root_mean_squared_error: 3.1629 - val_loss: 119.9665 - val_root_mean_squared_error: 0.6718\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 121.4018 - root_mean_squared_error: 1.4996 - val_loss: 121.4717 - val_root_mean_squared_error: 2.1912\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 116.8130 - root_mean_squared_error: 1.9151 - val_loss: 102.7679 - val_root_mean_squared_error: 0.1898\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 108.2836 - root_mean_squared_error: 3.2920 - val_loss: 106.4379 - val_root_mean_squared_error: 2.7639\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 104.3257 - root_mean_squared_error: 2.5309 - val_loss: 104.7051 - val_root_mean_squared_error: 0.8500\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 124.5918 - root_mean_squared_error: 1.4450 - val_loss: 146.0011 - val_root_mean_squared_error: 0.2262\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 144.2501 - root_mean_squared_error: 1.0121 - val_loss: 129.1936 - val_root_mean_squared_error: 0.2866\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 119.9570 - root_mean_squared_error: 0.9360 - val_loss: 110.2407 - val_root_mean_squared_error: 2.5404\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 101.2909 - root_mean_squared_error: 1.7997 - val_loss: 120.4399 - val_root_mean_squared_error: 5.8615\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 86.5049 - root_mean_squared_error: 2.7964 - val_loss: 71.8607 - val_root_mean_squared_error: 2.3464\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 68.6807 - root_mean_squared_error: 1.8594 - val_loss: 62.9669 - val_root_mean_squared_error: 1.8985\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 52.0031 - root_mean_squared_error: 1.1586 - val_loss: 41.9381 - val_root_mean_squared_error: 0.1711\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 42.9994 - root_mean_squared_error: 2.1309 - val_loss: 54.6666 - val_root_mean_squared_error: 4.3100\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 45.1085 - root_mean_squared_error: 3.0355 - val_loss: 36.4683 - val_root_mean_squared_error: 1.8905\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 34.8681 - root_mean_squared_error: 2.1891 - val_loss: 26.9905 - val_root_mean_squared_error: 0.6107\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 23.6443 - root_mean_squared_error: 0.5077 - val_loss: 33.0382 - val_root_mean_squared_error: 3.8243\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.8334 - root_mean_squared_error: 2.4098 - val_loss: 17.5847 - val_root_mean_squared_error: 1.3669\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 26.6611 - root_mean_squared_error: 1.9148 - val_loss: 48.3709 - val_root_mean_squared_error: 3.8047\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 41.1633 - root_mean_squared_error: 2.3264 - val_loss: 39.1988 - val_root_mean_squared_error: 2.0265\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 34.3508 - root_mean_squared_error: 1.4531 - val_loss: 29.8374 - val_root_mean_squared_error: 1.2210\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 29.4049 - root_mean_squared_error: 1.6253 - val_loss: 29.2015 - val_root_mean_squared_error: 2.1965\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 25.0448 - root_mean_squared_error: 1.5268 - val_loss: 20.1739 - val_root_mean_squared_error: 0.1875\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 19.3307 - root_mean_squared_error: 0.5841 - val_loss: 17.4457 - val_root_mean_squared_error: 0.2643\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 17.0975 - root_mean_squared_error: 0.2368 - val_loss: 15.7141 - val_root_mean_squared_error: 0.1832\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.1316 - root_mean_squared_error: 0.4772 - val_loss: 10.2095 - val_root_mean_squared_error: 0.3155\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 8.1321 - root_mean_squared_error: 0.2593 - val_loss: 6.0184 - val_root_mean_squared_error: 0.6606\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.5299 - root_mean_squared_error: 0.5573 - val_loss: 6.1840 - val_root_mean_squared_error: 1.1001\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.4878 - root_mean_squared_error: 0.7985 - val_loss: 4.0954 - val_root_mean_squared_error: 0.1954\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.3230 - root_mean_squared_error: 0.3520 - val_loss: 2.1770 - val_root_mean_squared_error: 0.3389\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7859 - root_mean_squared_error: 0.3058 - val_loss: 1.3683 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.2109 - root_mean_squared_error: 0.7090 - val_loss: 17.8952 - val_root_mean_squared_error: 0.3770\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 13.6434 - root_mean_squared_error: 0.5092 - val_loss: 7.5500 - val_root_mean_squared_error: 0.2333\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 7.6655 - root_mean_squared_error: 0.2318 - val_loss: 5.9525 - val_root_mean_squared_error: 0.2899\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.4448 - root_mean_squared_error: 0.2551 - val_loss: 2.7711 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.0625 - root_mean_squared_error: 0.2430 - val_loss: 1.0633 - val_root_mean_squared_error: 0.2065\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.0705 - root_mean_squared_error: 0.2036 - val_loss: 0.9989 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.7012 - root_mean_squared_error: 0.8242 - val_loss: 5.8255 - val_root_mean_squared_error: 0.1706\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.6173 - root_mean_squared_error: 0.3491 - val_loss: 11.7352 - val_root_mean_squared_error: 0.3744\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.6975 - root_mean_squared_error: 0.3201\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.6975 - root_mean_squared_error: 0.3201\n",
            "MODEL EVALUATION:  [11.697490692138672, 0.32013681530952454]\n",
            "Number of epochs: 40 learning rate: 1 Activation Function: sigmoid\n",
            "Model number:  530\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 52ms/step - loss: 158.6174 - root_mean_squared_error: 12.5943 - val_loss: 130.8994 - val_root_mean_squared_error: 11.4411\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 67.5245 - root_mean_squared_error: 8.2173 - val_loss: 66.2925 - val_root_mean_squared_error: 8.1420\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 32.0896 - root_mean_squared_error: 5.6648 - val_loss: 43.4282 - val_root_mean_squared_error: 6.5900\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 18.2327 - root_mean_squared_error: 4.2700 - val_loss: 26.7193 - val_root_mean_squared_error: 5.1691\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.6691 - root_mean_squared_error: 3.2664 - val_loss: 15.2534 - val_root_mean_squared_error: 3.9056\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 6.2637 - root_mean_squared_error: 2.5027 - val_loss: 8.4884 - val_root_mean_squared_error: 2.9135\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.4767 - root_mean_squared_error: 1.8646 - val_loss: 4.6360 - val_root_mean_squared_error: 2.1531\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 2.0284 - root_mean_squared_error: 1.4242 - val_loss: 2.2772 - val_root_mean_squared_error: 1.5090\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.1468 - root_mean_squared_error: 1.0709 - val_loss: 0.8489 - val_root_mean_squared_error: 0.9214\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5772 - root_mean_squared_error: 0.7597 - val_loss: 0.1959 - val_root_mean_squared_error: 0.4426\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3264 - root_mean_squared_error: 0.5713 - val_loss: 0.0299 - val_root_mean_squared_error: 0.1728\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1830 - root_mean_squared_error: 0.4278 - val_loss: 0.1038 - val_root_mean_squared_error: 0.3221\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1323 - root_mean_squared_error: 0.3637 - val_loss: 0.1594 - val_root_mean_squared_error: 0.3992\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1209 - root_mean_squared_error: 0.3477 - val_loss: 0.0576 - val_root_mean_squared_error: 0.2399\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0517 - root_mean_squared_error: 0.2274 - val_loss: 0.0302 - val_root_mean_squared_error: 0.1738\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0530 - root_mean_squared_error: 0.2303 - val_loss: 0.0474 - val_root_mean_squared_error: 0.2177\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0486 - root_mean_squared_error: 0.2205 - val_loss: 0.0412 - val_root_mean_squared_error: 0.2030\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0428 - root_mean_squared_error: 0.2069 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1706\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0405 - root_mean_squared_error: 0.2013 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1837\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0363 - root_mean_squared_error: 0.1904 - val_loss: 0.0293 - val_root_mean_squared_error: 0.1712\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0353 - root_mean_squared_error: 0.1879 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0342 - root_mean_squared_error: 0.1848 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1716\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0346 - root_mean_squared_error: 0.1859 - val_loss: 0.0310 - val_root_mean_squared_error: 0.1761\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0379 - root_mean_squared_error: 0.1946 - val_loss: 0.0309 - val_root_mean_squared_error: 0.1759\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0356 - root_mean_squared_error: 0.1887 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1708\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0348 - root_mean_squared_error: 0.1865 - val_loss: 0.0301 - val_root_mean_squared_error: 0.1735\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0355 - root_mean_squared_error: 0.1883 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0343 - root_mean_squared_error: 0.1851 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0347 - root_mean_squared_error: 0.1863 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0340 - root_mean_squared_error: 0.1843 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1708\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0363 - root_mean_squared_error: 0.1904 - val_loss: 0.0297 - val_root_mean_squared_error: 0.1724\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0352 - root_mean_squared_error: 0.1877 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0398 - root_mean_squared_error: 0.1996 - val_loss: 0.0356 - val_root_mean_squared_error: 0.1887\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0386 - root_mean_squared_error: 0.1966 - val_loss: 0.0371 - val_root_mean_squared_error: 0.1926\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0396 - root_mean_squared_error: 0.1990 - val_loss: 0.0300 - val_root_mean_squared_error: 0.1733\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0359 - root_mean_squared_error: 0.1894 - val_loss: 0.0302 - val_root_mean_squared_error: 0.1737\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0343 - root_mean_squared_error: 0.1851 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0353 - root_mean_squared_error: 0.1879 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0347 - root_mean_squared_error: 0.1863 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0351 - root_mean_squared_error: 0.1872 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1747\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0235 - root_mean_squared_error: 0.1534\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0235 - root_mean_squared_error: 0.1534\n",
            "MODEL EVALUATION:  [0.02352888323366642, 0.1533912718296051]\n",
            "Number of epochs: 40 learning rate: 1 Activation Function: sigmoid\n",
            "Model number:  531\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 46ms/step - loss: 16283442.0000 - root_mean_squared_error: 4035.2639 - val_loss: 165.9117 - val_root_mean_squared_error: 6.4530\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 16200.5693 - root_mean_squared_error: 126.7018 - val_loss: 6000.6001 - val_root_mean_squared_error: 76.2952\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1277.8856 - root_mean_squared_error: 32.8242 - val_loss: 386.8076 - val_root_mean_squared_error: 12.8684\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 634.7429 - root_mean_squared_error: 19.9963 - val_loss: 259.6060 - val_root_mean_squared_error: 3.6698\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 354.4977 - root_mean_squared_error: 10.0755 - val_loss: 266.8775 - val_root_mean_squared_error: 2.6629\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 303.9563 - root_mean_squared_error: 6.3205 - val_loss: 276.8556 - val_root_mean_squared_error: 2.7641\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 279.0272 - root_mean_squared_error: 2.7937 - val_loss: 280.3229 - val_root_mean_squared_error: 2.8166\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 281.2862 - root_mean_squared_error: 2.8338 - val_loss: 282.3384 - val_root_mean_squared_error: 2.8407\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 283.6713 - root_mean_squared_error: 2.8507 - val_loss: 284.6927 - val_root_mean_squared_error: 2.8481\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 285.4168 - root_mean_squared_error: 2.8538 - val_loss: 284.7395 - val_root_mean_squared_error: 2.8457\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 284.5913 - root_mean_squared_error: 2.8489 - val_loss: 284.4916 - val_root_mean_squared_error: 2.8375\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 284.7929 - root_mean_squared_error: 2.8392 - val_loss: 285.1390 - val_root_mean_squared_error: 2.8258\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 285.0123 - root_mean_squared_error: 2.8266 - val_loss: 284.5630 - val_root_mean_squared_error: 2.8119\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 284.2592 - root_mean_squared_error: 2.8120 - val_loss: 283.8278 - val_root_mean_squared_error: 2.7964\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 284.2798 - root_mean_squared_error: 2.7962 - val_loss: 284.4794 - val_root_mean_squared_error: 2.7800\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 288.0102 - root_mean_squared_error: 3.3821 - val_loss: 283.7720 - val_root_mean_squared_error: 2.7625\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 283.5349 - root_mean_squared_error: 2.7612 - val_loss: 283.6553 - val_root_mean_squared_error: 2.7436\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 283.8920 - root_mean_squared_error: 2.7423 - val_loss: 284.1372 - val_root_mean_squared_error: 2.7246\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 284.0328 - root_mean_squared_error: 2.7232 - val_loss: 282.9019 - val_root_mean_squared_error: 2.7054\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 282.7732 - root_mean_squared_error: 2.7040 - val_loss: 282.6740 - val_root_mean_squared_error: 2.6859\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 283.0441 - root_mean_squared_error: 2.6843 - val_loss: 283.5712 - val_root_mean_squared_error: 2.6662\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 283.2755 - root_mean_squared_error: 2.6645 - val_loss: 282.3001 - val_root_mean_squared_error: 2.6461\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 282.1565 - root_mean_squared_error: 2.6443 - val_loss: 281.9124 - val_root_mean_squared_error: 2.6256\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 282.1248 - root_mean_squared_error: 2.6237 - val_loss: 282.0417 - val_root_mean_squared_error: 2.6049\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 282.1227 - root_mean_squared_error: 2.6029 - val_loss: 281.3422 - val_root_mean_squared_error: 2.5839\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 281.1723 - root_mean_squared_error: 2.5818 - val_loss: 281.3472 - val_root_mean_squared_error: 2.5626\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 281.2007 - root_mean_squared_error: 2.5603 - val_loss: 281.4711 - val_root_mean_squared_error: 2.5410\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 281.3113 - root_mean_squared_error: 2.5387 - val_loss: 280.3500 - val_root_mean_squared_error: 2.5192\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 280.2279 - root_mean_squared_error: 2.5168 - val_loss: 279.7979 - val_root_mean_squared_error: 2.4971\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 280.1456 - root_mean_squared_error: 2.4946 - val_loss: 280.1439 - val_root_mean_squared_error: 2.4748\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 280.1991 - root_mean_squared_error: 2.4723 - val_loss: 279.4819 - val_root_mean_squared_error: 2.4523\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 279.2733 - root_mean_squared_error: 2.4497 - val_loss: 279.4937 - val_root_mean_squared_error: 2.4296\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 279.6191 - root_mean_squared_error: 2.4269 - val_loss: 279.6322 - val_root_mean_squared_error: 2.4067\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 279.3740 - root_mean_squared_error: 2.4040 - val_loss: 277.8088 - val_root_mean_squared_error: 2.3837\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 277.9658 - root_mean_squared_error: 2.3808 - val_loss: 277.8917 - val_root_mean_squared_error: 2.3605\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 278.3519 - root_mean_squared_error: 2.3577 - val_loss: 279.0201 - val_root_mean_squared_error: 2.3372\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 278.9628 - root_mean_squared_error: 2.3343 - val_loss: 278.2666 - val_root_mean_squared_error: 2.3137\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 277.6429 - root_mean_squared_error: 2.3107 - val_loss: 277.1626 - val_root_mean_squared_error: 2.2901\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 277.3127 - root_mean_squared_error: 2.2872 - val_loss: 277.4202 - val_root_mean_squared_error: 2.2665\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 277.5856 - root_mean_squared_error: 2.2634 - val_loss: 277.0253 - val_root_mean_squared_error: 2.2427\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 276.8313 - root_mean_squared_error: 2.1990\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 276.8313 - root_mean_squared_error: 2.1990\n",
            "MODEL EVALUATION:  [276.831298828125, 2.199028253555298]\n",
            "Number of epochs: 40 learning rate: 1 Activation Function: relu\n",
            "Model number:  532\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 45ms/step - loss: 75498904.0000 - root_mean_squared_error: 8689.0039 - val_loss: 198247.0312 - val_root_mean_squared_error: 444.9091\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 32409848.0000 - root_mean_squared_error: 5692.9214 - val_loss: 344483.6875 - val_root_mean_squared_error: 586.2783\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 171804.0938 - root_mean_squared_error: 413.3715 - val_loss: 1178.1610 - val_root_mean_squared_error: 4.3616\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1300.2024 - root_mean_squared_error: 4.7189 - val_loss: 1462.3470 - val_root_mean_squared_error: 5.1541\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1539.7275 - root_mean_squared_error: 5.3582 - val_loss: 1640.9146 - val_root_mean_squared_error: 5.6029\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1687.1970 - root_mean_squared_error: 5.7201 - val_loss: 1747.1024 - val_root_mean_squared_error: 5.8556\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1773.7987 - root_mean_squared_error: 5.9230 - val_loss: 1807.9434 - val_root_mean_squared_error: 5.9953\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2001.9088 - root_mean_squared_error: 14.6906 - val_loss: 1840.9344 - val_root_mean_squared_error: 6.0705\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1848.8676 - root_mean_squared_error: 6.0930 - val_loss: 1858.6184 - val_root_mean_squared_error: 6.1078\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1862.6566 - root_mean_squared_error: 6.1208 - val_loss: 1867.3601 - val_root_mean_squared_error: 6.1233\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1869.1638 - root_mean_squared_error: 6.1308 - val_loss: 1870.9995 - val_root_mean_squared_error: 6.1262\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1871.5391 - root_mean_squared_error: 6.1305 - val_loss: 1871.7646 - val_root_mean_squared_error: 6.1218\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1871.6046 - root_mean_squared_error: 6.1243 - val_loss: 1870.9402 - val_root_mean_squared_error: 6.1130\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1870.4011 - root_mean_squared_error: 6.1144 - val_loss: 1869.2582 - val_root_mean_squared_error: 6.1017\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1868.5167 - root_mean_squared_error: 6.1023 - val_loss: 1867.1222 - val_root_mean_squared_error: 6.0887\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1866.2787 - root_mean_squared_error: 6.0889 - val_loss: 1864.7595 - val_root_mean_squared_error: 6.0745\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1863.8679 - root_mean_squared_error: 6.0744 - val_loss: 1862.2933 - val_root_mean_squared_error: 6.0596\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1861.3833 - root_mean_squared_error: 6.0592 - val_loss: 1859.7899 - val_root_mean_squared_error: 6.0440\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1858.8771 - root_mean_squared_error: 6.0433 - val_loss: 1857.2853 - val_root_mean_squared_error: 6.0278\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1856.3774 - root_mean_squared_error: 6.0270 - val_loss: 1854.7975 - val_root_mean_squared_error: 6.0112\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1853.8995 - root_mean_squared_error: 6.0102 - val_loss: 1852.3356 - val_root_mean_squared_error: 5.9942\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1851.4492 - root_mean_squared_error: 5.9930 - val_loss: 1849.9043 - val_root_mean_squared_error: 5.9767\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1849.0300 - root_mean_squared_error: 5.9754 - val_loss: 1847.5049 - val_root_mean_squared_error: 5.9589\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1846.6432 - root_mean_squared_error: 5.9574 - val_loss: 1845.1378 - val_root_mean_squared_error: 5.9407\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1844.2882 - root_mean_squared_error: 5.9391 - val_loss: 1842.8027 - val_root_mean_squared_error: 5.9221\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1841.9653 - root_mean_squared_error: 5.9204 - val_loss: 1840.4984 - val_root_mean_squared_error: 5.9032\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1839.6729 - root_mean_squared_error: 5.9013 - val_loss: 1838.2246 - val_root_mean_squared_error: 5.8839\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1837.4104 - root_mean_squared_error: 5.8819 - val_loss: 1835.9802 - val_root_mean_squared_error: 5.8643\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1835.1771 - root_mean_squared_error: 5.8622 - val_loss: 1833.7645 - val_root_mean_squared_error: 5.8444\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1832.9720 - root_mean_squared_error: 5.8422 - val_loss: 1831.5765 - val_root_mean_squared_error: 5.8242\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1830.7942 - root_mean_squared_error: 5.8219 - val_loss: 1829.4156 - val_root_mean_squared_error: 5.8037\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1828.6437 - root_mean_squared_error: 5.8013 - val_loss: 1827.2810 - val_root_mean_squared_error: 5.7829\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1826.5187 - root_mean_squared_error: 5.7804 - val_loss: 1825.1714 - val_root_mean_squared_error: 5.7619\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1824.4188 - root_mean_squared_error: 5.7592 - val_loss: 1823.0868 - val_root_mean_squared_error: 5.7405\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1822.3433 - root_mean_squared_error: 5.7377 - val_loss: 1821.0264 - val_root_mean_squared_error: 5.7189\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1820.2917 - root_mean_squared_error: 5.7160 - val_loss: 1818.9894 - val_root_mean_squared_error: 5.6970\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1818.2637 - root_mean_squared_error: 5.6940 - val_loss: 1816.9750 - val_root_mean_squared_error: 5.6748\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1816.2579 - root_mean_squared_error: 5.6717 - val_loss: 1814.9832 - val_root_mean_squared_error: 5.6524\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1814.2743 - root_mean_squared_error: 5.6492 - val_loss: 1813.0127 - val_root_mean_squared_error: 5.6297\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1812.3121 - root_mean_squared_error: 5.6265 - val_loss: 1811.0642 - val_root_mean_squared_error: 5.6068\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1810.5935 - root_mean_squared_error: 5.5647\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1810.5935 - root_mean_squared_error: 5.5647\n",
            "MODEL EVALUATION:  [1810.593505859375, 5.564717769622803]\n",
            "Number of epochs: 40 learning rate: 1 Activation Function: relu\n",
            "Model number:  533\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 44ms/step - loss: 207357280.0000 - root_mean_squared_error: 14399.9053 - val_loss: 3.7026 - val_root_mean_squared_error: 1.9242\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 6.5221 - root_mean_squared_error: 2.5538 - val_loss: 10.5791 - val_root_mean_squared_error: 3.2525\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 12.7780 - root_mean_squared_error: 3.5746 - val_loss: 15.6389 - val_root_mean_squared_error: 3.9546\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 17.0890 - root_mean_squared_error: 4.1339 - val_loss: 18.8971 - val_root_mean_squared_error: 4.3471\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 19.8074 - root_mean_squared_error: 4.4506 - val_loss: 20.8754 - val_root_mean_squared_error: 4.5690\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 21.4318 - root_mean_squared_error: 4.6294 - val_loss: 22.0289 - val_root_mean_squared_error: 4.6935\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 22.3681 - root_mean_squared_error: 4.7295 - val_loss: 22.6760 - val_root_mean_squared_error: 4.7619\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 22.8838 - root_mean_squared_error: 4.7837 - val_loss: 23.0206 - val_root_mean_squared_error: 4.7980\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 23.1520 - root_mean_squared_error: 4.8116 - val_loss: 23.1877 - val_root_mean_squared_error: 4.8154\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 23.2743 - root_mean_squared_error: 4.8243 - val_loss: 23.2515 - val_root_mean_squared_error: 4.8220\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 23.3121 - root_mean_squared_error: 4.8283 - val_loss: 23.2555 - val_root_mean_squared_error: 4.8224\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 23.3007 - root_mean_squared_error: 4.8271 - val_loss: 23.2244 - val_root_mean_squared_error: 4.8192\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 23.2606 - root_mean_squared_error: 4.8229 - val_loss: 23.1723 - val_root_mean_squared_error: 4.8138\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 23.2030 - root_mean_squared_error: 4.8170 - val_loss: 23.1076 - val_root_mean_squared_error: 4.8070\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 23.1348 - root_mean_squared_error: 4.8099 - val_loss: 23.0347 - val_root_mean_squared_error: 4.7994\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 23.0594 - root_mean_squared_error: 4.8020 - val_loss: 22.9561 - val_root_mean_squared_error: 4.7913\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 22.9790 - root_mean_squared_error: 4.7936 - val_loss: 22.8735 - val_root_mean_squared_error: 4.7826\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 22.8951 - root_mean_squared_error: 4.7849 - val_loss: 22.7876 - val_root_mean_squared_error: 4.7736\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 22.8080 - root_mean_squared_error: 4.7758 - val_loss: 22.6988 - val_root_mean_squared_error: 4.7643\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 22.7181 - root_mean_squared_error: 4.7664 - val_loss: 22.6078 - val_root_mean_squared_error: 4.7548\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 22.6260 - root_mean_squared_error: 4.7567 - val_loss: 22.5146 - val_root_mean_squared_error: 4.7450\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 22.5319 - root_mean_squared_error: 4.7468 - val_loss: 22.4192 - val_root_mean_squared_error: 4.7349\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 22.4356 - root_mean_squared_error: 4.7366 - val_loss: 22.3218 - val_root_mean_squared_error: 4.7246\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 22.3373 - root_mean_squared_error: 4.7262 - val_loss: 22.2225 - val_root_mean_squared_error: 4.7141\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 22.2373 - root_mean_squared_error: 4.7156 - val_loss: 22.1215 - val_root_mean_squared_error: 4.7033\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 22.1355 - root_mean_squared_error: 4.7048 - val_loss: 22.0186 - val_root_mean_squared_error: 4.6924\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 22.0318 - root_mean_squared_error: 4.6938 - val_loss: 21.9142 - val_root_mean_squared_error: 4.6813\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 21.9268 - root_mean_squared_error: 4.6826 - val_loss: 21.8081 - val_root_mean_squared_error: 4.6699\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 21.8199 - root_mean_squared_error: 4.6712 - val_loss: 21.7005 - val_root_mean_squared_error: 4.6584\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 21.7114 - root_mean_squared_error: 4.6595 - val_loss: 21.5914 - val_root_mean_squared_error: 4.6467\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 21.6017 - root_mean_squared_error: 4.6478 - val_loss: 21.4808 - val_root_mean_squared_error: 4.6347\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 21.4904 - root_mean_squared_error: 4.6358 - val_loss: 21.3688 - val_root_mean_squared_error: 4.6226\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 21.3778 - root_mean_squared_error: 4.6236 - val_loss: 21.2555 - val_root_mean_squared_error: 4.6104\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 21.2638 - root_mean_squared_error: 4.6113 - val_loss: 21.1409 - val_root_mean_squared_error: 4.5979\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 21.1486 - root_mean_squared_error: 4.5988 - val_loss: 21.0251 - val_root_mean_squared_error: 4.5853\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 21.0321 - root_mean_squared_error: 4.5861 - val_loss: 20.9081 - val_root_mean_squared_error: 4.5725\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 20.9146 - root_mean_squared_error: 4.5733 - val_loss: 20.7899 - val_root_mean_squared_error: 4.5596\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 20.7958 - root_mean_squared_error: 4.5602 - val_loss: 20.6705 - val_root_mean_squared_error: 4.5465\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 20.6758 - root_mean_squared_error: 4.5471 - val_loss: 20.5501 - val_root_mean_squared_error: 4.5332\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 20.5549 - root_mean_squared_error: 4.5338 - val_loss: 20.4286 - val_root_mean_squared_error: 4.5198\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 20.0473 - root_mean_squared_error: 4.4774\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 20.0473 - root_mean_squared_error: 4.4774\n",
            "MODEL EVALUATION:  [20.047300338745117, 4.477421283721924]\n",
            "Number of epochs: 40 learning rate: 1 Activation Function: relu\n",
            "Model number:  534\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 49ms/step - loss: 37.8920 - root_mean_squared_error: 2.9563 - val_loss: 30.4878 - val_root_mean_squared_error: 1.6573\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 25.7651 - root_mean_squared_error: 1.0418 - val_loss: 20.1310 - val_root_mean_squared_error: 0.2480\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 17.0020 - root_mean_squared_error: 0.3119 - val_loss: 18.1121 - val_root_mean_squared_error: 2.1842\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 22.1881 - root_mean_squared_error: 1.7279 - val_loss: 26.3671 - val_root_mean_squared_error: 0.6287\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 27.9106 - root_mean_squared_error: 0.5625 - val_loss: 27.5774 - val_root_mean_squared_error: 0.7549\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 25.3465 - root_mean_squared_error: 0.5974 - val_loss: 21.4110 - val_root_mean_squared_error: 0.2144\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 19.0237 - root_mean_squared_error: 0.2025 - val_loss: 15.3772 - val_root_mean_squared_error: 0.1744\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 13.7190 - root_mean_squared_error: 0.1974 - val_loss: 11.5507 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.6468 - root_mean_squared_error: 0.2181 - val_loss: 9.2948 - val_root_mean_squared_error: 0.3293\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 8.4514 - root_mean_squared_error: 0.2591 - val_loss: 7.2487 - val_root_mean_squared_error: 0.2424\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.7122 - root_mean_squared_error: 0.2212 - val_loss: 6.0343 - val_root_mean_squared_error: 0.2066\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.8782 - root_mean_squared_error: 0.3760 - val_loss: 5.6563 - val_root_mean_squared_error: 0.3219\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.4424 - root_mean_squared_error: 0.2412 - val_loss: 5.0652 - val_root_mean_squared_error: 0.2124\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.9574 - root_mean_squared_error: 0.2019 - val_loss: 4.7363 - val_root_mean_squared_error: 0.1934\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.5693 - root_mean_squared_error: 0.2083 - val_loss: 4.3222 - val_root_mean_squared_error: 0.2037\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 4.1852 - root_mean_squared_error: 0.1952 - val_loss: 3.9866 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.8956 - root_mean_squared_error: 0.1889 - val_loss: 3.7226 - val_root_mean_squared_error: 0.1735\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 3.6907 - root_mean_squared_error: 0.1915 - val_loss: 3.6257 - val_root_mean_squared_error: 0.1735\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.6530 - root_mean_squared_error: 0.1873 - val_loss: 3.6601 - val_root_mean_squared_error: 0.2264\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.7872 - root_mean_squared_error: 0.3618 - val_loss: 3.7369 - val_root_mean_squared_error: 0.1947\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.8332 - root_mean_squared_error: 0.2597 - val_loss: 3.8493 - val_root_mean_squared_error: 0.2829\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.8226 - root_mean_squared_error: 0.2352 - val_loss: 3.7899 - val_root_mean_squared_error: 0.2258\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.7263 - root_mean_squared_error: 0.2191 - val_loss: 3.6490 - val_root_mean_squared_error: 0.2835\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.6524 - root_mean_squared_error: 0.2529 - val_loss: 3.6554 - val_root_mean_squared_error: 0.1714\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.6387 - root_mean_squared_error: 0.1958 - val_loss: 3.5993 - val_root_mean_squared_error: 0.1709\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.5718 - root_mean_squared_error: 0.1844 - val_loss: 3.5174 - val_root_mean_squared_error: 0.1821\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.4901 - root_mean_squared_error: 0.1903 - val_loss: 3.4746 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.4755 - root_mean_squared_error: 0.1934 - val_loss: 3.4644 - val_root_mean_squared_error: 0.1827\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.4526 - root_mean_squared_error: 0.1932 - val_loss: 3.4446 - val_root_mean_squared_error: 0.1814\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.4744 - root_mean_squared_error: 0.1926 - val_loss: 3.4779 - val_root_mean_squared_error: 0.1837\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.5121 - root_mean_squared_error: 0.2198 - val_loss: 3.5164 - val_root_mean_squared_error: 0.1758\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.5460 - root_mean_squared_error: 0.2343 - val_loss: 3.5421 - val_root_mean_squared_error: 0.2209\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.5545 - root_mean_squared_error: 0.1965 - val_loss: 3.6129 - val_root_mean_squared_error: 0.1978\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.5886 - root_mean_squared_error: 0.2092 - val_loss: 3.5369 - val_root_mean_squared_error: 0.1706\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.5395 - root_mean_squared_error: 0.1914 - val_loss: 3.5472 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.5578 - root_mean_squared_error: 0.1888 - val_loss: 3.5585 - val_root_mean_squared_error: 0.2152\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.5268 - root_mean_squared_error: 0.2046 - val_loss: 3.4942 - val_root_mean_squared_error: 0.2067\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.5091 - root_mean_squared_error: 0.1992 - val_loss: 3.4619 - val_root_mean_squared_error: 0.1782\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.5049 - root_mean_squared_error: 0.1843 - val_loss: 3.5158 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.5321 - root_mean_squared_error: 0.1851 - val_loss: 3.5222 - val_root_mean_squared_error: 0.1732\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 3.5093 - root_mean_squared_error: 0.1305\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 3.5093 - root_mean_squared_error: 0.1305\n",
            "MODEL EVALUATION:  [3.509256362915039, 0.13045841455459595]\n",
            "Number of epochs: 40 learning rate: 0.3 Activation Function: sigmoid\n",
            "Model number:  535\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 51ms/step - loss: 20.9595 - root_mean_squared_error: 3.6105 - val_loss: 6.8884 - val_root_mean_squared_error: 0.2258\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 7.5909 - root_mean_squared_error: 1.2989 - val_loss: 7.4677 - val_root_mean_squared_error: 1.3474\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 9.0778 - root_mean_squared_error: 1.3644 - val_loss: 8.7765 - val_root_mean_squared_error: 0.1792\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.0382 - root_mean_squared_error: 1.2110 - val_loss: 7.8665 - val_root_mean_squared_error: 0.2996\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 7.5282 - root_mean_squared_error: 0.4137 - val_loss: 6.6992 - val_root_mean_squared_error: 0.2049\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.9099 - root_mean_squared_error: 0.3632 - val_loss: 4.7600 - val_root_mean_squared_error: 0.1795\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.5905 - root_mean_squared_error: 0.4894 - val_loss: 4.0624 - val_root_mean_squared_error: 0.2805\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.4349 - root_mean_squared_error: 0.2391 - val_loss: 2.7098 - val_root_mean_squared_error: 0.2079\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.3082 - root_mean_squared_error: 0.3120 - val_loss: 1.5115 - val_root_mean_squared_error: 0.2031\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2325 - root_mean_squared_error: 0.2594 - val_loss: 0.7990 - val_root_mean_squared_error: 0.2501\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6178 - root_mean_squared_error: 0.2564 - val_loss: 0.4051 - val_root_mean_squared_error: 0.2163\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3948 - root_mean_squared_error: 0.3022 - val_loss: 0.3948 - val_root_mean_squared_error: 0.3337\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3181 - root_mean_squared_error: 0.2400 - val_loss: 0.2241 - val_root_mean_squared_error: 0.1776\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1939 - root_mean_squared_error: 0.2125 - val_loss: 0.1249 - val_root_mean_squared_error: 0.1836\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1109 - root_mean_squared_error: 0.1958 - val_loss: 0.1200 - val_root_mean_squared_error: 0.2766\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1161 - root_mean_squared_error: 0.2697 - val_loss: 0.0765 - val_root_mean_squared_error: 0.1708\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0836 - root_mean_squared_error: 0.2057 - val_loss: 0.1442 - val_root_mean_squared_error: 0.3432\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0917 - root_mean_squared_error: 0.2488 - val_loss: 0.1082 - val_root_mean_squared_error: 0.2804\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0739 - root_mean_squared_error: 0.2249 - val_loss: 0.0538 - val_root_mean_squared_error: 0.1850\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0590 - root_mean_squared_error: 0.2042 - val_loss: 0.0477 - val_root_mean_squared_error: 0.1829\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0498 - root_mean_squared_error: 0.1958 - val_loss: 0.1565 - val_root_mean_squared_error: 0.3807\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1092 - root_mean_squared_error: 0.2995 - val_loss: 0.0816 - val_root_mean_squared_error: 0.2227\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1055 - root_mean_squared_error: 0.2761 - val_loss: 0.0795 - val_root_mean_squared_error: 0.2349\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0730 - root_mean_squared_error: 0.2279 - val_loss: 0.0499 - val_root_mean_squared_error: 0.1853\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0606 - root_mean_squared_error: 0.2187 - val_loss: 0.0386 - val_root_mean_squared_error: 0.1721\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0570 - root_mean_squared_error: 0.2208 - val_loss: 0.0586 - val_root_mean_squared_error: 0.2248\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0497 - root_mean_squared_error: 0.2079 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1814\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0552 - root_mean_squared_error: 0.2252 - val_loss: 0.0353 - val_root_mean_squared_error: 0.1760\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0495 - root_mean_squared_error: 0.2124 - val_loss: 0.0344 - val_root_mean_squared_error: 0.1759\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0426 - root_mean_squared_error: 0.1987 - val_loss: 0.0310 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0387 - root_mean_squared_error: 0.1920 - val_loss: 0.0422 - val_root_mean_squared_error: 0.2025\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0603 - root_mean_squared_error: 0.2409 - val_loss: 0.0558 - val_root_mean_squared_error: 0.2246\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0513 - root_mean_squared_error: 0.2157 - val_loss: 0.0352 - val_root_mean_squared_error: 0.1769\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0456 - root_mean_squared_error: 0.2059 - val_loss: 0.0490 - val_root_mean_squared_error: 0.2158\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0475 - root_mean_squared_error: 0.2126 - val_loss: 0.0491 - val_root_mean_squared_error: 0.2158\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0675 - root_mean_squared_error: 0.2518 - val_loss: 0.0798 - val_root_mean_squared_error: 0.2690\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0695 - root_mean_squared_error: 0.2498 - val_loss: 0.0414 - val_root_mean_squared_error: 0.1879\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0554 - root_mean_squared_error: 0.2241 - val_loss: 0.0336 - val_root_mean_squared_error: 0.1733\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0467 - root_mean_squared_error: 0.2093 - val_loss: 0.0469 - val_root_mean_squared_error: 0.2108\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0534 - root_mean_squared_error: 0.2256 - val_loss: 0.0480 - val_root_mean_squared_error: 0.2123\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0273 - root_mean_squared_error: 0.1560\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0273 - root_mean_squared_error: 0.1560\n",
            "MODEL EVALUATION:  [0.02732621319591999, 0.15602844953536987]\n",
            "Number of epochs: 40 learning rate: 0.3 Activation Function: sigmoid\n",
            "Model number:  536\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 44ms/step - loss: 15.2038 - root_mean_squared_error: 3.8992 - val_loss: 20.8057 - val_root_mean_squared_error: 4.5613\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 8.1382 - root_mean_squared_error: 2.8528 - val_loss: 8.5638 - val_root_mean_squared_error: 2.9264\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.8836 - root_mean_squared_error: 2.2099 - val_loss: 1.6947 - val_root_mean_squared_error: 1.3018\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.8227 - root_mean_squared_error: 1.6801 - val_loss: 0.0327 - val_root_mean_squared_error: 0.1808\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3070 - root_mean_squared_error: 1.1432 - val_loss: 0.3710 - val_root_mean_squared_error: 0.6091\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6173 - root_mean_squared_error: 0.7857 - val_loss: 0.5738 - val_root_mean_squared_error: 0.7575\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.3449 - root_mean_squared_error: 0.5873 - val_loss: 0.4783 - val_root_mean_squared_error: 0.6916\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2197 - root_mean_squared_error: 0.4687 - val_loss: 0.3036 - val_root_mean_squared_error: 0.5510\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1438 - root_mean_squared_error: 0.3793 - val_loss: 0.1763 - val_root_mean_squared_error: 0.4199\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0938 - root_mean_squared_error: 0.3063 - val_loss: 0.1011 - val_root_mean_squared_error: 0.3179\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0611 - root_mean_squared_error: 0.2471 - val_loss: 0.0734 - val_root_mean_squared_error: 0.2708\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0497 - root_mean_squared_error: 0.2230 - val_loss: 0.0537 - val_root_mean_squared_error: 0.2317\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0460 - root_mean_squared_error: 0.2144 - val_loss: 0.0422 - val_root_mean_squared_error: 0.2054\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0381 - root_mean_squared_error: 0.1953 - val_loss: 0.0351 - val_root_mean_squared_error: 0.1872\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0371 - root_mean_squared_error: 0.1927 - val_loss: 0.0329 - val_root_mean_squared_error: 0.1814\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0364 - root_mean_squared_error: 0.1909 - val_loss: 0.0301 - val_root_mean_squared_error: 0.1736\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0369 - root_mean_squared_error: 0.1920 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1708\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0372 - root_mean_squared_error: 0.1930 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1756\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0367 - root_mean_squared_error: 0.1916 - val_loss: 0.0296 - val_root_mean_squared_error: 0.1719\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0345 - root_mean_squared_error: 0.1857 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0344 - root_mean_squared_error: 0.1856 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1749\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0360 - root_mean_squared_error: 0.1897 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1715\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0349 - root_mean_squared_error: 0.1868 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0343 - root_mean_squared_error: 0.1851 - val_loss: 0.0293 - val_root_mean_squared_error: 0.1711\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0345 - root_mean_squared_error: 0.1858 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1707\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0342 - root_mean_squared_error: 0.1849 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1707\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0340 - root_mean_squared_error: 0.1843 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1716\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0349 - root_mean_squared_error: 0.1869 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1705\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0345 - root_mean_squared_error: 0.1857 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1746\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0374 - root_mean_squared_error: 0.1934 - val_loss: 0.0327 - val_root_mean_squared_error: 0.1808\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0409 - root_mean_squared_error: 0.2023 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0407 - root_mean_squared_error: 0.2017 - val_loss: 0.0384 - val_root_mean_squared_error: 0.1960\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0415 - root_mean_squared_error: 0.2037 - val_loss: 0.0347 - val_root_mean_squared_error: 0.1863\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0376 - root_mean_squared_error: 0.1938 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1750\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0376 - root_mean_squared_error: 0.1940 - val_loss: 0.0347 - val_root_mean_squared_error: 0.1864\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0419 - root_mean_squared_error: 0.2047 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0380 - root_mean_squared_error: 0.1949 - val_loss: 0.0369 - val_root_mean_squared_error: 0.1920\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0425 - root_mean_squared_error: 0.2062 - val_loss: 0.0358 - val_root_mean_squared_error: 0.1892\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0415 - root_mean_squared_error: 0.2037 - val_loss: 0.0311 - val_root_mean_squared_error: 0.1764\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0390 - root_mean_squared_error: 0.1976 - val_loss: 0.0366 - val_root_mean_squared_error: 0.1912\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829\n",
            "MODEL EVALUATION:  [0.033462099730968475, 0.1829264909029007]\n",
            "Number of epochs: 40 learning rate: 0.3 Activation Function: sigmoid\n",
            "Model number:  537\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 50ms/step - loss: 4671.5835 - root_mean_squared_error: 68.1572 - val_loss: 81.5790 - val_root_mean_squared_error: 6.1214\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 121.4174 - root_mean_squared_error: 8.3145 - val_loss: 64.1078 - val_root_mean_squared_error: 0.5772\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 69.8455 - root_mean_squared_error: 0.7744 - val_loss: 75.7467 - val_root_mean_squared_error: 0.3097\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 78.6160 - root_mean_squared_error: 0.5263 - val_loss: 81.5977 - val_root_mean_squared_error: 0.3227\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 82.9130 - root_mean_squared_error: 0.2789 - val_loss: 84.4867 - val_root_mean_squared_error: 0.1970\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 85.3658 - root_mean_squared_error: 0.6591 - val_loss: 86.5987 - val_root_mean_squared_error: 0.9113\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 86.6735 - root_mean_squared_error: 0.8830 - val_loss: 86.7739 - val_root_mean_squared_error: 0.7919\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 86.3779 - root_mean_squared_error: 0.7295 - val_loss: 86.1250 - val_root_mean_squared_error: 0.5934\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 85.8737 - root_mean_squared_error: 0.5253 - val_loss: 85.7400 - val_root_mean_squared_error: 0.3868\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 85.3186 - root_mean_squared_error: 0.3340 - val_loss: 84.8978 - val_root_mean_squared_error: 0.2301\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 84.6125 - root_mean_squared_error: 0.2152 - val_loss: 84.4575 - val_root_mean_squared_error: 0.1706\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 84.0100 - root_mean_squared_error: 0.1906 - val_loss: 83.7031 - val_root_mean_squared_error: 0.1838\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 83.4300 - root_mean_squared_error: 0.2002 - val_loss: 83.2582 - val_root_mean_squared_error: 0.1968\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 82.7579 - root_mean_squared_error: 0.2063 - val_loss: 82.3402 - val_root_mean_squared_error: 0.1932\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 82.1536 - root_mean_squared_error: 0.1999 - val_loss: 82.0636 - val_root_mean_squared_error: 0.1837\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 81.6287 - root_mean_squared_error: 0.1918 - val_loss: 81.3436 - val_root_mean_squared_error: 0.1747\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 81.0584 - root_mean_squared_error: 0.1860 - val_loss: 80.8987 - val_root_mean_squared_error: 0.1708\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 80.5377 - root_mean_squared_error: 0.1844 - val_loss: 80.3337 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 80.0733 - root_mean_squared_error: 0.1843 - val_loss: 79.9211 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 79.4867 - root_mean_squared_error: 0.1845 - val_loss: 79.1739 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 79.0605 - root_mean_squared_error: 0.1843 - val_loss: 79.0697 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 78.6833 - root_mean_squared_error: 0.1840 - val_loss: 78.3863 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 78.1938 - root_mean_squared_error: 0.1840 - val_loss: 78.1526 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 77.7554 - root_mean_squared_error: 0.1840 - val_loss: 77.5574 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 77.3891 - root_mean_squared_error: 0.1840 - val_loss: 77.2755 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 76.9402 - root_mean_squared_error: 0.1840 - val_loss: 76.7729 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 76.5647 - root_mean_squared_error: 0.1842 - val_loss: 76.5859 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 76.2117 - root_mean_squared_error: 0.1842 - val_loss: 75.9792 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 75.7719 - root_mean_squared_error: 0.1840 - val_loss: 75.7075 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 75.3808 - root_mean_squared_error: 0.1841 - val_loss: 75.1768 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 75.0511 - root_mean_squared_error: 0.1840 - val_loss: 75.0447 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 74.6286 - root_mean_squared_error: 0.1841 - val_loss: 74.4654 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 74.3136 - root_mean_squared_error: 0.1840 - val_loss: 74.3004 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 73.8883 - root_mean_squared_error: 0.1840 - val_loss: 73.5917 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 73.4234 - root_mean_squared_error: 0.1841 - val_loss: 73.3741 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 73.0968 - root_mean_squared_error: 0.1840 - val_loss: 73.0239 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 72.8591 - root_mean_squared_error: 0.1840 - val_loss: 72.7566 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 72.3724 - root_mean_squared_error: 0.1839 - val_loss: 72.1527 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 71.9770 - root_mean_squared_error: 0.1841 - val_loss: 71.9954 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 71.6631 - root_mean_squared_error: 0.1841 - val_loss: 71.4322 - val_root_mean_squared_error: 0.1704\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 71.4227 - root_mean_squared_error: 0.1398\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 71.4227 - root_mean_squared_error: 0.1398\n",
            "MODEL EVALUATION:  [71.42269134521484, 0.13983449339866638]\n",
            "Number of epochs: 40 learning rate: 0.3 Activation Function: relu\n",
            "Model number:  538\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 52ms/step - loss: 70768.4453 - root_mean_squared_error: 266.0055 - val_loss: 594.6287 - val_root_mean_squared_error: 23.8601\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 143.3044 - root_mean_squared_error: 10.1636 - val_loss: 249.9339 - val_root_mean_squared_error: 13.6963\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 107.9406 - root_mean_squared_error: 5.7737 - val_loss: 150.4724 - val_root_mean_squared_error: 7.6818\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 108.6731 - root_mean_squared_error: 3.0686 - val_loss: 111.7544 - val_root_mean_squared_error: 1.4647\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 116.6009 - root_mean_squared_error: 1.4923 - val_loss: 122.8021 - val_root_mean_squared_error: 1.5092\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 125.5506 - root_mean_squared_error: 1.5231 - val_loss: 128.9599 - val_root_mean_squared_error: 1.5226\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 130.3624 - root_mean_squared_error: 1.5285 - val_loss: 131.9974 - val_root_mean_squared_error: 1.5173\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 132.6089 - root_mean_squared_error: 1.5182 - val_loss: 133.2273 - val_root_mean_squared_error: 1.5004\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 133.3878 - root_mean_squared_error: 1.4983 - val_loss: 133.4281 - val_root_mean_squared_error: 1.4763\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 133.3402 - root_mean_squared_error: 1.4723 - val_loss: 133.0684 - val_root_mean_squared_error: 1.4478\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 132.8492 - root_mean_squared_error: 1.4426 - val_loss: 132.4140 - val_root_mean_squared_error: 1.4162\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 132.1287 - root_mean_squared_error: 1.4102 - val_loss: 131.6158 - val_root_mean_squared_error: 1.3828\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 131.3022 - root_mean_squared_error: 1.3763 - val_loss: 130.7593 - val_root_mean_squared_error: 1.3481\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 130.4375 - root_mean_squared_error: 1.3413 - val_loss: 129.8890 - val_root_mean_squared_error: 1.3125\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 129.5695 - root_mean_squared_error: 1.3055 - val_loss: 129.0285 - val_root_mean_squared_error: 1.2763\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 128.7160 - root_mean_squared_error: 1.2691 - val_loss: 128.1891 - val_root_mean_squared_error: 1.2397\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 127.8860 - root_mean_squared_error: 1.2326 - val_loss: 127.3750 - val_root_mean_squared_error: 1.2030\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 127.0819 - root_mean_squared_error: 1.1958 - val_loss: 126.5874 - val_root_mean_squared_error: 1.1661\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 126.3041 - root_mean_squared_error: 1.1590 - val_loss: 125.8258 - val_root_mean_squared_error: 1.1293\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 125.5517 - root_mean_squared_error: 1.1222 - val_loss: 125.0889 - val_root_mean_squared_error: 1.0926\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 124.8239 - root_mean_squared_error: 1.0858 - val_loss: 124.3752 - val_root_mean_squared_error: 1.0562\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 124.1184 - root_mean_squared_error: 1.0496 - val_loss: 123.6832 - val_root_mean_squared_error: 1.0200\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 123.4342 - root_mean_squared_error: 1.0137 - val_loss: 123.0117 - val_root_mean_squared_error: 0.9844\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 122.7694 - root_mean_squared_error: 0.9782 - val_loss: 122.3592 - val_root_mean_squared_error: 0.9493\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 122.1240 - root_mean_squared_error: 0.9436 - val_loss: 121.7242 - val_root_mean_squared_error: 0.9146\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 121.4952 - root_mean_squared_error: 0.9092 - val_loss: 121.1058 - val_root_mean_squared_error: 0.8805\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 120.8824 - root_mean_squared_error: 0.8754 - val_loss: 120.5029 - val_root_mean_squared_error: 0.8471\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 120.2851 - root_mean_squared_error: 0.8424 - val_loss: 119.9145 - val_root_mean_squared_error: 0.8143\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 119.7019 - root_mean_squared_error: 0.8101 - val_loss: 119.3397 - val_root_mean_squared_error: 0.7823\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 119.1318 - root_mean_squared_error: 0.7784 - val_loss: 118.7779 - val_root_mean_squared_error: 0.7511\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 118.5743 - root_mean_squared_error: 0.7476 - val_loss: 118.2282 - val_root_mean_squared_error: 0.7207\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 118.0285 - root_mean_squared_error: 0.7174 - val_loss: 117.6898 - val_root_mean_squared_error: 0.6911\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 117.4942 - root_mean_squared_error: 0.6885 - val_loss: 117.1618 - val_root_mean_squared_error: 0.6622\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 116.9700 - root_mean_squared_error: 0.6601 - val_loss: 116.6439 - val_root_mean_squared_error: 0.6342\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 116.4553 - root_mean_squared_error: 0.6324 - val_loss: 116.1356 - val_root_mean_squared_error: 0.6072\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 115.9504 - root_mean_squared_error: 0.6061 - val_loss: 115.6360 - val_root_mean_squared_error: 0.5810\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 115.4538 - root_mean_squared_error: 0.5803 - val_loss: 115.1450 - val_root_mean_squared_error: 0.5558\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 114.9659 - root_mean_squared_error: 0.5559 - val_loss: 114.6617 - val_root_mean_squared_error: 0.5314\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 114.4849 - root_mean_squared_error: 0.5317 - val_loss: 114.1860 - val_root_mean_squared_error: 0.5081\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 114.0119 - root_mean_squared_error: 0.5090 - val_loss: 113.7172 - val_root_mean_squared_error: 0.4856\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 113.6696 - root_mean_squared_error: 0.4338\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 113.6696 - root_mean_squared_error: 0.4338\n",
            "MODEL EVALUATION:  [113.66956329345703, 0.43376410007476807]\n",
            "Number of epochs: 40 learning rate: 0.3 Activation Function: relu\n",
            "Model number:  539\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 43ms/step - loss: 228197.7031 - root_mean_squared_error: 477.7004 - val_loss: 0.0168 - val_root_mean_squared_error: 0.1298\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.6580 - root_mean_squared_error: 1.6303 - val_loss: 3.0314 - val_root_mean_squared_error: 1.7411\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2598 - root_mean_squared_error: 1.1224 - val_loss: 0.6360 - val_root_mean_squared_error: 0.7975\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.1971 - root_mean_squared_error: 1.0941 - val_loss: 0.2001 - val_root_mean_squared_error: 0.4473\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3429 - root_mean_squared_error: 0.5856 - val_loss: 0.7084 - val_root_mean_squared_error: 0.8417\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3084 - root_mean_squared_error: 0.5554 - val_loss: 0.1972 - val_root_mean_squared_error: 0.4440\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2469 - root_mean_squared_error: 0.4969 - val_loss: 0.0311 - val_root_mean_squared_error: 0.1764\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1242 - root_mean_squared_error: 0.3524 - val_loss: 0.1048 - val_root_mean_squared_error: 0.3237\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0757 - root_mean_squared_error: 0.2752 - val_loss: 0.1026 - val_root_mean_squared_error: 0.3203\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0588 - root_mean_squared_error: 0.2426 - val_loss: 0.0565 - val_root_mean_squared_error: 0.2378\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0577 - root_mean_squared_error: 0.2403 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1839\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0434 - root_mean_squared_error: 0.2083 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0384 - root_mean_squared_error: 0.1961 - val_loss: 0.0297 - val_root_mean_squared_error: 0.1722\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0403 - root_mean_squared_error: 0.2007 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1754\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0382 - root_mean_squared_error: 0.1953 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1747\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0359 - root_mean_squared_error: 0.1896 - val_loss: 0.0309 - val_root_mean_squared_error: 0.1758\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0336 - root_mean_squared_error: 0.1833 - val_loss: 0.0300 - val_root_mean_squared_error: 0.1732\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0353 - root_mean_squared_error: 0.1879 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0341 - root_mean_squared_error: 0.1847 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0340 - root_mean_squared_error: 0.1844 - val_loss: 0.0293 - val_root_mean_squared_error: 0.1712\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0343 - root_mean_squared_error: 0.1851 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0347 - root_mean_squared_error: 0.1864 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1715\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0355 - root_mean_squared_error: 0.1883 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1754\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0353 - root_mean_squared_error: 0.1878 - val_loss: 0.0297 - val_root_mean_squared_error: 0.1724\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0356 - root_mean_squared_error: 0.1887 - val_loss: 0.0297 - val_root_mean_squared_error: 0.1723\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0348 - root_mean_squared_error: 0.1864 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0352 - root_mean_squared_error: 0.1877 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0347 - root_mean_squared_error: 0.1862 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0344 - root_mean_squared_error: 0.1855 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0345 - root_mean_squared_error: 0.1857 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1708\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0350 - root_mean_squared_error: 0.1870 - val_loss: 0.0300 - val_root_mean_squared_error: 0.1732\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0350 - root_mean_squared_error: 0.1871 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1716\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0344 - root_mean_squared_error: 0.1854 - val_loss: 0.0297 - val_root_mean_squared_error: 0.1724\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0344 - root_mean_squared_error: 0.1855 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0349 - root_mean_squared_error: 0.1868 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0338 - root_mean_squared_error: 0.1839 - val_loss: 0.0302 - val_root_mean_squared_error: 0.1737\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0345 - root_mean_squared_error: 0.1857 - val_loss: 0.0316 - val_root_mean_squared_error: 0.1779\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0349 - root_mean_squared_error: 0.1868 - val_loss: 0.0318 - val_root_mean_squared_error: 0.1784\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0364 - root_mean_squared_error: 0.1908 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1701\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0187 - root_mean_squared_error: 0.1366\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0187 - root_mean_squared_error: 0.1366\n",
            "MODEL EVALUATION:  [0.018651088699698448, 0.13656899333000183]\n",
            "Number of epochs: 40 learning rate: 0.3 Activation Function: relu\n",
            "Model number:  540\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 58ms/step - loss: 13.4359 - root_mean_squared_error: 1.8223 - val_loss: 8.4977 - val_root_mean_squared_error: 0.7596\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 7.1332 - root_mean_squared_error: 0.4891 - val_loss: 6.1000 - val_root_mean_squared_error: 0.2787\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.9772 - root_mean_squared_error: 0.2775 - val_loss: 4.0660 - val_root_mean_squared_error: 0.2997\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.5940 - root_mean_squared_error: 0.2588 - val_loss: 2.9123 - val_root_mean_squared_error: 0.1775\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.7073 - root_mean_squared_error: 0.2291 - val_loss: 2.2692 - val_root_mean_squared_error: 0.2290\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.1841 - root_mean_squared_error: 0.2790 - val_loss: 1.9020 - val_root_mean_squared_error: 0.1889\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.8839 - root_mean_squared_error: 0.2180 - val_loss: 1.7173 - val_root_mean_squared_error: 0.1865\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7011 - root_mean_squared_error: 0.2111 - val_loss: 1.6057 - val_root_mean_squared_error: 0.1723\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5796 - root_mean_squared_error: 0.1886 - val_loss: 1.5115 - val_root_mean_squared_error: 0.1755\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.5003 - root_mean_squared_error: 0.1980 - val_loss: 1.4574 - val_root_mean_squared_error: 0.1783\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.4529 - root_mean_squared_error: 0.1880 - val_loss: 1.4159 - val_root_mean_squared_error: 0.1859\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4130 - root_mean_squared_error: 0.1904 - val_loss: 1.3973 - val_root_mean_squared_error: 0.1824\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3918 - root_mean_squared_error: 0.2015 - val_loss: 1.3962 - val_root_mean_squared_error: 0.2041\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4112 - root_mean_squared_error: 0.2215 - val_loss: 1.4677 - val_root_mean_squared_error: 0.2870\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4710 - root_mean_squared_error: 0.2636 - val_loss: 1.4513 - val_root_mean_squared_error: 0.1997\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4826 - root_mean_squared_error: 0.2056 - val_loss: 1.4965 - val_root_mean_squared_error: 0.1886\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5021 - root_mean_squared_error: 0.2017 - val_loss: 1.4773 - val_root_mean_squared_error: 0.1711\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4851 - root_mean_squared_error: 0.2114 - val_loss: 1.4954 - val_root_mean_squared_error: 0.2783\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4652 - root_mean_squared_error: 0.2202 - val_loss: 1.4740 - val_root_mean_squared_error: 0.2312\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4806 - root_mean_squared_error: 0.2321 - val_loss: 1.4564 - val_root_mean_squared_error: 0.2210\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4518 - root_mean_squared_error: 0.2044 - val_loss: 1.4505 - val_root_mean_squared_error: 0.2254\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4601 - root_mean_squared_error: 0.2321 - val_loss: 1.4324 - val_root_mean_squared_error: 0.1994\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4607 - root_mean_squared_error: 0.2239 - val_loss: 1.4534 - val_root_mean_squared_error: 0.2278\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4582 - root_mean_squared_error: 0.2055 - val_loss: 1.4381 - val_root_mean_squared_error: 0.1734\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4321 - root_mean_squared_error: 0.1842 - val_loss: 1.3768 - val_root_mean_squared_error: 0.1711\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3856 - root_mean_squared_error: 0.1868 - val_loss: 1.3518 - val_root_mean_squared_error: 0.1784\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3522 - root_mean_squared_error: 0.1893 - val_loss: 1.3092 - val_root_mean_squared_error: 0.1781\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3113 - root_mean_squared_error: 0.1978 - val_loss: 1.2935 - val_root_mean_squared_error: 0.1744\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3246 - root_mean_squared_error: 0.2000 - val_loss: 1.3327 - val_root_mean_squared_error: 0.2010\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3496 - root_mean_squared_error: 0.1912 - val_loss: 1.3500 - val_root_mean_squared_error: 0.1760\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3623 - root_mean_squared_error: 0.1965 - val_loss: 1.3480 - val_root_mean_squared_error: 0.1730\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3629 - root_mean_squared_error: 0.2150 - val_loss: 1.3257 - val_root_mean_squared_error: 0.1722\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3532 - root_mean_squared_error: 0.1975 - val_loss: 1.3539 - val_root_mean_squared_error: 0.1788\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3682 - root_mean_squared_error: 0.1897 - val_loss: 1.3699 - val_root_mean_squared_error: 0.1804\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3661 - root_mean_squared_error: 0.1890 - val_loss: 1.3363 - val_root_mean_squared_error: 0.1774\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3416 - root_mean_squared_error: 0.1913 - val_loss: 1.3110 - val_root_mean_squared_error: 0.1754\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3168 - root_mean_squared_error: 0.1885 - val_loss: 1.3005 - val_root_mean_squared_error: 0.1804\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3040 - root_mean_squared_error: 0.1927 - val_loss: 1.2893 - val_root_mean_squared_error: 0.1745\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.3044 - root_mean_squared_error: 0.1854 - val_loss: 1.2845 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 1.3026 - root_mean_squared_error: 0.1890 - val_loss: 1.2913 - val_root_mean_squared_error: 0.1783\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.2766 - root_mean_squared_error: 0.1308\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2766 - root_mean_squared_error: 0.1308\n",
            "MODEL EVALUATION:  [1.2766269445419312, 0.13080459833145142]\n",
            "Number of epochs: 40 learning rate: 0.1 Activation Function: sigmoid\n",
            "Model number:  541\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 70ms/step - loss: 6.2916 - root_mean_squared_error: 2.0632 - val_loss: 2.1669 - val_root_mean_squared_error: 0.3986\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.9933 - root_mean_squared_error: 0.2771 - val_loss: 1.5765 - val_root_mean_squared_error: 0.2545\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3844 - root_mean_squared_error: 0.2560 - val_loss: 1.2465 - val_root_mean_squared_error: 0.2105\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.0647 - root_mean_squared_error: 0.2209 - val_loss: 0.7316 - val_root_mean_squared_error: 0.2275\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.6374 - root_mean_squared_error: 0.2476 - val_loss: 0.4629 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.4200 - root_mean_squared_error: 0.2644 - val_loss: 0.3010 - val_root_mean_squared_error: 0.1963\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2806 - root_mean_squared_error: 0.2587 - val_loss: 0.1947 - val_root_mean_squared_error: 0.2221\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1714 - root_mean_squared_error: 0.2312 - val_loss: 0.1475 - val_root_mean_squared_error: 0.2485\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1221 - root_mean_squared_error: 0.2315 - val_loss: 0.1038 - val_root_mean_squared_error: 0.2272\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1060 - root_mean_squared_error: 0.2519 - val_loss: 0.1354 - val_root_mean_squared_error: 0.3230\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1074 - root_mean_squared_error: 0.2787 - val_loss: 0.1156 - val_root_mean_squared_error: 0.2957\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1002 - root_mean_squared_error: 0.2740 - val_loss: 0.0565 - val_root_mean_squared_error: 0.1813\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0843 - root_mean_squared_error: 0.2434 - val_loss: 0.0660 - val_root_mean_squared_error: 0.2009\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0921 - root_mean_squared_error: 0.2582 - val_loss: 0.1110 - val_root_mean_squared_error: 0.2856\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0780 - root_mean_squared_error: 0.2330 - val_loss: 0.0767 - val_root_mean_squared_error: 0.2311\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0644 - root_mean_squared_error: 0.2159 - val_loss: 0.0413 - val_root_mean_squared_error: 0.1721\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0447 - root_mean_squared_error: 0.1883 - val_loss: 0.0358 - val_root_mean_squared_error: 0.1723\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0422 - root_mean_squared_error: 0.1938 - val_loss: 0.0546 - val_root_mean_squared_error: 0.2237\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0462 - root_mean_squared_error: 0.2080 - val_loss: 0.0310 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0393 - root_mean_squared_error: 0.1932 - val_loss: 0.0373 - val_root_mean_squared_error: 0.1898\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0369 - root_mean_squared_error: 0.1881 - val_loss: 0.1160 - val_root_mean_squared_error: 0.3394\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0773 - root_mean_squared_error: 0.2696 - val_loss: 0.0424 - val_root_mean_squared_error: 0.1834\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0475 - root_mean_squared_error: 0.2008 - val_loss: 0.0353 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0412 - root_mean_squared_error: 0.1900 - val_loss: 0.0337 - val_root_mean_squared_error: 0.1747\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0504 - root_mean_squared_error: 0.2169 - val_loss: 0.0315 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0434 - root_mean_squared_error: 0.2025 - val_loss: 0.0332 - val_root_mean_squared_error: 0.1772\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0378 - root_mean_squared_error: 0.1901 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1713\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0369 - root_mean_squared_error: 0.1895 - val_loss: 0.0346 - val_root_mean_squared_error: 0.1847\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0396 - root_mean_squared_error: 0.1976 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1932\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0385 - root_mean_squared_error: 0.1950 - val_loss: 0.0447 - val_root_mean_squared_error: 0.2093\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0425 - root_mean_squared_error: 0.2047 - val_loss: 0.0502 - val_root_mean_squared_error: 0.2211\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0548 - root_mean_squared_error: 0.2302 - val_loss: 0.0318 - val_root_mean_squared_error: 0.1717\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0439 - root_mean_squared_error: 0.2037 - val_loss: 0.0316 - val_root_mean_squared_error: 0.1710\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0456 - root_mean_squared_error: 0.2087 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0421 - root_mean_squared_error: 0.2003 - val_loss: 0.0443 - val_root_mean_squared_error: 0.2040\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0408 - root_mean_squared_error: 0.1979 - val_loss: 0.0301 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0379 - root_mean_squared_error: 0.1924 - val_loss: 0.0312 - val_root_mean_squared_error: 0.1756\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0357 - root_mean_squared_error: 0.1879 - val_loss: 0.0293 - val_root_mean_squared_error: 0.1706\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0346 - root_mean_squared_error: 0.1856 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1706\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0348 - root_mean_squared_error: 0.1864 - val_loss: 0.0373 - val_root_mean_squared_error: 0.1930\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 0.0345 - root_mean_squared_error: 0.1856\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0345 - root_mean_squared_error: 0.1856\n",
            "MODEL EVALUATION:  [0.034523844718933105, 0.18558116257190704]\n",
            "Number of epochs: 40 learning rate: 0.1 Activation Function: sigmoid\n",
            "Model number:  542\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 52ms/step - loss: 3.9453 - root_mean_squared_error: 1.9863 - val_loss: 1.1116 - val_root_mean_squared_error: 1.0543\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.8032 - root_mean_squared_error: 1.3428 - val_loss: 0.7555 - val_root_mean_squared_error: 0.8692\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2870 - root_mean_squared_error: 0.5357 - val_loss: 0.5698 - val_root_mean_squared_error: 0.7548\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5716 - root_mean_squared_error: 0.7561 - val_loss: 0.1400 - val_root_mean_squared_error: 0.3742\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1047 - root_mean_squared_error: 0.3235 - val_loss: 0.2418 - val_root_mean_squared_error: 0.4918\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1632 - root_mean_squared_error: 0.4040 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0578 - root_mean_squared_error: 0.2404 - val_loss: 0.0784 - val_root_mean_squared_error: 0.2799\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0561 - root_mean_squared_error: 0.2368 - val_loss: 0.0331 - val_root_mean_squared_error: 0.1818\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0450 - root_mean_squared_error: 0.2120 - val_loss: 0.0339 - val_root_mean_squared_error: 0.1842\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0355 - root_mean_squared_error: 0.1884 - val_loss: 0.0345 - val_root_mean_squared_error: 0.1857\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0377 - root_mean_squared_error: 0.1941 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0348 - root_mean_squared_error: 0.1865 - val_loss: 0.0298 - val_root_mean_squared_error: 0.1727\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0342 - root_mean_squared_error: 0.1850 - val_loss: 0.0298 - val_root_mean_squared_error: 0.1725\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0345 - root_mean_squared_error: 0.1858 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0343 - root_mean_squared_error: 0.1852 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0341 - root_mean_squared_error: 0.1845 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1710\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0340 - root_mean_squared_error: 0.1844 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0343 - root_mean_squared_error: 0.1851 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0339 - root_mean_squared_error: 0.1842 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1710\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0340 - root_mean_squared_error: 0.1844 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0341 - root_mean_squared_error: 0.1845 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0352 - root_mean_squared_error: 0.1876 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0368 - root_mean_squared_error: 0.1917 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1716\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0335 - root_mean_squared_error: 0.1830 - val_loss: 0.0319 - val_root_mean_squared_error: 0.1786\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0358 - root_mean_squared_error: 0.1891 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1716\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0341 - root_mean_squared_error: 0.1847 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1706\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0343 - root_mean_squared_error: 0.1853 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1710\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0340 - root_mean_squared_error: 0.1843 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0339 - root_mean_squared_error: 0.1841 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1707\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0344 - root_mean_squared_error: 0.1854 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0340 - root_mean_squared_error: 0.1845 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0357 - root_mean_squared_error: 0.1889 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0349 - root_mean_squared_error: 0.1867 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0335 - root_mean_squared_error: 0.1830 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1749\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0349 - root_mean_squared_error: 0.1869 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1709\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0343 - root_mean_squared_error: 0.1851 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1709\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0339 - root_mean_squared_error: 0.1841 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0348 - root_mean_squared_error: 0.1865 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1708\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0348 - root_mean_squared_error: 0.1865 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0359 - root_mean_squared_error: 0.1896 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1701\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0184 - root_mean_squared_error: 0.1355\n",
            "MODEL EVALUATION:  [0.01837162673473358, 0.13554197549819946]\n",
            "Number of epochs: 40 learning rate: 0.1 Activation Function: sigmoid\n",
            "Model number:  543\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 46ms/step - loss: 22.2098 - root_mean_squared_error: 3.5323 - val_loss: 12.7489 - val_root_mean_squared_error: 1.1887\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 13.4604 - root_mean_squared_error: 0.7933 - val_loss: 14.2482 - val_root_mean_squared_error: 0.5720\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 14.4681 - root_mean_squared_error: 0.3991 - val_loss: 14.3326 - val_root_mean_squared_error: 0.2357\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.2422 - root_mean_squared_error: 0.2371 - val_loss: 13.5731 - val_root_mean_squared_error: 0.1427\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 13.2658 - root_mean_squared_error: 0.2285 - val_loss: 12.4429 - val_root_mean_squared_error: 0.1603\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 12.0403 - root_mean_squared_error: 0.1652 - val_loss: 11.2768 - val_root_mean_squared_error: 0.1987\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 10.8893 - root_mean_squared_error: 0.1723 - val_loss: 10.1599 - val_root_mean_squared_error: 0.1292\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 9.8067 - root_mean_squared_error: 0.1588 - val_loss: 9.1521 - val_root_mean_squared_error: 0.1426\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 8.8383 - root_mean_squared_error: 0.1606 - val_loss: 8.2452 - val_root_mean_squared_error: 0.1449\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 8.0171 - root_mean_squared_error: 0.1694 - val_loss: 7.5163 - val_root_mean_squared_error: 0.1746\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 7.2873 - root_mean_squared_error: 0.1752 - val_loss: 6.8517 - val_root_mean_squared_error: 0.1507\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 6.6711 - root_mean_squared_error: 0.1723 - val_loss: 6.2731 - val_root_mean_squared_error: 0.1491\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.1220 - root_mean_squared_error: 0.1702 - val_loss: 5.7689 - val_root_mean_squared_error: 0.1611\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.6306 - root_mean_squared_error: 0.1729 - val_loss: 5.3000 - val_root_mean_squared_error: 0.1616\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 5.1902 - root_mean_squared_error: 0.1755 - val_loss: 4.9044 - val_root_mean_squared_error: 0.1613\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 4.8279 - root_mean_squared_error: 0.1763 - val_loss: 4.5430 - val_root_mean_squared_error: 0.1620\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.4856 - root_mean_squared_error: 0.1882 - val_loss: 4.2494 - val_root_mean_squared_error: 0.1634\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.1894 - root_mean_squared_error: 0.1862 - val_loss: 3.9923 - val_root_mean_squared_error: 0.1659\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.9276 - root_mean_squared_error: 0.1813 - val_loss: 3.7113 - val_root_mean_squared_error: 0.1663\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.6676 - root_mean_squared_error: 0.1816 - val_loss: 3.4575 - val_root_mean_squared_error: 0.1670\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.4300 - root_mean_squared_error: 0.1836 - val_loss: 3.2445 - val_root_mean_squared_error: 0.1700\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.2249 - root_mean_squared_error: 0.1851 - val_loss: 3.0282 - val_root_mean_squared_error: 0.1691\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.0052 - root_mean_squared_error: 0.1836 - val_loss: 2.8524 - val_root_mean_squared_error: 0.1696\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.8320 - root_mean_squared_error: 0.1855 - val_loss: 2.6696 - val_root_mean_squared_error: 0.1716\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.6800 - root_mean_squared_error: 0.1865 - val_loss: 2.5244 - val_root_mean_squared_error: 0.1796\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.5314 - root_mean_squared_error: 0.1905 - val_loss: 2.3987 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2.4068 - root_mean_squared_error: 0.1905 - val_loss: 2.3010 - val_root_mean_squared_error: 0.1944\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.2929 - root_mean_squared_error: 0.1915 - val_loss: 2.1608 - val_root_mean_squared_error: 0.1725\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.1649 - root_mean_squared_error: 0.1915 - val_loss: 2.0313 - val_root_mean_squared_error: 0.1774\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.0548 - root_mean_squared_error: 0.1919 - val_loss: 1.9505 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.9736 - root_mean_squared_error: 0.1864 - val_loss: 1.8704 - val_root_mean_squared_error: 0.1778\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.8919 - root_mean_squared_error: 0.1894 - val_loss: 1.7849 - val_root_mean_squared_error: 0.1740\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.8140 - root_mean_squared_error: 0.1887 - val_loss: 1.7269 - val_root_mean_squared_error: 0.1713\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7467 - root_mean_squared_error: 0.1872 - val_loss: 1.6379 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6596 - root_mean_squared_error: 0.1850 - val_loss: 1.5787 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6230 - root_mean_squared_error: 0.1885 - val_loss: 1.5485 - val_root_mean_squared_error: 0.1762\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5938 - root_mean_squared_error: 0.1860 - val_loss: 1.4999 - val_root_mean_squared_error: 0.1723\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5427 - root_mean_squared_error: 0.1869 - val_loss: 1.4716 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 1.4921 - root_mean_squared_error: 0.1843 - val_loss: 1.4126 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.4671 - root_mean_squared_error: 0.1841 - val_loss: 1.3683 - val_root_mean_squared_error: 0.1736\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.3609 - root_mean_squared_error: 0.1507\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.3609 - root_mean_squared_error: 0.1507\n",
            "MODEL EVALUATION:  [1.3609254360198975, 0.15072913467884064]\n",
            "Number of epochs: 40 learning rate: 0.1 Activation Function: relu\n",
            "Model number:  544\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 47ms/step - loss: 182.4588 - root_mean_squared_error: 13.4513 - val_loss: 2.5126 - val_root_mean_squared_error: 0.1377\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.3249 - root_mean_squared_error: 0.3170 - val_loss: 4.2942 - val_root_mean_squared_error: 0.1946\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.8884 - root_mean_squared_error: 0.3566 - val_loss: 5.5143 - val_root_mean_squared_error: 0.2843\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 5.8851 - root_mean_squared_error: 0.3830 - val_loss: 6.2869 - val_root_mean_squared_error: 0.4186\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 6.3371 - root_mean_squared_error: 0.3006 - val_loss: 6.4123 - val_root_mean_squared_error: 0.1418\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.4493 - root_mean_squared_error: 0.1657 - val_loss: 6.4542 - val_root_mean_squared_error: 0.1518\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.4315 - root_mean_squared_error: 0.1643 - val_loss: 6.3640 - val_root_mean_squared_error: 0.1342\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.3190 - root_mean_squared_error: 0.1630 - val_loss: 6.2186 - val_root_mean_squared_error: 0.1354\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.1594 - root_mean_squared_error: 0.1575 - val_loss: 6.0985 - val_root_mean_squared_error: 0.2630\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.0006 - root_mean_squared_error: 0.2023 - val_loss: 5.9125 - val_root_mean_squared_error: 0.2422\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.8188 - root_mean_squared_error: 0.1834 - val_loss: 5.6976 - val_root_mean_squared_error: 0.1361\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 5.6369 - root_mean_squared_error: 0.1615 - val_loss: 5.5232 - val_root_mean_squared_error: 0.1366\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.4665 - root_mean_squared_error: 0.1679 - val_loss: 5.3529 - val_root_mean_squared_error: 0.1296\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.2993 - root_mean_squared_error: 0.1631 - val_loss: 5.1946 - val_root_mean_squared_error: 0.1373\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.1388 - root_mean_squared_error: 0.1528 - val_loss: 5.0401 - val_root_mean_squared_error: 0.1304\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.9898 - root_mean_squared_error: 0.1547 - val_loss: 4.9002 - val_root_mean_squared_error: 0.1473\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.8486 - root_mean_squared_error: 0.1571 - val_loss: 4.7619 - val_root_mean_squared_error: 0.1448\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.7185 - root_mean_squared_error: 0.1713 - val_loss: 4.6273 - val_root_mean_squared_error: 0.1324\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.5868 - root_mean_squared_error: 0.1606 - val_loss: 4.5038 - val_root_mean_squared_error: 0.1364\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 4.4656 - root_mean_squared_error: 0.1645 - val_loss: 4.3922 - val_root_mean_squared_error: 0.1583\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 4.3470 - root_mean_squared_error: 0.1583 - val_loss: 4.2716 - val_root_mean_squared_error: 0.1356\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.2348 - root_mean_squared_error: 0.1562 - val_loss: 4.1635 - val_root_mean_squared_error: 0.1375\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.1278 - root_mean_squared_error: 0.1560 - val_loss: 4.0627 - val_root_mean_squared_error: 0.1485\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.0253 - root_mean_squared_error: 0.1554 - val_loss: 3.9630 - val_root_mean_squared_error: 0.1518\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.9314 - root_mean_squared_error: 0.1701 - val_loss: 3.8645 - val_root_mean_squared_error: 0.1419\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.8326 - root_mean_squared_error: 0.1577 - val_loss: 3.7715 - val_root_mean_squared_error: 0.1409\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.7431 - root_mean_squared_error: 0.1630 - val_loss: 3.6869 - val_root_mean_squared_error: 0.1587\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.6575 - root_mean_squared_error: 0.1706 - val_loss: 3.5972 - val_root_mean_squared_error: 0.1448\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.5688 - root_mean_squared_error: 0.1599 - val_loss: 3.5169 - val_root_mean_squared_error: 0.1539\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 3.4910 - root_mean_squared_error: 0.1727 - val_loss: 3.4318 - val_root_mean_squared_error: 0.1399\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 3.4099 - root_mean_squared_error: 0.1677 - val_loss: 3.3562 - val_root_mean_squared_error: 0.1490\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.3326 - root_mean_squared_error: 0.1673 - val_loss: 3.2790 - val_root_mean_squared_error: 0.1424\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.2631 - root_mean_squared_error: 0.1827 - val_loss: 3.2073 - val_root_mean_squared_error: 0.1478\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.1853 - root_mean_squared_error: 0.1679 - val_loss: 3.1423 - val_root_mean_squared_error: 0.1664\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.1148 - root_mean_squared_error: 0.1667 - val_loss: 3.0655 - val_root_mean_squared_error: 0.1434\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.0453 - root_mean_squared_error: 0.1636 - val_loss: 3.0002 - val_root_mean_squared_error: 0.1493\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.9796 - root_mean_squared_error: 0.1664 - val_loss: 2.9357 - val_root_mean_squared_error: 0.1523\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.9135 - root_mean_squared_error: 0.1619 - val_loss: 2.8695 - val_root_mean_squared_error: 0.1442\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.8508 - root_mean_squared_error: 0.1626 - val_loss: 2.8098 - val_root_mean_squared_error: 0.1512\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.7896 - root_mean_squared_error: 0.1632 - val_loss: 2.7468 - val_root_mean_squared_error: 0.1429\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 2.7423 - root_mean_squared_error: 0.1261\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 2.7423 - root_mean_squared_error: 0.1261\n",
            "MODEL EVALUATION:  [2.742279291152954, 0.12614066898822784]\n",
            "Number of epochs: 40 learning rate: 0.1 Activation Function: relu\n",
            "Model number:  545\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 42ms/step - loss: 207.7022 - root_mean_squared_error: 14.4119 - val_loss: 0.0740 - val_root_mean_squared_error: 0.2721\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0376 - root_mean_squared_error: 0.1940 - val_loss: 0.0273 - val_root_mean_squared_error: 0.1653\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0375 - root_mean_squared_error: 0.1938 - val_loss: 0.3404 - val_root_mean_squared_error: 0.5834\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1369 - root_mean_squared_error: 0.3701 - val_loss: 0.1228 - val_root_mean_squared_error: 0.3504\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0709 - root_mean_squared_error: 0.2663 - val_loss: 0.0296 - val_root_mean_squared_error: 0.1720\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0344 - root_mean_squared_error: 0.1854 - val_loss: 0.0315 - val_root_mean_squared_error: 0.1775\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0421 - root_mean_squared_error: 0.2053 - val_loss: 0.0395 - val_root_mean_squared_error: 0.1987\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0235 - root_mean_squared_error: 0.1534 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0961\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0131 - root_mean_squared_error: 0.1145 - val_loss: 0.0165 - val_root_mean_squared_error: 0.1283\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0121 - root_mean_squared_error: 0.1099 - val_loss: 0.0177 - val_root_mean_squared_error: 0.1329\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0106 - root_mean_squared_error: 0.1027 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1012\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0092 - root_mean_squared_error: 0.0957 - val_loss: 0.0126 - val_root_mean_squared_error: 0.1121\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0087 - root_mean_squared_error: 0.0930 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1050\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0054 - root_mean_squared_error: 0.0732 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0670\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0042 - root_mean_squared_error: 0.0651 - val_loss: 0.0030 - val_root_mean_squared_error: 0.0548\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0054 - root_mean_squared_error: 0.0738 - val_loss: 0.0077 - val_root_mean_squared_error: 0.0880\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0086 - root_mean_squared_error: 0.0926 - val_loss: 0.0164 - val_root_mean_squared_error: 0.1282\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0083 - root_mean_squared_error: 0.0910 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0886\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0065 - root_mean_squared_error: 0.0806 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0491\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0030 - root_mean_squared_error: 0.0544 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0634\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0024 - root_mean_squared_error: 0.0491 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0714\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0024 - root_mean_squared_error: 0.0485 - val_loss: 0.0045 - val_root_mean_squared_error: 0.0671\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0028 - root_mean_squared_error: 0.0531 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0402\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0027 - root_mean_squared_error: 0.0517 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0400\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0020 - root_mean_squared_error: 0.0451 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0492\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0018 - root_mean_squared_error: 0.0420 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0405\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0018 - root_mean_squared_error: 0.0421 - val_loss: 0.0012 - val_root_mean_squared_error: 0.0345\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0019 - root_mean_squared_error: 0.0441 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0401\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0020 - root_mean_squared_error: 0.0445 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0377\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0023 - root_mean_squared_error: 0.0483 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0444\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0020 - root_mean_squared_error: 0.0451 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0412\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0016 - root_mean_squared_error: 0.0395 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0398\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0015 - root_mean_squared_error: 0.0383 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0396\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0014 - root_mean_squared_error: 0.0369 - val_loss: 7.5548e-04 - val_root_mean_squared_error: 0.0275\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0014 - root_mean_squared_error: 0.0370 - val_loss: 7.6200e-04 - val_root_mean_squared_error: 0.0276\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0013 - root_mean_squared_error: 0.0362 - val_loss: 0.0026 - val_root_mean_squared_error: 0.0514\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0026 - root_mean_squared_error: 0.0514 - val_loss: 6.4402e-04 - val_root_mean_squared_error: 0.0254\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0020 - root_mean_squared_error: 0.0449 - val_loss: 7.4567e-04 - val_root_mean_squared_error: 0.0273\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0020 - root_mean_squared_error: 0.0444 - val_loss: 4.6574e-04 - val_root_mean_squared_error: 0.0216\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0022 - root_mean_squared_error: 0.0474 - val_loss: 4.0858e-04 - val_root_mean_squared_error: 0.0202\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.5603e-04 - root_mean_squared_error: 0.0189\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 3.5603e-04 - root_mean_squared_error: 0.0189\n",
            "MODEL EVALUATION:  [0.0003560284967534244, 0.018868718296289444]\n",
            "Number of epochs: 40 learning rate: 0.1 Activation Function: relu\n",
            "Model number:  546\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 48ms/step - loss: 9.8771 - root_mean_squared_error: 0.5431 - val_loss: 6.7282 - val_root_mean_squared_error: 0.3059\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.2863 - root_mean_squared_error: 0.2683 - val_loss: 3.4855 - val_root_mean_squared_error: 0.2938\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.8011 - root_mean_squared_error: 0.2261 - val_loss: 2.1881 - val_root_mean_squared_error: 0.2228\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.0150 - root_mean_squared_error: 0.2181 - val_loss: 1.6559 - val_root_mean_squared_error: 0.2007\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3861 - root_mean_squared_error: 0.1982 - val_loss: 1.0217 - val_root_mean_squared_error: 0.1713\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.9122 - root_mean_squared_error: 0.1871 - val_loss: 0.7568 - val_root_mean_squared_error: 0.1719\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6578 - root_mean_squared_error: 0.1846 - val_loss: 0.5237 - val_root_mean_squared_error: 0.1717\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4730 - root_mean_squared_error: 0.1876 - val_loss: 0.3844 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3529 - root_mean_squared_error: 0.1849 - val_loss: 0.3052 - val_root_mean_squared_error: 0.1728\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2862 - root_mean_squared_error: 0.1874 - val_loss: 0.2566 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2446 - root_mean_squared_error: 0.1850 - val_loss: 0.2223 - val_root_mean_squared_error: 0.1711\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2178 - root_mean_squared_error: 0.1846 - val_loss: 0.2027 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2016 - root_mean_squared_error: 0.1845 - val_loss: 0.1917 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1917 - root_mean_squared_error: 0.1844 - val_loss: 0.1854 - val_root_mean_squared_error: 0.1708\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1893 - root_mean_squared_error: 0.1852 - val_loss: 0.1830 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1842 - root_mean_squared_error: 0.1844 - val_loss: 0.1767 - val_root_mean_squared_error: 0.1705\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1822 - root_mean_squared_error: 0.1855 - val_loss: 0.1843 - val_root_mean_squared_error: 0.1754\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1841 - root_mean_squared_error: 0.1852 - val_loss: 0.1792 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1855 - root_mean_squared_error: 0.1892 - val_loss: 0.1849 - val_root_mean_squared_error: 0.1755\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1885 - root_mean_squared_error: 0.1917 - val_loss: 0.1775 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1850 - root_mean_squared_error: 0.1916 - val_loss: 0.1788 - val_root_mean_squared_error: 0.1711\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1816 - root_mean_squared_error: 0.1854 - val_loss: 0.1827 - val_root_mean_squared_error: 0.1788\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1856 - root_mean_squared_error: 0.1879 - val_loss: 0.1828 - val_root_mean_squared_error: 0.1722\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1877 - root_mean_squared_error: 0.1944 - val_loss: 0.1847 - val_root_mean_squared_error: 0.1816\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1831 - root_mean_squared_error: 0.1886 - val_loss: 0.1748 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1802 - root_mean_squared_error: 0.1847 - val_loss: 0.1830 - val_root_mean_squared_error: 0.1816\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1839 - root_mean_squared_error: 0.1924 - val_loss: 0.1811 - val_root_mean_squared_error: 0.1801\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1843 - root_mean_squared_error: 0.1926 - val_loss: 0.1755 - val_root_mean_squared_error: 0.1714\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1773 - root_mean_squared_error: 0.1857 - val_loss: 0.1733 - val_root_mean_squared_error: 0.1726\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1763 - root_mean_squared_error: 0.1848 - val_loss: 0.1732 - val_root_mean_squared_error: 0.1719\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1775 - root_mean_squared_error: 0.1896 - val_loss: 0.1699 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1731 - root_mean_squared_error: 0.1850 - val_loss: 0.1689 - val_root_mean_squared_error: 0.1707\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1729 - root_mean_squared_error: 0.1862 - val_loss: 0.1694 - val_root_mean_squared_error: 0.1752\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1767 - root_mean_squared_error: 0.1941 - val_loss: 0.1693 - val_root_mean_squared_error: 0.1755\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1743 - root_mean_squared_error: 0.1881 - val_loss: 0.1713 - val_root_mean_squared_error: 0.1733\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1746 - root_mean_squared_error: 0.1879 - val_loss: 0.1672 - val_root_mean_squared_error: 0.1709\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1705 - root_mean_squared_error: 0.1843 - val_loss: 0.1669 - val_root_mean_squared_error: 0.1718\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1729 - root_mean_squared_error: 0.1901 - val_loss: 0.1712 - val_root_mean_squared_error: 0.1768\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1733 - root_mean_squared_error: 0.1858 - val_loss: 0.1692 - val_root_mean_squared_error: 0.1723\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1735 - root_mean_squared_error: 0.1888 - val_loss: 0.1740 - val_root_mean_squared_error: 0.1811\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1586 - root_mean_squared_error: 0.1319\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1586 - root_mean_squared_error: 0.1319\n",
            "MODEL EVALUATION:  [0.15861208736896515, 0.1319083273410797]\n",
            "Number of epochs: 40 learning rate: 0.01 Activation Function: sigmoid\n",
            "Model number:  547\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 49ms/step - loss: 1.6459 - root_mean_squared_error: 0.5618 - val_loss: 1.0688 - val_root_mean_squared_error: 0.2340\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.9554 - root_mean_squared_error: 0.3370 - val_loss: 0.6459 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5835 - root_mean_squared_error: 0.2533 - val_loss: 0.4398 - val_root_mean_squared_error: 0.2099\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3951 - root_mean_squared_error: 0.2252 - val_loss: 0.3308 - val_root_mean_squared_error: 0.2232\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2997 - root_mean_squared_error: 0.2128 - val_loss: 0.2612 - val_root_mean_squared_error: 0.2086\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2377 - root_mean_squared_error: 0.2008 - val_loss: 0.2051 - val_root_mean_squared_error: 0.1909\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1911 - root_mean_squared_error: 0.1938 - val_loss: 0.1633 - val_root_mean_squared_error: 0.1787\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1539 - root_mean_squared_error: 0.1866 - val_loss: 0.1320 - val_root_mean_squared_error: 0.1738\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1262 - root_mean_squared_error: 0.1825 - val_loss: 0.1131 - val_root_mean_squared_error: 0.1810\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1097 - root_mean_squared_error: 0.1911 - val_loss: 0.0946 - val_root_mean_squared_error: 0.1778\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0946 - root_mean_squared_error: 0.1915 - val_loss: 0.0793 - val_root_mean_squared_error: 0.1708\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0807 - root_mean_squared_error: 0.1867 - val_loss: 0.0713 - val_root_mean_squared_error: 0.1771\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0740 - root_mean_squared_error: 0.1935 - val_loss: 0.0608 - val_root_mean_squared_error: 0.1707\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0647 - root_mean_squared_error: 0.1883 - val_loss: 0.0564 - val_root_mean_squared_error: 0.1765\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0594 - root_mean_squared_error: 0.1902 - val_loss: 0.0619 - val_root_mean_squared_error: 0.2029\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0568 - root_mean_squared_error: 0.1949 - val_loss: 0.0502 - val_root_mean_squared_error: 0.1841\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0598 - root_mean_squared_error: 0.2110 - val_loss: 0.0564 - val_root_mean_squared_error: 0.2078\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0645 - root_mean_squared_error: 0.2279 - val_loss: 0.0720 - val_root_mean_squared_error: 0.2451\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0592 - root_mean_squared_error: 0.2184 - val_loss: 0.0513 - val_root_mean_squared_error: 0.2016\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0518 - root_mean_squared_error: 0.2052 - val_loss: 0.0376 - val_root_mean_squared_error: 0.1712\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0436 - root_mean_squared_error: 0.1901 - val_loss: 0.0351 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0400 - root_mean_squared_error: 0.1857 - val_loss: 0.0344 - val_root_mean_squared_error: 0.1720\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0391 - root_mean_squared_error: 0.1863 - val_loss: 0.0354 - val_root_mean_squared_error: 0.1781\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0398 - root_mean_squared_error: 0.1904 - val_loss: 0.0326 - val_root_mean_squared_error: 0.1717\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0372 - root_mean_squared_error: 0.1855 - val_loss: 0.0319 - val_root_mean_squared_error: 0.1716\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0388 - root_mean_squared_error: 0.1910 - val_loss: 0.0315 - val_root_mean_squared_error: 0.1718\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0377 - root_mean_squared_error: 0.1892 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0356 - root_mean_squared_error: 0.1845 - val_loss: 0.0309 - val_root_mean_squared_error: 0.1719\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0362 - root_mean_squared_error: 0.1870 - val_loss: 0.0311 - val_root_mean_squared_error: 0.1735\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0358 - root_mean_squared_error: 0.1866 - val_loss: 0.0298 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0350 - root_mean_squared_error: 0.1848 - val_loss: 0.0299 - val_root_mean_squared_error: 0.1707\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0351 - root_mean_squared_error: 0.1854 - val_loss: 0.0295 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0352 - root_mean_squared_error: 0.1861 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0348 - root_mean_squared_error: 0.1853 - val_loss: 0.0293 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0348 - root_mean_squared_error: 0.1854 - val_loss: 0.0296 - val_root_mean_squared_error: 0.1711\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0359 - root_mean_squared_error: 0.1888 - val_loss: 0.0296 - val_root_mean_squared_error: 0.1714\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0362 - root_mean_squared_error: 0.1895 - val_loss: 0.0320 - val_root_mean_squared_error: 0.1783\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0358 - root_mean_squared_error: 0.1887 - val_loss: 0.0305 - val_root_mean_squared_error: 0.1740\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0354 - root_mean_squared_error: 0.1875 - val_loss: 0.0348 - val_root_mean_squared_error: 0.1858\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0389 - root_mean_squared_error: 0.1967 - val_loss: 0.0420 - val_root_mean_squared_error: 0.2042\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0224 - root_mean_squared_error: 0.1488\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0224 - root_mean_squared_error: 0.1488\n",
            "MODEL EVALUATION:  [0.02239665947854519, 0.14877517521381378]\n",
            "Number of epochs: 40 learning rate: 0.01 Activation Function: sigmoid\n",
            "Model number:  548\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 42ms/step - loss: 0.1997 - root_mean_squared_error: 0.4469 - val_loss: 0.1348 - val_root_mean_squared_error: 0.3672\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0853 - root_mean_squared_error: 0.2920 - val_loss: 0.0554 - val_root_mean_squared_error: 0.2353\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0569 - root_mean_squared_error: 0.2385 - val_loss: 0.0300 - val_root_mean_squared_error: 0.1733\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0411 - root_mean_squared_error: 0.2028 - val_loss: 0.0320 - val_root_mean_squared_error: 0.1790\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0343 - root_mean_squared_error: 0.1851 - val_loss: 0.0323 - val_root_mean_squared_error: 0.1797\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0350 - root_mean_squared_error: 0.1871 - val_loss: 0.0302 - val_root_mean_squared_error: 0.1739\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0338 - root_mean_squared_error: 0.1838 - val_loss: 0.0275 - val_root_mean_squared_error: 0.1658\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0340 - root_mean_squared_error: 0.1844 - val_loss: 0.0272 - val_root_mean_squared_error: 0.1648\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0326 - root_mean_squared_error: 0.1807 - val_loss: 0.0281 - val_root_mean_squared_error: 0.1676\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0330 - root_mean_squared_error: 0.1818 - val_loss: 0.0268 - val_root_mean_squared_error: 0.1638\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0309 - root_mean_squared_error: 0.1757 - val_loss: 0.0276 - val_root_mean_squared_error: 0.1662\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0311 - root_mean_squared_error: 0.1762 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1570\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0289 - root_mean_squared_error: 0.1700 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1554\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0274 - root_mean_squared_error: 0.1655 - val_loss: 0.0215 - val_root_mean_squared_error: 0.1465\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0245 - root_mean_squared_error: 0.1566 - val_loss: 0.0198 - val_root_mean_squared_error: 0.1409\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0221 - root_mean_squared_error: 0.1487 - val_loss: 0.0174 - val_root_mean_squared_error: 0.1317\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0210 - root_mean_squared_error: 0.1449 - val_loss: 0.0206 - val_root_mean_squared_error: 0.1435\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0168 - root_mean_squared_error: 0.1297 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1023\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0133 - root_mean_squared_error: 0.1152 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1056\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0109 - root_mean_squared_error: 0.1045 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0908\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0102 - root_mean_squared_error: 0.1012 - val_loss: 0.0079 - val_root_mean_squared_error: 0.0890\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0097 - root_mean_squared_error: 0.0987 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0960\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0088 - root_mean_squared_error: 0.0937 - val_loss: 0.0090 - val_root_mean_squared_error: 0.0946\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0076 - root_mean_squared_error: 0.0872 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1078\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0073 - root_mean_squared_error: 0.0853 - val_loss: 0.0065 - val_root_mean_squared_error: 0.0805\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0068 - root_mean_squared_error: 0.0822 - val_loss: 0.0041 - val_root_mean_squared_error: 0.0637\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0058 - root_mean_squared_error: 0.0762 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0614\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0049 - root_mean_squared_error: 0.0704 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0570\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0043 - root_mean_squared_error: 0.0653 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0758\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0039 - root_mean_squared_error: 0.0623 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0570\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0035 - root_mean_squared_error: 0.0590 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0751\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0037 - root_mean_squared_error: 0.0605 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0935\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0043 - root_mean_squared_error: 0.0658 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0749\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0036 - root_mean_squared_error: 0.0601 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0750\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0034 - root_mean_squared_error: 0.0584 - val_loss: 0.0027 - val_root_mean_squared_error: 0.0521\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0035 - root_mean_squared_error: 0.0590 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0455\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0025 - root_mean_squared_error: 0.0499 - val_loss: 0.0038 - val_root_mean_squared_error: 0.0618\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0031 - root_mean_squared_error: 0.0556 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0478\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0023 - root_mean_squared_error: 0.0475 - val_loss: 0.0027 - val_root_mean_squared_error: 0.0516\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0032 - root_mean_squared_error: 0.0565 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0408\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0012 - root_mean_squared_error: 0.0344\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.0012 - root_mean_squared_error: 0.0344\n",
            "MODEL EVALUATION:  [0.0011865539709106088, 0.034446392208337784]\n",
            "Number of epochs: 40 learning rate: 0.01 Activation Function: sigmoid\n",
            "Model number:  549\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 47ms/step - loss: 9.5770 - root_mean_squared_error: 0.3351 - val_loss: 6.4484 - val_root_mean_squared_error: 0.1340\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.0014 - root_mean_squared_error: 0.1723 - val_loss: 3.1608 - val_root_mean_squared_error: 0.1545\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.5243 - root_mean_squared_error: 0.1671 - val_loss: 1.9203 - val_root_mean_squared_error: 0.1506\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.7303 - root_mean_squared_error: 0.1706 - val_loss: 1.3751 - val_root_mean_squared_error: 0.1625\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.1738 - root_mean_squared_error: 0.1808 - val_loss: 0.8992 - val_root_mean_squared_error: 0.1681\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.8058 - root_mean_squared_error: 0.1834 - val_loss: 0.6529 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.5715 - root_mean_squared_error: 0.1845 - val_loss: 0.4714 - val_root_mean_squared_error: 0.1710\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4252 - root_mean_squared_error: 0.1843 - val_loss: 0.3425 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3256 - root_mean_squared_error: 0.1845 - val_loss: 0.2846 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2676 - root_mean_squared_error: 0.1842 - val_loss: 0.2453 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2350 - root_mean_squared_error: 0.1845 - val_loss: 0.2168 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2128 - root_mean_squared_error: 0.1843 - val_loss: 0.2010 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1999 - root_mean_squared_error: 0.1849 - val_loss: 0.1930 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1930 - root_mean_squared_error: 0.1849 - val_loss: 0.1878 - val_root_mean_squared_error: 0.1709\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1897 - root_mean_squared_error: 0.1843 - val_loss: 0.1825 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1868 - root_mean_squared_error: 0.1843 - val_loss: 0.1783 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1829 - root_mean_squared_error: 0.1847 - val_loss: 0.1814 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1834 - root_mean_squared_error: 0.1847 - val_loss: 0.1797 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1835 - root_mean_squared_error: 0.1848 - val_loss: 0.1818 - val_root_mean_squared_error: 0.1706\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1827 - root_mean_squared_error: 0.1850 - val_loss: 0.1766 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1821 - root_mean_squared_error: 0.1844 - val_loss: 0.1811 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1831 - root_mean_squared_error: 0.1841 - val_loss: 0.1802 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1841 - root_mean_squared_error: 0.1845 - val_loss: 0.1803 - val_root_mean_squared_error: 0.1705\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1824 - root_mean_squared_error: 0.1849 - val_loss: 0.1785 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1810 - root_mean_squared_error: 0.1844 - val_loss: 0.1784 - val_root_mean_squared_error: 0.1705\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1828 - root_mean_squared_error: 0.1845 - val_loss: 0.1781 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1818 - root_mean_squared_error: 0.1852 - val_loss: 0.1797 - val_root_mean_squared_error: 0.1709\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1832 - root_mean_squared_error: 0.1869 - val_loss: 0.1794 - val_root_mean_squared_error: 0.1713\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1847 - root_mean_squared_error: 0.1844 - val_loss: 0.1813 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1847 - root_mean_squared_error: 0.1859 - val_loss: 0.1770 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1819 - root_mean_squared_error: 0.1840 - val_loss: 0.1795 - val_root_mean_squared_error: 0.1709\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1816 - root_mean_squared_error: 0.1846 - val_loss: 0.1800 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1829 - root_mean_squared_error: 0.1844 - val_loss: 0.1805 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1816 - root_mean_squared_error: 0.1843 - val_loss: 0.1789 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1833 - root_mean_squared_error: 0.1840 - val_loss: 0.1803 - val_root_mean_squared_error: 0.1708\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1841 - root_mean_squared_error: 0.1843 - val_loss: 0.1774 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1811 - root_mean_squared_error: 0.1856 - val_loss: 0.1805 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1829 - root_mean_squared_error: 0.1845 - val_loss: 0.1804 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1842 - root_mean_squared_error: 0.1843 - val_loss: 0.1824 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1830 - root_mean_squared_error: 0.1848 - val_loss: 0.1764 - val_root_mean_squared_error: 0.1702\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1667 - root_mean_squared_error: 0.1389\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1667 - root_mean_squared_error: 0.1389\n",
            "MODEL EVALUATION:  [0.16668392717838287, 0.13892023265361786]\n",
            "Number of epochs: 40 learning rate: 0.01 Activation Function: relu\n",
            "Model number:  550\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 58ms/step - loss: 1.2234 - root_mean_squared_error: 0.2474 - val_loss: 0.7345 - val_root_mean_squared_error: 0.1508\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5481 - root_mean_squared_error: 0.1371 - val_loss: 0.3279 - val_root_mean_squared_error: 0.1080\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2615 - root_mean_squared_error: 0.1280 - val_loss: 0.1779 - val_root_mean_squared_error: 0.1039\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1567 - root_mean_squared_error: 0.1210 - val_loss: 0.1284 - val_root_mean_squared_error: 0.1263\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1135 - root_mean_squared_error: 0.1227 - val_loss: 0.0892 - val_root_mean_squared_error: 0.1014\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0814 - root_mean_squared_error: 0.1136 - val_loss: 0.0631 - val_root_mean_squared_error: 0.0944\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0589 - root_mean_squared_error: 0.1062 - val_loss: 0.0458 - val_root_mean_squared_error: 0.0855\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0455 - root_mean_squared_error: 0.1024 - val_loss: 0.0369 - val_root_mean_squared_error: 0.0850\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0383 - root_mean_squared_error: 0.1037 - val_loss: 0.0322 - val_root_mean_squared_error: 0.0906\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0352 - root_mean_squared_error: 0.1096 - val_loss: 0.0275 - val_root_mean_squared_error: 0.0791\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0295 - root_mean_squared_error: 0.0961 - val_loss: 0.0267 - val_root_mean_squared_error: 0.0873\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0262 - root_mean_squared_error: 0.0876 - val_loss: 0.0231 - val_root_mean_squared_error: 0.0730\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0258 - root_mean_squared_error: 0.0912 - val_loss: 0.0216 - val_root_mean_squared_error: 0.0702\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0239 - root_mean_squared_error: 0.0861 - val_loss: 0.0211 - val_root_mean_squared_error: 0.0706\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0226 - root_mean_squared_error: 0.0813 - val_loss: 0.0267 - val_root_mean_squared_error: 0.1024\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0228 - root_mean_squared_error: 0.0833 - val_loss: 0.0240 - val_root_mean_squared_error: 0.0910\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0209 - root_mean_squared_error: 0.0757 - val_loss: 0.0218 - val_root_mean_squared_error: 0.0832\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0211 - root_mean_squared_error: 0.0813 - val_loss: 0.0235 - val_root_mean_squared_error: 0.0959\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0203 - root_mean_squared_error: 0.0798 - val_loss: 0.0177 - val_root_mean_squared_error: 0.0623\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0199 - root_mean_squared_error: 0.0773 - val_loss: 0.0172 - val_root_mean_squared_error: 0.0585\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0191 - root_mean_squared_error: 0.0738 - val_loss: 0.0181 - val_root_mean_squared_error: 0.0684\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0187 - root_mean_squared_error: 0.0731 - val_loss: 0.0180 - val_root_mean_squared_error: 0.0680\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0206 - root_mean_squared_error: 0.0844 - val_loss: 0.0219 - val_root_mean_squared_error: 0.0944\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0207 - root_mean_squared_error: 0.0889 - val_loss: 0.0175 - val_root_mean_squared_error: 0.0711\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0181 - root_mean_squared_error: 0.0765 - val_loss: 0.0189 - val_root_mean_squared_error: 0.0813\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0184 - root_mean_squared_error: 0.0772 - val_loss: 0.0279 - val_root_mean_squared_error: 0.1218\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0181 - root_mean_squared_error: 0.0727 - val_loss: 0.0155 - val_root_mean_squared_error: 0.0534\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0182 - root_mean_squared_error: 0.0756 - val_loss: 0.0168 - val_root_mean_squared_error: 0.0690\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0177 - root_mean_squared_error: 0.0773 - val_loss: 0.0171 - val_root_mean_squared_error: 0.0722\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0169 - root_mean_squared_error: 0.0697 - val_loss: 0.0154 - val_root_mean_squared_error: 0.0544\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0162 - root_mean_squared_error: 0.0603 - val_loss: 0.0159 - val_root_mean_squared_error: 0.0575\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0164 - root_mean_squared_error: 0.0632 - val_loss: 0.0181 - val_root_mean_squared_error: 0.0774\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0160 - root_mean_squared_error: 0.0645 - val_loss: 0.0147 - val_root_mean_squared_error: 0.0548\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0155 - root_mean_squared_error: 0.0608 - val_loss: 0.0195 - val_root_mean_squared_error: 0.0862\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0165 - root_mean_squared_error: 0.0665 - val_loss: 0.0143 - val_root_mean_squared_error: 0.0477\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0154 - root_mean_squared_error: 0.0596 - val_loss: 0.0173 - val_root_mean_squared_error: 0.0748\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0159 - root_mean_squared_error: 0.0653 - val_loss: 0.0163 - val_root_mean_squared_error: 0.0690\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0166 - root_mean_squared_error: 0.0714 - val_loss: 0.0160 - val_root_mean_squared_error: 0.0676\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0158 - root_mean_squared_error: 0.0673 - val_loss: 0.0142 - val_root_mean_squared_error: 0.0558\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0162 - root_mean_squared_error: 0.0709 - val_loss: 0.0140 - val_root_mean_squared_error: 0.0539\n",
            "2/2 [==============================] - 0s 11ms/step - loss: 0.0134 - root_mean_squared_error: 0.0485\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0134 - root_mean_squared_error: 0.0485\n",
            "MODEL EVALUATION:  [0.013413460925221443, 0.048486754298210144]\n",
            "Number of epochs: 40 learning rate: 0.01 Activation Function: relu\n",
            "Model number:  551\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 43ms/step - loss: 0.0753 - root_mean_squared_error: 0.2743 - val_loss: 0.0180 - val_root_mean_squared_error: 0.1341\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0130 - root_mean_squared_error: 0.1139 - val_loss: 0.0117 - val_root_mean_squared_error: 0.1082\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0101 - root_mean_squared_error: 0.1003 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1263\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0140 - root_mean_squared_error: 0.1183 - val_loss: 0.0094 - val_root_mean_squared_error: 0.0970\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0101 - root_mean_squared_error: 0.1006 - val_loss: 0.0159 - val_root_mean_squared_error: 0.1262\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0143 - root_mean_squared_error: 0.1196 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0958\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0089 - root_mean_squared_error: 0.0946 - val_loss: 0.0067 - val_root_mean_squared_error: 0.0819\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0070 - root_mean_squared_error: 0.0837 - val_loss: 0.0042 - val_root_mean_squared_error: 0.0651\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0056 - root_mean_squared_error: 0.0748 - val_loss: 0.0029 - val_root_mean_squared_error: 0.0539\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0042 - root_mean_squared_error: 0.0649 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0582\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0034 - root_mean_squared_error: 0.0586 - val_loss: 0.0047 - val_root_mean_squared_error: 0.0688\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0032 - root_mean_squared_error: 0.0562 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0765\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0034 - root_mean_squared_error: 0.0579 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0909\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0038 - root_mean_squared_error: 0.0613 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0761\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0032 - root_mean_squared_error: 0.0567 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0703\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0023 - root_mean_squared_error: 0.0484 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0441\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0018 - root_mean_squared_error: 0.0421 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0426\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0020 - root_mean_squared_error: 0.0449 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0462\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0016 - root_mean_squared_error: 0.0406 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0402\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0019 - root_mean_squared_error: 0.0432 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0448\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0016 - root_mean_squared_error: 0.0405 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0392\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0015 - root_mean_squared_error: 0.0392 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0501\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0016 - root_mean_squared_error: 0.0398 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0601\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0019 - root_mean_squared_error: 0.0437 - val_loss: 0.0011 - val_root_mean_squared_error: 0.0335\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0016 - root_mean_squared_error: 0.0396 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0440\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0025 - root_mean_squared_error: 0.0496 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0367\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0022 - root_mean_squared_error: 0.0472 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0600\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0031 - root_mean_squared_error: 0.0559 - val_loss: 0.0049 - val_root_mean_squared_error: 0.0700\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0022 - root_mean_squared_error: 0.0470 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0500\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0017 - root_mean_squared_error: 0.0417 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0374\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0013 - root_mean_squared_error: 0.0357 - val_loss: 8.7037e-04 - val_root_mean_squared_error: 0.0295\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0013 - root_mean_squared_error: 0.0362 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0391\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0017 - root_mean_squared_error: 0.0408 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0362\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0018 - root_mean_squared_error: 0.0429 - val_loss: 7.7359e-04 - val_root_mean_squared_error: 0.0278\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0018 - root_mean_squared_error: 0.0419 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0622\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0022 - root_mean_squared_error: 0.0469 - val_loss: 0.0026 - val_root_mean_squared_error: 0.0509\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0017 - root_mean_squared_error: 0.0408 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0456\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0011 - root_mean_squared_error: 0.0333 - val_loss: 6.4006e-04 - val_root_mean_squared_error: 0.0253\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 9.0476e-04 - root_mean_squared_error: 0.0301 - val_loss: 7.8116e-04 - val_root_mean_squared_error: 0.0279\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 9.5151e-04 - root_mean_squared_error: 0.0308 - val_loss: 9.7741e-04 - val_root_mean_squared_error: 0.0313\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.5944e-04 - root_mean_squared_error: 0.0257\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 6.5944e-04 - root_mean_squared_error: 0.0257\n",
            "MODEL EVALUATION:  [0.0006594410515390337, 0.025679584592580795]\n",
            "Number of epochs: 40 learning rate: 0.01 Activation Function: relu\n",
            "Model number:  552\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 51ms/step - loss: 8.5768 - root_mean_squared_error: 0.8351 - val_loss: 4.4069 - val_root_mean_squared_error: 0.6109\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.9028 - root_mean_squared_error: 0.3834 - val_loss: 3.2035 - val_root_mean_squared_error: 0.3291\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.5855 - root_mean_squared_error: 0.2621 - val_loss: 2.0347 - val_root_mean_squared_error: 0.2758\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7813 - root_mean_squared_error: 0.2347 - val_loss: 1.4093 - val_root_mean_squared_error: 0.1850\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2541 - root_mean_squared_error: 0.2077 - val_loss: 1.0151 - val_root_mean_squared_error: 0.1724\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.9293 - root_mean_squared_error: 0.1975 - val_loss: 0.8019 - val_root_mean_squared_error: 0.1926\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.7506 - root_mean_squared_error: 0.2078 - val_loss: 0.6709 - val_root_mean_squared_error: 0.2042\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6310 - root_mean_squared_error: 0.1942 - val_loss: 0.5822 - val_root_mean_squared_error: 0.1716\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5698 - root_mean_squared_error: 0.1866 - val_loss: 0.5335 - val_root_mean_squared_error: 0.1722\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.5236 - root_mean_squared_error: 0.1859 - val_loss: 0.5019 - val_root_mean_squared_error: 0.1738\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4986 - root_mean_squared_error: 0.1857 - val_loss: 0.4757 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4801 - root_mean_squared_error: 0.1862 - val_loss: 0.4731 - val_root_mean_squared_error: 0.1706\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4767 - root_mean_squared_error: 0.1844 - val_loss: 0.4722 - val_root_mean_squared_error: 0.1710\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4717 - root_mean_squared_error: 0.1868 - val_loss: 0.4623 - val_root_mean_squared_error: 0.1721\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4640 - root_mean_squared_error: 0.1847 - val_loss: 0.4623 - val_root_mean_squared_error: 0.1733\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4675 - root_mean_squared_error: 0.1912 - val_loss: 0.4657 - val_root_mean_squared_error: 0.1758\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4690 - root_mean_squared_error: 0.1904 - val_loss: 0.4613 - val_root_mean_squared_error: 0.1747\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.4642 - root_mean_squared_error: 0.1877 - val_loss: 0.4579 - val_root_mean_squared_error: 0.1705\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.4641 - root_mean_squared_error: 0.1845 - val_loss: 0.4596 - val_root_mean_squared_error: 0.1723\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4655 - root_mean_squared_error: 0.1897 - val_loss: 0.4624 - val_root_mean_squared_error: 0.1722\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4644 - root_mean_squared_error: 0.1937 - val_loss: 0.4511 - val_root_mean_squared_error: 0.1718\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4612 - root_mean_squared_error: 0.1918 - val_loss: 0.4670 - val_root_mean_squared_error: 0.1747\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4686 - root_mean_squared_error: 0.1952 - val_loss: 0.4598 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4631 - root_mean_squared_error: 0.1874 - val_loss: 0.4517 - val_root_mean_squared_error: 0.1705\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4551 - root_mean_squared_error: 0.1866 - val_loss: 0.4488 - val_root_mean_squared_error: 0.1714\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4509 - root_mean_squared_error: 0.1860 - val_loss: 0.4427 - val_root_mean_squared_error: 0.1808\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4452 - root_mean_squared_error: 0.1874 - val_loss: 0.4374 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.4425 - root_mean_squared_error: 0.1889 - val_loss: 0.4461 - val_root_mean_squared_error: 0.1767\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.4460 - root_mean_squared_error: 0.1847 - val_loss: 0.4437 - val_root_mean_squared_error: 0.1737\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4457 - root_mean_squared_error: 0.1844 - val_loss: 0.4426 - val_root_mean_squared_error: 0.1725\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4488 - root_mean_squared_error: 0.1997 - val_loss: 0.4334 - val_root_mean_squared_error: 0.1712\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4421 - root_mean_squared_error: 0.1855 - val_loss: 0.4384 - val_root_mean_squared_error: 0.1733\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4435 - root_mean_squared_error: 0.1884 - val_loss: 0.4437 - val_root_mean_squared_error: 0.1808\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4492 - root_mean_squared_error: 0.1909 - val_loss: 0.4419 - val_root_mean_squared_error: 0.1798\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4440 - root_mean_squared_error: 0.1862 - val_loss: 0.4318 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4336 - root_mean_squared_error: 0.1844 - val_loss: 0.4264 - val_root_mean_squared_error: 0.1747\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4312 - root_mean_squared_error: 0.1855 - val_loss: 0.4249 - val_root_mean_squared_error: 0.1711\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4330 - root_mean_squared_error: 0.1906 - val_loss: 0.4227 - val_root_mean_squared_error: 0.1712\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4334 - root_mean_squared_error: 0.1941 - val_loss: 0.4274 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4375 - root_mean_squared_error: 0.1946 - val_loss: 0.4397 - val_root_mean_squared_error: 0.1924\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4368 - root_mean_squared_error: 0.1846\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4368 - root_mean_squared_error: 0.1846\n",
            "MODEL EVALUATION:  [0.4367882013320923, 0.184648796916008]\n",
            "Number of epochs: 40 learning rate: 0.03 Activation Function: sigmoid\n",
            "Model number:  553\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 50ms/step - loss: 2.2966 - root_mean_squared_error: 1.0768 - val_loss: 1.3489 - val_root_mean_squared_error: 0.7038\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.0065 - root_mean_squared_error: 0.4391 - val_loss: 0.8733 - val_root_mean_squared_error: 0.3906\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.7287 - root_mean_squared_error: 0.3235 - val_loss: 0.5122 - val_root_mean_squared_error: 0.1953\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4298 - root_mean_squared_error: 0.2108 - val_loss: 0.3338 - val_root_mean_squared_error: 0.2540\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2741 - root_mean_squared_error: 0.2245 - val_loss: 0.1966 - val_root_mean_squared_error: 0.1726\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1972 - root_mean_squared_error: 0.2296 - val_loss: 0.1448 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1540 - root_mean_squared_error: 0.2251 - val_loss: 0.1417 - val_root_mean_squared_error: 0.2441\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1207 - root_mean_squared_error: 0.2155 - val_loss: 0.0920 - val_root_mean_squared_error: 0.1790\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0937 - root_mean_squared_error: 0.2105 - val_loss: 0.0714 - val_root_mean_squared_error: 0.1790\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0743 - root_mean_squared_error: 0.2000 - val_loss: 0.0726 - val_root_mean_squared_error: 0.2168\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0679 - root_mean_squared_error: 0.2119 - val_loss: 0.0612 - val_root_mean_squared_error: 0.2039\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0606 - root_mean_squared_error: 0.2096 - val_loss: 0.0440 - val_root_mean_squared_error: 0.1749\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0454 - root_mean_squared_error: 0.1833 - val_loss: 0.0388 - val_root_mean_squared_error: 0.1718\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0431 - root_mean_squared_error: 0.1877 - val_loss: 0.0353 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0411 - root_mean_squared_error: 0.1882 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1716\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0414 - root_mean_squared_error: 0.1933 - val_loss: 0.0432 - val_root_mean_squared_error: 0.2005\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0437 - root_mean_squared_error: 0.2022 - val_loss: 0.0313 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0376 - root_mean_squared_error: 0.1885 - val_loss: 0.0317 - val_root_mean_squared_error: 0.1730\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0379 - root_mean_squared_error: 0.1908 - val_loss: 0.0301 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0362 - root_mean_squared_error: 0.1875 - val_loss: 0.0342 - val_root_mean_squared_error: 0.1828\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0386 - root_mean_squared_error: 0.1944 - val_loss: 0.0296 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0385 - root_mean_squared_error: 0.1946 - val_loss: 0.0387 - val_root_mean_squared_error: 0.1945\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0478 - root_mean_squared_error: 0.2169 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1717\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0425 - root_mean_squared_error: 0.2037 - val_loss: 0.0431 - val_root_mean_squared_error: 0.2047\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0398 - root_mean_squared_error: 0.1970 - val_loss: 0.0462 - val_root_mean_squared_error: 0.2131\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0444 - root_mean_squared_error: 0.2092 - val_loss: 0.0317 - val_root_mean_squared_error: 0.1764\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0369 - root_mean_squared_error: 0.1908 - val_loss: 0.0300 - val_root_mean_squared_error: 0.1724\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0352 - root_mean_squared_error: 0.1872 - val_loss: 0.0316 - val_root_mean_squared_error: 0.1774\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0360 - root_mean_squared_error: 0.1895 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0344 - root_mean_squared_error: 0.1853 - val_loss: 0.0295 - val_root_mean_squared_error: 0.1716\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0343 - root_mean_squared_error: 0.1852 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1706\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0342 - root_mean_squared_error: 0.1848 - val_loss: 0.0320 - val_root_mean_squared_error: 0.1785\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0401 - root_mean_squared_error: 0.2001 - val_loss: 0.0324 - val_root_mean_squared_error: 0.1794\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0367 - root_mean_squared_error: 0.1912 - val_loss: 0.0306 - val_root_mean_squared_error: 0.1746\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0368 - root_mean_squared_error: 0.1915 - val_loss: 0.0382 - val_root_mean_squared_error: 0.1950\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0417 - root_mean_squared_error: 0.2037 - val_loss: 0.0362 - val_root_mean_squared_error: 0.1891\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0364 - root_mean_squared_error: 0.1898 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1751\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0360 - root_mean_squared_error: 0.1895 - val_loss: 0.0319 - val_root_mean_squared_error: 0.1783\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0382 - root_mean_squared_error: 0.1953 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1707\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0361 - root_mean_squared_error: 0.1897 - val_loss: 0.0347 - val_root_mean_squared_error: 0.1857\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0183 - root_mean_squared_error: 0.1344\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0183 - root_mean_squared_error: 0.1344\n",
            "MODEL EVALUATION:  [0.018266068771481514, 0.13441601395606995]\n",
            "Number of epochs: 40 learning rate: 0.03 Activation Function: sigmoid\n",
            "Model number:  554\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 46ms/step - loss: 1.2858 - root_mean_squared_error: 1.1339 - val_loss: 0.6328 - val_root_mean_squared_error: 0.7955\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2341 - root_mean_squared_error: 0.4838 - val_loss: 0.1346 - val_root_mean_squared_error: 0.3668\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1674 - root_mean_squared_error: 0.4092 - val_loss: 0.0480 - val_root_mean_squared_error: 0.2190\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0576 - root_mean_squared_error: 0.2400 - val_loss: 0.0907 - val_root_mean_squared_error: 0.3011\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0627 - root_mean_squared_error: 0.2504 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1754\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0523 - root_mean_squared_error: 0.2286 - val_loss: 0.0399 - val_root_mean_squared_error: 0.1998\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0352 - root_mean_squared_error: 0.1875 - val_loss: 0.0371 - val_root_mean_squared_error: 0.1925\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0424 - root_mean_squared_error: 0.2059 - val_loss: 0.0296 - val_root_mean_squared_error: 0.1722\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0347 - root_mean_squared_error: 0.1862 - val_loss: 0.0304 - val_root_mean_squared_error: 0.1743\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0350 - root_mean_squared_error: 0.1871 - val_loss: 0.0294 - val_root_mean_squared_error: 0.1714\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0344 - root_mean_squared_error: 0.1854 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1705\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0340 - root_mean_squared_error: 0.1845 - val_loss: 0.0292 - val_root_mean_squared_error: 0.1709\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0346 - root_mean_squared_error: 0.1860 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1707\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0338 - root_mean_squared_error: 0.1838 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1693\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0341 - root_mean_squared_error: 0.1846 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1690\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0284 - val_root_mean_squared_error: 0.1685\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0335 - root_mean_squared_error: 0.1830 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1682\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0330 - root_mean_squared_error: 0.1817 - val_loss: 0.0279 - val_root_mean_squared_error: 0.1670\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0335 - root_mean_squared_error: 0.1831 - val_loss: 0.0276 - val_root_mean_squared_error: 0.1660\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0327 - root_mean_squared_error: 0.1807 - val_loss: 0.0269 - val_root_mean_squared_error: 0.1641\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0318 - root_mean_squared_error: 0.1782 - val_loss: 0.0258 - val_root_mean_squared_error: 0.1605\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0301 - root_mean_squared_error: 0.1734 - val_loss: 0.0245 - val_root_mean_squared_error: 0.1566\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0293 - root_mean_squared_error: 0.1713 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1527\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0273 - root_mean_squared_error: 0.1652 - val_loss: 0.0196 - val_root_mean_squared_error: 0.1398\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0265 - root_mean_squared_error: 0.1627 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1590\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0225 - root_mean_squared_error: 0.1499 - val_loss: 0.0133 - val_root_mean_squared_error: 0.1152\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0177 - root_mean_squared_error: 0.1329 - val_loss: 0.0111 - val_root_mean_squared_error: 0.1055\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0139 - root_mean_squared_error: 0.1179 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1116\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0126 - root_mean_squared_error: 0.1121 - val_loss: 0.0081 - val_root_mean_squared_error: 0.0898\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0121 - root_mean_squared_error: 0.1101 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0859\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0105 - root_mean_squared_error: 0.1022 - val_loss: 0.0181 - val_root_mean_squared_error: 0.1346\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0116 - root_mean_squared_error: 0.1076 - val_loss: 0.0132 - val_root_mean_squared_error: 0.1150\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0096 - root_mean_squared_error: 0.0982 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0734\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0088 - root_mean_squared_error: 0.0936 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0747\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0084 - root_mean_squared_error: 0.0919 - val_loss: 0.0056 - val_root_mean_squared_error: 0.0746\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0064 - root_mean_squared_error: 0.0798 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0910\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0057 - root_mean_squared_error: 0.0753 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0695\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0045 - root_mean_squared_error: 0.0669 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0563\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0043 - root_mean_squared_error: 0.0654 - val_loss: 0.0058 - val_root_mean_squared_error: 0.0760\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0041 - root_mean_squared_error: 0.0640 - val_loss: 0.0027 - val_root_mean_squared_error: 0.0524\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0025 - root_mean_squared_error: 0.0499\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0025 - root_mean_squared_error: 0.0499\n",
            "MODEL EVALUATION:  [0.00248651672154665, 0.049864985048770905]\n",
            "Number of epochs: 40 learning rate: 0.03 Activation Function: sigmoid\n",
            "Model number:  555\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 157ms/step - loss: 7.6592 - root_mean_squared_error: 0.5961 - val_loss: 4.0777 - val_root_mean_squared_error: 0.1637\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.8765 - root_mean_squared_error: 0.2107 - val_loss: 3.0125 - val_root_mean_squared_error: 0.1850\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.5715 - root_mean_squared_error: 0.1917 - val_loss: 2.0896 - val_root_mean_squared_error: 0.1725\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.8087 - root_mean_squared_error: 0.1843 - val_loss: 1.4440 - val_root_mean_squared_error: 0.1693\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2992 - root_mean_squared_error: 0.1895 - val_loss: 1.0847 - val_root_mean_squared_error: 0.1699\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.9836 - root_mean_squared_error: 0.1835 - val_loss: 0.8665 - val_root_mean_squared_error: 0.1711\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.7916 - root_mean_squared_error: 0.1868 - val_loss: 0.7124 - val_root_mean_squared_error: 0.1709\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6693 - root_mean_squared_error: 0.1900 - val_loss: 0.6074 - val_root_mean_squared_error: 0.1708\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5955 - root_mean_squared_error: 0.1859 - val_loss: 0.5552 - val_root_mean_squared_error: 0.1708\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5407 - root_mean_squared_error: 0.1843 - val_loss: 0.5405 - val_root_mean_squared_error: 0.1706\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5217 - root_mean_squared_error: 0.1849 - val_loss: 0.4962 - val_root_mean_squared_error: 0.1706\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4980 - root_mean_squared_error: 0.1844 - val_loss: 0.4700 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4779 - root_mean_squared_error: 0.1852 - val_loss: 0.4772 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4778 - root_mean_squared_error: 0.1845 - val_loss: 0.4762 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4751 - root_mean_squared_error: 0.1866 - val_loss: 0.4842 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4750 - root_mean_squared_error: 0.1840 - val_loss: 0.4755 - val_root_mean_squared_error: 0.1724\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4753 - root_mean_squared_error: 0.1861 - val_loss: 0.4547 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.4676 - root_mean_squared_error: 0.1841 - val_loss: 0.4572 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4695 - root_mean_squared_error: 0.1844 - val_loss: 0.4674 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4694 - root_mean_squared_error: 0.1855 - val_loss: 0.4859 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4766 - root_mean_squared_error: 0.1852 - val_loss: 0.4780 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4700 - root_mean_squared_error: 0.1846 - val_loss: 0.4656 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.4688 - root_mean_squared_error: 0.1850 - val_loss: 0.4640 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4759 - root_mean_squared_error: 0.1845 - val_loss: 0.4708 - val_root_mean_squared_error: 0.1708\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.4749 - root_mean_squared_error: 0.1839 - val_loss: 0.4780 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4746 - root_mean_squared_error: 0.1851 - val_loss: 0.4658 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4731 - root_mean_squared_error: 0.1852 - val_loss: 0.4667 - val_root_mean_squared_error: 0.1706\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4733 - root_mean_squared_error: 0.1891 - val_loss: 0.4753 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4808 - root_mean_squared_error: 0.1920 - val_loss: 0.4768 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4796 - root_mean_squared_error: 0.1878 - val_loss: 0.4900 - val_root_mean_squared_error: 0.1710\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4799 - root_mean_squared_error: 0.1850 - val_loss: 0.4775 - val_root_mean_squared_error: 0.1718\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4782 - root_mean_squared_error: 0.1833 - val_loss: 0.4583 - val_root_mean_squared_error: 0.1750\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.4735 - root_mean_squared_error: 0.1878 - val_loss: 0.4686 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4755 - root_mean_squared_error: 0.1853 - val_loss: 0.4780 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4752 - root_mean_squared_error: 0.1853 - val_loss: 0.4885 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4771 - root_mean_squared_error: 0.1855 - val_loss: 0.4837 - val_root_mean_squared_error: 0.1710\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4813 - root_mean_squared_error: 0.1842 - val_loss: 0.4697 - val_root_mean_squared_error: 0.1706\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.4749 - root_mean_squared_error: 0.1857 - val_loss: 0.4627 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4779 - root_mean_squared_error: 0.1846 - val_loss: 0.4729 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4804 - root_mean_squared_error: 0.1851 - val_loss: 0.4874 - val_root_mean_squared_error: 0.1705\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4781 - root_mean_squared_error: 0.1407\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.4781 - root_mean_squared_error: 0.1407\n",
            "MODEL EVALUATION:  [0.478104829788208, 0.14074793457984924]\n",
            "Number of epochs: 40 learning rate: 0.03 Activation Function: relu\n",
            "Model number:  556\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 57ms/step - loss: 1.6024 - root_mean_squared_error: 0.8471 - val_loss: 0.5627 - val_root_mean_squared_error: 0.2584\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5637 - root_mean_squared_error: 0.2033 - val_loss: 0.5406 - val_root_mean_squared_error: 0.1585\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4900 - root_mean_squared_error: 0.1580 - val_loss: 0.4170 - val_root_mean_squared_error: 0.1545\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3874 - root_mean_squared_error: 0.1582 - val_loss: 0.3529 - val_root_mean_squared_error: 0.1696\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3262 - root_mean_squared_error: 0.1666 - val_loss: 0.2819 - val_root_mean_squared_error: 0.1508\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2680 - root_mean_squared_error: 0.1664 - val_loss: 0.2290 - val_root_mean_squared_error: 0.1330\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2178 - root_mean_squared_error: 0.1507 - val_loss: 0.1924 - val_root_mean_squared_error: 0.1433\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1797 - root_mean_squared_error: 0.1461 - val_loss: 0.1565 - val_root_mean_squared_error: 0.1276\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1499 - root_mean_squared_error: 0.1401 - val_loss: 0.1316 - val_root_mean_squared_error: 0.1295\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.1272 - root_mean_squared_error: 0.1393 - val_loss: 0.1094 - val_root_mean_squared_error: 0.1141\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1072 - root_mean_squared_error: 0.1291 - val_loss: 0.0929 - val_root_mean_squared_error: 0.1068\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0915 - root_mean_squared_error: 0.1200 - val_loss: 0.0804 - val_root_mean_squared_error: 0.0993\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0792 - root_mean_squared_error: 0.1124 - val_loss: 0.0719 - val_root_mean_squared_error: 0.1028\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0685 - root_mean_squared_error: 0.1030 - val_loss: 0.0697 - val_root_mean_squared_error: 0.1240\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0622 - root_mean_squared_error: 0.1046 - val_loss: 0.0565 - val_root_mean_squared_error: 0.0947\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0543 - root_mean_squared_error: 0.0962 - val_loss: 0.0520 - val_root_mean_squared_error: 0.0988\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0506 - root_mean_squared_error: 0.0983 - val_loss: 0.0450 - val_root_mean_squared_error: 0.0815\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0481 - root_mean_squared_error: 0.1072 - val_loss: 0.0405 - val_root_mean_squared_error: 0.0824\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0410 - root_mean_squared_error: 0.0929 - val_loss: 0.0373 - val_root_mean_squared_error: 0.0804\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0380 - root_mean_squared_error: 0.0871 - val_loss: 0.0365 - val_root_mean_squared_error: 0.0812\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0350 - root_mean_squared_error: 0.0791 - val_loss: 0.0317 - val_root_mean_squared_error: 0.0674\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0329 - root_mean_squared_error: 0.0804 - val_loss: 0.0345 - val_root_mean_squared_error: 0.0948\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0323 - root_mean_squared_error: 0.0877 - val_loss: 0.0286 - val_root_mean_squared_error: 0.0753\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0326 - root_mean_squared_error: 0.1012 - val_loss: 0.0269 - val_root_mean_squared_error: 0.0776\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0322 - root_mean_squared_error: 0.1095 - val_loss: 0.0297 - val_root_mean_squared_error: 0.1003\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0287 - root_mean_squared_error: 0.0985 - val_loss: 0.0367 - val_root_mean_squared_error: 0.1324\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0310 - root_mean_squared_error: 0.1101 - val_loss: 0.0247 - val_root_mean_squared_error: 0.0776\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0277 - root_mean_squared_error: 0.0971 - val_loss: 0.0237 - val_root_mean_squared_error: 0.0788\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0249 - root_mean_squared_error: 0.0877 - val_loss: 0.0233 - val_root_mean_squared_error: 0.0831\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0253 - root_mean_squared_error: 0.0936 - val_loss: 0.0241 - val_root_mean_squared_error: 0.0845\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0240 - root_mean_squared_error: 0.0834 - val_loss: 0.0204 - val_root_mean_squared_error: 0.0593\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0225 - root_mean_squared_error: 0.0770 - val_loss: 0.0203 - val_root_mean_squared_error: 0.0669\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0225 - root_mean_squared_error: 0.0836 - val_loss: 0.0308 - val_root_mean_squared_error: 0.1244\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0242 - root_mean_squared_error: 0.0958 - val_loss: 0.0240 - val_root_mean_squared_error: 0.0977\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0247 - root_mean_squared_error: 0.1014 - val_loss: 0.0190 - val_root_mean_squared_error: 0.0687\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0202 - root_mean_squared_error: 0.0763 - val_loss: 0.0267 - val_root_mean_squared_error: 0.1090\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0213 - root_mean_squared_error: 0.0821 - val_loss: 0.0176 - val_root_mean_squared_error: 0.0576\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0220 - root_mean_squared_error: 0.0885 - val_loss: 0.0208 - val_root_mean_squared_error: 0.0805\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0209 - root_mean_squared_error: 0.0836 - val_loss: 0.0235 - val_root_mean_squared_error: 0.0995\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0210 - root_mean_squared_error: 0.0880 - val_loss: 0.0201 - val_root_mean_squared_error: 0.0847\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.0176 - root_mean_squared_error: 0.0684\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0176 - root_mean_squared_error: 0.0684\n",
            "MODEL EVALUATION:  [0.0175797026604414, 0.06839028000831604]\n",
            "Number of epochs: 40 learning rate: 0.03 Activation Function: relu\n",
            "Model number:  557\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 46ms/step - loss: 1.1278 - root_mean_squared_error: 1.0620 - val_loss: 0.0853 - val_root_mean_squared_error: 0.2921\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0377 - root_mean_squared_error: 0.1942 - val_loss: 0.0199 - val_root_mean_squared_error: 0.1409\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0258 - root_mean_squared_error: 0.1607 - val_loss: 0.0141 - val_root_mean_squared_error: 0.1189\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0224 - root_mean_squared_error: 0.1496 - val_loss: 0.0170 - val_root_mean_squared_error: 0.1303\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0229 - root_mean_squared_error: 0.1512 - val_loss: 0.0229 - val_root_mean_squared_error: 0.1514\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0214 - root_mean_squared_error: 0.1463 - val_loss: 0.0178 - val_root_mean_squared_error: 0.1335\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0194 - root_mean_squared_error: 0.1393 - val_loss: 0.0122 - val_root_mean_squared_error: 0.1104\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0177 - root_mean_squared_error: 0.1329 - val_loss: 0.0155 - val_root_mean_squared_error: 0.1246\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0126 - root_mean_squared_error: 0.1121 - val_loss: 0.0087 - val_root_mean_squared_error: 0.0932\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0094 - root_mean_squared_error: 0.0970 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0781\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0082 - root_mean_squared_error: 0.0907 - val_loss: 0.0108 - val_root_mean_squared_error: 0.1037\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0076 - root_mean_squared_error: 0.0875 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0725\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0068 - root_mean_squared_error: 0.0824 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0660\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0054 - root_mean_squared_error: 0.0735 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0734\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0044 - root_mean_squared_error: 0.0667 - val_loss: 0.0068 - val_root_mean_squared_error: 0.0824\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0040 - root_mean_squared_error: 0.0633 - val_loss: 0.0051 - val_root_mean_squared_error: 0.0717\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0035 - root_mean_squared_error: 0.0588 - val_loss: 0.0028 - val_root_mean_squared_error: 0.0531\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0028 - root_mean_squared_error: 0.0530 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0563\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0024 - root_mean_squared_error: 0.0493 - val_loss: 0.0028 - val_root_mean_squared_error: 0.0529\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0023 - root_mean_squared_error: 0.0478 - val_loss: 0.0032 - val_root_mean_squared_error: 0.0566\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0021 - root_mean_squared_error: 0.0463 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0494\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0019 - root_mean_squared_error: 0.0434 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0449\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0021 - root_mean_squared_error: 0.0458 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0463\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0018 - root_mean_squared_error: 0.0430 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0690\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0040 - root_mean_squared_error: 0.0634 - val_loss: 0.0066 - val_root_mean_squared_error: 0.0811\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0046 - root_mean_squared_error: 0.0678 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0449\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0026 - root_mean_squared_error: 0.0509 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0607\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0024 - root_mean_squared_error: 0.0492 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0397\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0027 - root_mean_squared_error: 0.0522 - val_loss: 0.0026 - val_root_mean_squared_error: 0.0513\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0024 - root_mean_squared_error: 0.0490 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0369\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0016 - root_mean_squared_error: 0.0404 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0411\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0020 - root_mean_squared_error: 0.0450 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0475\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0020 - root_mean_squared_error: 0.0447 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0393\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0025 - root_mean_squared_error: 0.0502 - val_loss: 0.0012 - val_root_mean_squared_error: 0.0348\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0020 - root_mean_squared_error: 0.0452 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0400\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0014 - root_mean_squared_error: 0.0375 - val_loss: 0.0023 - val_root_mean_squared_error: 0.0475\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0014 - root_mean_squared_error: 0.0370 - val_loss: 0.0013 - val_root_mean_squared_error: 0.0360\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0013 - root_mean_squared_error: 0.0357 - val_loss: 8.3898e-04 - val_root_mean_squared_error: 0.0290\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0015 - root_mean_squared_error: 0.0386 - val_loss: 9.4305e-04 - val_root_mean_squared_error: 0.0307\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0011 - root_mean_squared_error: 0.0333 - val_loss: 8.3252e-04 - val_root_mean_squared_error: 0.0289\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.5299e-04 - root_mean_squared_error: 0.0235\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 5.5299e-04 - root_mean_squared_error: 0.0235\n",
            "MODEL EVALUATION:  [0.0005529909394681454, 0.02351575903594494]\n",
            "Number of epochs: 40 learning rate: 0.03 Activation Function: relu\n",
            "Model number:  558\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 60ms/step - loss: 11.5422 - root_mean_squared_error: 0.3853 - val_loss: 11.0581 - val_root_mean_squared_error: 0.2088\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.8046 - root_mean_squared_error: 0.1938 - val_loss: 10.4142 - val_root_mean_squared_error: 0.1826\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 10.1744 - root_mean_squared_error: 0.2024 - val_loss: 9.7855 - val_root_mean_squared_error: 0.1844\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 9.5466 - root_mean_squared_error: 0.1904 - val_loss: 9.1687 - val_root_mean_squared_error: 0.1707\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 8.9413 - root_mean_squared_error: 0.1885 - val_loss: 8.5791 - val_root_mean_squared_error: 0.1809\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 8.3566 - root_mean_squared_error: 0.1927 - val_loss: 8.0023 - val_root_mean_squared_error: 0.1784\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 7.7870 - root_mean_squared_error: 0.1869 - val_loss: 7.4455 - val_root_mean_squared_error: 0.1715\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 7.2390 - root_mean_squared_error: 0.1843 - val_loss: 6.9093 - val_root_mean_squared_error: 0.1705\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 6.7093 - root_mean_squared_error: 0.1844 - val_loss: 6.3893 - val_root_mean_squared_error: 0.1705\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 6.1965 - root_mean_squared_error: 0.1850 - val_loss: 5.8888 - val_root_mean_squared_error: 0.1718\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 5.7046 - root_mean_squared_error: 0.1852 - val_loss: 5.4100 - val_root_mean_squared_error: 0.1713\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 5.2339 - root_mean_squared_error: 0.1846 - val_loss: 4.9523 - val_root_mean_squared_error: 0.1707\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.7847 - root_mean_squared_error: 0.1847 - val_loss: 4.5156 - val_root_mean_squared_error: 0.1708\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 4.3562 - root_mean_squared_error: 0.1847 - val_loss: 4.1004 - val_root_mean_squared_error: 0.1707\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.9495 - root_mean_squared_error: 0.1843 - val_loss: 3.7062 - val_root_mean_squared_error: 0.1706\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.5636 - root_mean_squared_error: 0.1844 - val_loss: 3.3335 - val_root_mean_squared_error: 0.1709\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.1991 - root_mean_squared_error: 0.1846 - val_loss: 2.9826 - val_root_mean_squared_error: 0.1707\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.8572 - root_mean_squared_error: 0.1842 - val_loss: 2.6542 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 2.5372 - root_mean_squared_error: 0.1841 - val_loss: 2.3479 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 2.2400 - root_mean_squared_error: 0.1843 - val_loss: 2.0643 - val_root_mean_squared_error: 0.1705\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.9654 - root_mean_squared_error: 0.1847 - val_loss: 1.8038 - val_root_mean_squared_error: 0.1712\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.7135 - root_mean_squared_error: 0.1844 - val_loss: 1.5659 - val_root_mean_squared_error: 0.1706\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.4852 - root_mean_squared_error: 0.1842 - val_loss: 1.3518 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2790 - root_mean_squared_error: 0.1840 - val_loss: 1.1579 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.0944 - root_mean_squared_error: 0.1841 - val_loss: 0.9884 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.9333 - root_mean_squared_error: 0.1840 - val_loss: 0.8397 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.7930 - root_mean_squared_error: 0.1841 - val_loss: 0.7128 - val_root_mean_squared_error: 0.1705\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6746 - root_mean_squared_error: 0.1843 - val_loss: 0.6078 - val_root_mean_squared_error: 0.1706\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5789 - root_mean_squared_error: 0.1846 - val_loss: 0.5255 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5035 - root_mean_squared_error: 0.1842 - val_loss: 0.4590 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4404 - root_mean_squared_error: 0.1843 - val_loss: 0.3991 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3833 - root_mean_squared_error: 0.1841 - val_loss: 0.3482 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3351 - root_mean_squared_error: 0.1840 - val_loss: 0.3045 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2947 - root_mean_squared_error: 0.1841 - val_loss: 0.2685 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.2613 - root_mean_squared_error: 0.1841 - val_loss: 0.2372 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2310 - root_mean_squared_error: 0.1850 - val_loss: 0.2081 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2023 - root_mean_squared_error: 0.1842 - val_loss: 0.1815 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1774 - root_mean_squared_error: 0.1844 - val_loss: 0.1587 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1564 - root_mean_squared_error: 0.1853 - val_loss: 0.1394 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1374 - root_mean_squared_error: 0.1841 - val_loss: 0.1224 - val_root_mean_squared_error: 0.1703\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1128 - root_mean_squared_error: 0.1394\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1128 - root_mean_squared_error: 0.1394\n",
            "MODEL EVALUATION:  [0.11282704770565033, 0.13941337168216705]\n",
            "Number of epochs: 40 learning rate: 0.001 Activation Function: sigmoid\n",
            "Model number:  559\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 61ms/step - loss: 1.5661 - root_mean_squared_error: 0.2413 - val_loss: 1.5024 - val_root_mean_squared_error: 0.2232\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4630 - root_mean_squared_error: 0.2233 - val_loss: 1.3824 - val_root_mean_squared_error: 0.1731\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.3532 - root_mean_squared_error: 0.1976 - val_loss: 1.2896 - val_root_mean_squared_error: 0.1851\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.2555 - root_mean_squared_error: 0.1911 - val_loss: 1.1928 - val_root_mean_squared_error: 0.1717\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.1635 - root_mean_squared_error: 0.1867 - val_loss: 1.1057 - val_root_mean_squared_error: 0.1739\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.0769 - root_mean_squared_error: 0.1852 - val_loss: 1.0216 - val_root_mean_squared_error: 0.1708\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.9961 - root_mean_squared_error: 0.1856 - val_loss: 0.9438 - val_root_mean_squared_error: 0.1699\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.9200 - root_mean_squared_error: 0.1837 - val_loss: 0.8719 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.8505 - root_mean_squared_error: 0.1851 - val_loss: 0.8051 - val_root_mean_squared_error: 0.1706\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.7851 - root_mean_squared_error: 0.1838 - val_loss: 0.7429 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.7264 - root_mean_squared_error: 0.1877 - val_loss: 0.6858 - val_root_mean_squared_error: 0.1699\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.6713 - root_mean_squared_error: 0.1875 - val_loss: 0.6346 - val_root_mean_squared_error: 0.1735\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.6185 - root_mean_squared_error: 0.1827 - val_loss: 0.5858 - val_root_mean_squared_error: 0.1729\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.5732 - root_mean_squared_error: 0.1869 - val_loss: 0.5404 - val_root_mean_squared_error: 0.1699\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5292 - root_mean_squared_error: 0.1843 - val_loss: 0.4995 - val_root_mean_squared_error: 0.1700\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4900 - root_mean_squared_error: 0.1851 - val_loss: 0.4621 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4537 - root_mean_squared_error: 0.1855 - val_loss: 0.4277 - val_root_mean_squared_error: 0.1710\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4203 - root_mean_squared_error: 0.1853 - val_loss: 0.3964 - val_root_mean_squared_error: 0.1715\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3892 - root_mean_squared_error: 0.1840 - val_loss: 0.3669 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3617 - root_mean_squared_error: 0.1857 - val_loss: 0.3401 - val_root_mean_squared_error: 0.1699\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3357 - root_mean_squared_error: 0.1848 - val_loss: 0.3169 - val_root_mean_squared_error: 0.1730\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3129 - root_mean_squared_error: 0.1868 - val_loss: 0.2939 - val_root_mean_squared_error: 0.1712\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2909 - root_mean_squared_error: 0.1856 - val_loss: 0.2736 - val_root_mean_squared_error: 0.1714\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2709 - root_mean_squared_error: 0.1850 - val_loss: 0.2544 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2526 - root_mean_squared_error: 0.1843 - val_loss: 0.2375 - val_root_mean_squared_error: 0.1708\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2360 - root_mean_squared_error: 0.1842 - val_loss: 0.2214 - val_root_mean_squared_error: 0.1700\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2217 - root_mean_squared_error: 0.1870 - val_loss: 0.2071 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2080 - root_mean_squared_error: 0.1874 - val_loss: 0.1944 - val_root_mean_squared_error: 0.1718\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1943 - root_mean_squared_error: 0.1848 - val_loss: 0.1818 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1825 - root_mean_squared_error: 0.1848 - val_loss: 0.1706 - val_root_mean_squared_error: 0.1700\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1716 - root_mean_squared_error: 0.1841 - val_loss: 0.1606 - val_root_mean_squared_error: 0.1706\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1618 - root_mean_squared_error: 0.1844 - val_loss: 0.1510 - val_root_mean_squared_error: 0.1700\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1530 - root_mean_squared_error: 0.1852 - val_loss: 0.1425 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1444 - root_mean_squared_error: 0.1844 - val_loss: 0.1345 - val_root_mean_squared_error: 0.1700\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1369 - root_mean_squared_error: 0.1851 - val_loss: 0.1274 - val_root_mean_squared_error: 0.1705\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1298 - root_mean_squared_error: 0.1848 - val_loss: 0.1206 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1234 - root_mean_squared_error: 0.1849 - val_loss: 0.1143 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1173 - root_mean_squared_error: 0.1849 - val_loss: 0.1087 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1116 - root_mean_squared_error: 0.1844 - val_loss: 0.1036 - val_root_mean_squared_error: 0.1707\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1069 - root_mean_squared_error: 0.1855 - val_loss: 0.0985 - val_root_mean_squared_error: 0.1701\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0880 - root_mean_squared_error: 0.1359\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0880 - root_mean_squared_error: 0.1359\n",
            "MODEL EVALUATION:  [0.0880294069647789, 0.13588495552539825]\n",
            "Number of epochs: 40 learning rate: 0.001 Activation Function: sigmoid\n",
            "Model number:  560\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 51ms/step - loss: 0.3446 - root_mean_squared_error: 0.5870 - val_loss: 0.0622 - val_root_mean_squared_error: 0.2494\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0471 - root_mean_squared_error: 0.2170 - val_loss: 0.0664 - val_root_mean_squared_error: 0.2577\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0826 - root_mean_squared_error: 0.2875 - val_loss: 0.0781 - val_root_mean_squared_error: 0.2795\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0645 - root_mean_squared_error: 0.2540 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1837\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0372 - root_mean_squared_error: 0.1929 - val_loss: 0.0320 - val_root_mean_squared_error: 0.1788\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0397 - root_mean_squared_error: 0.1993 - val_loss: 0.0338 - val_root_mean_squared_error: 0.1838\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0368 - root_mean_squared_error: 0.1918 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0345 - root_mean_squared_error: 0.1857 - val_loss: 0.0303 - val_root_mean_squared_error: 0.1740\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0347 - root_mean_squared_error: 0.1864 - val_loss: 0.0298 - val_root_mean_squared_error: 0.1726\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0344 - root_mean_squared_error: 0.1854 - val_loss: 0.0283 - val_root_mean_squared_error: 0.1683\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0333 - root_mean_squared_error: 0.1826 - val_loss: 0.0282 - val_root_mean_squared_error: 0.1680\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0331 - root_mean_squared_error: 0.1820 - val_loss: 0.0281 - val_root_mean_squared_error: 0.1676\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0331 - root_mean_squared_error: 0.1818 - val_loss: 0.0280 - val_root_mean_squared_error: 0.1673\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0330 - root_mean_squared_error: 0.1816 - val_loss: 0.0280 - val_root_mean_squared_error: 0.1674\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0327 - root_mean_squared_error: 0.1810 - val_loss: 0.0278 - val_root_mean_squared_error: 0.1667\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0325 - root_mean_squared_error: 0.1804 - val_loss: 0.0276 - val_root_mean_squared_error: 0.1662\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0324 - root_mean_squared_error: 0.1800 - val_loss: 0.0275 - val_root_mean_squared_error: 0.1658\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0322 - root_mean_squared_error: 0.1795 - val_loss: 0.0273 - val_root_mean_squared_error: 0.1653\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0322 - root_mean_squared_error: 0.1793 - val_loss: 0.0273 - val_root_mean_squared_error: 0.1652\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0319 - root_mean_squared_error: 0.1786 - val_loss: 0.0270 - val_root_mean_squared_error: 0.1644\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0318 - root_mean_squared_error: 0.1782 - val_loss: 0.0269 - val_root_mean_squared_error: 0.1641\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0316 - root_mean_squared_error: 0.1777 - val_loss: 0.0268 - val_root_mean_squared_error: 0.1637\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0314 - root_mean_squared_error: 0.1773 - val_loss: 0.0267 - val_root_mean_squared_error: 0.1633\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0314 - root_mean_squared_error: 0.1772 - val_loss: 0.0268 - val_root_mean_squared_error: 0.1636\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0310 - root_mean_squared_error: 0.1762 - val_loss: 0.0262 - val_root_mean_squared_error: 0.1619\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0310 - root_mean_squared_error: 0.1760 - val_loss: 0.0260 - val_root_mean_squared_error: 0.1614\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0307 - root_mean_squared_error: 0.1752 - val_loss: 0.0259 - val_root_mean_squared_error: 0.1608\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0307 - root_mean_squared_error: 0.1752 - val_loss: 0.0262 - val_root_mean_squared_error: 0.1620\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0304 - root_mean_squared_error: 0.1744 - val_loss: 0.0255 - val_root_mean_squared_error: 0.1596\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0302 - root_mean_squared_error: 0.1737 - val_loss: 0.0253 - val_root_mean_squared_error: 0.1592\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0297 - root_mean_squared_error: 0.1724 - val_loss: 0.0251 - val_root_mean_squared_error: 0.1583\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0295 - root_mean_squared_error: 0.1718 - val_loss: 0.0248 - val_root_mean_squared_error: 0.1575\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0292 - root_mean_squared_error: 0.1710 - val_loss: 0.0246 - val_root_mean_squared_error: 0.1568\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0290 - root_mean_squared_error: 0.1703 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1562\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0288 - root_mean_squared_error: 0.1698 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1555\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0286 - root_mean_squared_error: 0.1692 - val_loss: 0.0242 - val_root_mean_squared_error: 0.1557\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0280 - root_mean_squared_error: 0.1672 - val_loss: 0.0235 - val_root_mean_squared_error: 0.1533\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0280 - root_mean_squared_error: 0.1673 - val_loss: 0.0232 - val_root_mean_squared_error: 0.1522\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0281 - root_mean_squared_error: 0.1676 - val_loss: 0.0230 - val_root_mean_squared_error: 0.1515\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0273 - root_mean_squared_error: 0.1652 - val_loss: 0.0226 - val_root_mean_squared_error: 0.1504\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0159 - root_mean_squared_error: 0.1263\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0159 - root_mean_squared_error: 0.1263\n",
            "MODEL EVALUATION:  [0.015949832275509834, 0.1262926459312439]\n",
            "Number of epochs: 40 learning rate: 0.001 Activation Function: sigmoid\n",
            "Model number:  561\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 46ms/step - loss: 11.5520 - root_mean_squared_error: 0.4266 - val_loss: 11.0534 - val_root_mean_squared_error: 0.2458\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.7978 - root_mean_squared_error: 0.2198 - val_loss: 10.3885 - val_root_mean_squared_error: 0.1371\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.1504 - root_mean_squared_error: 0.1575 - val_loss: 9.7674 - val_root_mean_squared_error: 0.1440\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 9.5299 - root_mean_squared_error: 0.1550 - val_loss: 9.1534 - val_root_mean_squared_error: 0.1385\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 8.9203 - root_mean_squared_error: 0.1498 - val_loss: 8.5498 - val_root_mean_squared_error: 0.1279\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 8.3272 - root_mean_squared_error: 0.1528 - val_loss: 7.9683 - val_root_mean_squared_error: 0.1314\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 7.7554 - root_mean_squared_error: 0.1592 - val_loss: 7.4086 - val_root_mean_squared_error: 0.1344\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 7.2029 - root_mean_squared_error: 0.1600 - val_loss: 6.8677 - val_root_mean_squared_error: 0.1330\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 6.6695 - root_mean_squared_error: 0.1561 - val_loss: 6.3484 - val_root_mean_squared_error: 0.1326\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 6.1582 - root_mean_squared_error: 0.1545 - val_loss: 5.8511 - val_root_mean_squared_error: 0.1349\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.6673 - root_mean_squared_error: 0.1560 - val_loss: 5.3706 - val_root_mean_squared_error: 0.1367\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 5.1959 - root_mean_squared_error: 0.1579 - val_loss: 4.9142 - val_root_mean_squared_error: 0.1387\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.7488 - root_mean_squared_error: 0.1595 - val_loss: 4.4798 - val_root_mean_squared_error: 0.1405\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 4.3229 - root_mean_squared_error: 0.1609 - val_loss: 4.0685 - val_root_mean_squared_error: 0.1425\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.9200 - root_mean_squared_error: 0.1629 - val_loss: 3.6780 - val_root_mean_squared_error: 0.1448\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.5379 - root_mean_squared_error: 0.1651 - val_loss: 3.3097 - val_root_mean_squared_error: 0.1467\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.1781 - root_mean_squared_error: 0.1661 - val_loss: 2.9621 - val_root_mean_squared_error: 0.1492\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.8379 - root_mean_squared_error: 0.1681 - val_loss: 2.6356 - val_root_mean_squared_error: 0.1517\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 2.5207 - root_mean_squared_error: 0.1717 - val_loss: 2.3317 - val_root_mean_squared_error: 0.1546\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.2256 - root_mean_squared_error: 0.1729 - val_loss: 2.0499 - val_root_mean_squared_error: 0.1562\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.9524 - root_mean_squared_error: 0.1735 - val_loss: 1.7914 - val_root_mean_squared_error: 0.1568\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.7018 - root_mean_squared_error: 0.1740 - val_loss: 1.5520 - val_root_mean_squared_error: 0.1584\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4704 - root_mean_squared_error: 0.1755 - val_loss: 1.3344 - val_root_mean_squared_error: 0.1600\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.2625 - root_mean_squared_error: 0.1768 - val_loss: 1.1415 - val_root_mean_squared_error: 0.1615\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.0780 - root_mean_squared_error: 0.1779 - val_loss: 0.9705 - val_root_mean_squared_error: 0.1627\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.9157 - root_mean_squared_error: 0.1789 - val_loss: 0.8217 - val_root_mean_squared_error: 0.1640\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.7754 - root_mean_squared_error: 0.1799 - val_loss: 0.6939 - val_root_mean_squared_error: 0.1650\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6554 - root_mean_squared_error: 0.1806 - val_loss: 0.5869 - val_root_mean_squared_error: 0.1661\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.5570 - root_mean_squared_error: 0.1815 - val_loss: 0.5019 - val_root_mean_squared_error: 0.1669\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.4799 - root_mean_squared_error: 0.1822 - val_loss: 0.4343 - val_root_mean_squared_error: 0.1675\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.4148 - root_mean_squared_error: 0.1824 - val_loss: 0.3719 - val_root_mean_squared_error: 0.1678\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3555 - root_mean_squared_error: 0.1826 - val_loss: 0.3192 - val_root_mean_squared_error: 0.1681\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.3064 - root_mean_squared_error: 0.1829 - val_loss: 0.2745 - val_root_mean_squared_error: 0.1685\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2638 - root_mean_squared_error: 0.1831 - val_loss: 0.2353 - val_root_mean_squared_error: 0.1689\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2269 - root_mean_squared_error: 0.1834 - val_loss: 0.2018 - val_root_mean_squared_error: 0.1692\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.1953 - root_mean_squared_error: 0.1836 - val_loss: 0.1730 - val_root_mean_squared_error: 0.1694\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1680 - root_mean_squared_error: 0.1837 - val_loss: 0.1479 - val_root_mean_squared_error: 0.1695\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1445 - root_mean_squared_error: 0.1838 - val_loss: 0.1274 - val_root_mean_squared_error: 0.1697\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1255 - root_mean_squared_error: 0.1839 - val_loss: 0.1108 - val_root_mean_squared_error: 0.1698\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1100 - root_mean_squared_error: 0.1840 - val_loss: 0.0969 - val_root_mean_squared_error: 0.1699\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0867 - root_mean_squared_error: 0.1368\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0867 - root_mean_squared_error: 0.1368\n",
            "MODEL EVALUATION:  [0.08671426773071289, 0.13681647181510925]\n",
            "Number of epochs: 40 learning rate: 0.001 Activation Function: relu\n",
            "Model number:  562\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 48ms/step - loss: 1.5329 - root_mean_squared_error: 0.2385 - val_loss: 1.4480 - val_root_mean_squared_error: 0.1895\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.4014 - root_mean_squared_error: 0.1775 - val_loss: 1.3219 - val_root_mean_squared_error: 0.1287\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.2873 - root_mean_squared_error: 0.1485 - val_loss: 1.2174 - val_root_mean_squared_error: 0.1145\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.1840 - root_mean_squared_error: 0.1311 - val_loss: 1.1231 - val_root_mean_squared_error: 0.1145\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.0893 - root_mean_squared_error: 0.1203 - val_loss: 1.0317 - val_root_mean_squared_error: 0.1015\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.0012 - root_mean_squared_error: 0.1124 - val_loss: 0.9471 - val_root_mean_squared_error: 0.0905\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.9206 - root_mean_squared_error: 0.1094 - val_loss: 0.8719 - val_root_mean_squared_error: 0.0956\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.8455 - root_mean_squared_error: 0.1046 - val_loss: 0.7994 - val_root_mean_squared_error: 0.0864\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7765 - root_mean_squared_error: 0.1030 - val_loss: 0.7346 - val_root_mean_squared_error: 0.0892\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.7132 - root_mean_squared_error: 0.1018 - val_loss: 0.6752 - val_root_mean_squared_error: 0.0924\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.6546 - root_mean_squared_error: 0.1008 - val_loss: 0.6177 - val_root_mean_squared_error: 0.0811\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.6009 - root_mean_squared_error: 0.0996 - val_loss: 0.5697 - val_root_mean_squared_error: 0.0960\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.5517 - root_mean_squared_error: 0.0995 - val_loss: 0.5209 - val_root_mean_squared_error: 0.0845\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.5063 - root_mean_squared_error: 0.0978 - val_loss: 0.4785 - val_root_mean_squared_error: 0.0860\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.4649 - root_mean_squared_error: 0.0970 - val_loss: 0.4388 - val_root_mean_squared_error: 0.0829\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.4267 - root_mean_squared_error: 0.0946 - val_loss: 0.4031 - val_root_mean_squared_error: 0.0837\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.3918 - root_mean_squared_error: 0.0937 - val_loss: 0.3696 - val_root_mean_squared_error: 0.0799\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3599 - root_mean_squared_error: 0.0929 - val_loss: 0.3399 - val_root_mean_squared_error: 0.0821\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3306 - root_mean_squared_error: 0.0917 - val_loss: 0.3121 - val_root_mean_squared_error: 0.0795\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3037 - root_mean_squared_error: 0.0889 - val_loss: 0.2870 - val_root_mean_squared_error: 0.0795\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2791 - root_mean_squared_error: 0.0869 - val_loss: 0.2630 - val_root_mean_squared_error: 0.0727\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2568 - root_mean_squared_error: 0.0864 - val_loss: 0.2432 - val_root_mean_squared_error: 0.0810\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2365 - root_mean_squared_error: 0.0870 - val_loss: 0.2235 - val_root_mean_squared_error: 0.0783\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2175 - root_mean_squared_error: 0.0846 - val_loss: 0.2051 - val_root_mean_squared_error: 0.0731\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2003 - root_mean_squared_error: 0.0830 - val_loss: 0.1893 - val_root_mean_squared_error: 0.0733\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1851 - root_mean_squared_error: 0.0832 - val_loss: 0.1742 - val_root_mean_squared_error: 0.0693\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1710 - root_mean_squared_error: 0.0835 - val_loss: 0.1636 - val_root_mean_squared_error: 0.0859\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1584 - root_mean_squared_error: 0.0840 - val_loss: 0.1487 - val_root_mean_squared_error: 0.0690\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1465 - root_mean_squared_error: 0.0833 - val_loss: 0.1398 - val_root_mean_squared_error: 0.0827\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1357 - root_mean_squared_error: 0.0819 - val_loss: 0.1276 - val_root_mean_squared_error: 0.0689\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1258 - root_mean_squared_error: 0.0808 - val_loss: 0.1200 - val_root_mean_squared_error: 0.0782\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1175 - root_mean_squared_error: 0.0830 - val_loss: 0.1099 - val_root_mean_squared_error: 0.0661\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1095 - root_mean_squared_error: 0.0843 - val_loss: 0.1040 - val_root_mean_squared_error: 0.0783\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1015 - root_mean_squared_error: 0.0799 - val_loss: 0.0955 - val_root_mean_squared_error: 0.0683\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0947 - root_mean_squared_error: 0.0797 - val_loss: 0.0905 - val_root_mean_squared_error: 0.0762\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0885 - root_mean_squared_error: 0.0782 - val_loss: 0.0834 - val_root_mean_squared_error: 0.0671\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0829 - root_mean_squared_error: 0.0781 - val_loss: 0.0790 - val_root_mean_squared_error: 0.0730\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0777 - root_mean_squared_error: 0.0769 - val_loss: 0.0734 - val_root_mean_squared_error: 0.0675\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0730 - root_mean_squared_error: 0.0764 - val_loss: 0.0692 - val_root_mean_squared_error: 0.0683\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0687 - root_mean_squared_error: 0.0756 - val_loss: 0.0654 - val_root_mean_squared_error: 0.0699\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0649 - root_mean_squared_error: 0.0658\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0649 - root_mean_squared_error: 0.0658\n",
            "MODEL EVALUATION:  [0.06489070504903793, 0.06581295281648636]\n",
            "Number of epochs: 40 learning rate: 0.001 Activation Function: relu\n",
            "Model number:  563\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 42ms/step - loss: 0.0442 - root_mean_squared_error: 0.2102 - val_loss: 0.0368 - val_root_mean_squared_error: 0.1918\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0276 - root_mean_squared_error: 0.1662 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1144\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0195 - root_mean_squared_error: 0.1396 - val_loss: 0.0100 - val_root_mean_squared_error: 0.1001\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0142 - root_mean_squared_error: 0.1191 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1275\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0138 - root_mean_squared_error: 0.1176 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0913\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0117 - root_mean_squared_error: 0.1084 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1011\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0098 - root_mean_squared_error: 0.0988 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0909\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0089 - root_mean_squared_error: 0.0944 - val_loss: 0.0083 - val_root_mean_squared_error: 0.0912\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0077 - root_mean_squared_error: 0.0880 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0860\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0071 - root_mean_squared_error: 0.0845 - val_loss: 0.0061 - val_root_mean_squared_error: 0.0779\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0064 - root_mean_squared_error: 0.0801 - val_loss: 0.0074 - val_root_mean_squared_error: 0.0860\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0056 - root_mean_squared_error: 0.0751 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0735\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0047 - root_mean_squared_error: 0.0685 - val_loss: 0.0057 - val_root_mean_squared_error: 0.0754\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0041 - root_mean_squared_error: 0.0637 - val_loss: 0.0048 - val_root_mean_squared_error: 0.0696\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0035 - root_mean_squared_error: 0.0590 - val_loss: 0.0043 - val_root_mean_squared_error: 0.0656\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0030 - root_mean_squared_error: 0.0552 - val_loss: 0.0037 - val_root_mean_squared_error: 0.0608\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0028 - root_mean_squared_error: 0.0527 - val_loss: 0.0039 - val_root_mean_squared_error: 0.0622\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0024 - root_mean_squared_error: 0.0485 - val_loss: 0.0028 - val_root_mean_squared_error: 0.0530\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0022 - root_mean_squared_error: 0.0470 - val_loss: 0.0022 - val_root_mean_squared_error: 0.0467\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0021 - root_mean_squared_error: 0.0461 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0422\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0019 - root_mean_squared_error: 0.0433 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0397\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0019 - root_mean_squared_error: 0.0437 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0406\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0020 - root_mean_squared_error: 0.0447 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0505\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0015 - root_mean_squared_error: 0.0393 - val_loss: 0.0016 - val_root_mean_squared_error: 0.0401\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0014 - root_mean_squared_error: 0.0378 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0425\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0020 - root_mean_squared_error: 0.0451 - val_loss: 0.0012 - val_root_mean_squared_error: 0.0349\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0024 - root_mean_squared_error: 0.0487 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0441\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0018 - root_mean_squared_error: 0.0427 - val_loss: 0.0021 - val_root_mean_squared_error: 0.0456\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0014 - root_mean_squared_error: 0.0381 - val_loss: 0.0015 - val_root_mean_squared_error: 0.0382\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0013 - root_mean_squared_error: 0.0365 - val_loss: 0.0011 - val_root_mean_squared_error: 0.0336\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0011 - root_mean_squared_error: 0.0337 - val_loss: 0.0010 - val_root_mean_squared_error: 0.0318\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0011 - root_mean_squared_error: 0.0329 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0375\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0011 - root_mean_squared_error: 0.0339 - val_loss: 9.5040e-04 - val_root_mean_squared_error: 0.0308\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0013 - root_mean_squared_error: 0.0362 - val_loss: 0.0012 - val_root_mean_squared_error: 0.0342\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0013 - root_mean_squared_error: 0.0357 - val_loss: 0.0011 - val_root_mean_squared_error: 0.0335\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0013 - root_mean_squared_error: 0.0364 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0421\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0012 - root_mean_squared_error: 0.0344 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0368\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0011 - root_mean_squared_error: 0.0333 - val_loss: 7.9948e-04 - val_root_mean_squared_error: 0.0283\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0011 - root_mean_squared_error: 0.0332 - val_loss: 7.9696e-04 - val_root_mean_squared_error: 0.0282\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0011 - root_mean_squared_error: 0.0331 - val_loss: 0.0011 - val_root_mean_squared_error: 0.0333\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.0015 - root_mean_squared_error: 0.0381\n",
            "2/2 [==============================] - 0s 4ms/step - loss: 0.0015 - root_mean_squared_error: 0.0381\n",
            "MODEL EVALUATION:  [0.0014517651870846748, 0.03810203820466995]\n",
            "Number of epochs: 40 learning rate: 0.001 Activation Function: relu\n",
            "Model number:  564\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 48ms/step - loss: 13.9309 - root_mean_squared_error: 1.5098 - val_loss: 13.7986 - val_root_mean_squared_error: 1.4732\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 13.7472 - root_mean_squared_error: 1.4608 - val_loss: 13.6195 - val_root_mean_squared_error: 1.4247\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 13.5698 - root_mean_squared_error: 1.4125 - val_loss: 13.4467 - val_root_mean_squared_error: 1.3770\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 13.3985 - root_mean_squared_error: 1.3651 - val_loss: 13.2806 - val_root_mean_squared_error: 1.3304\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 13.2351 - root_mean_squared_error: 1.3193 - val_loss: 13.1208 - val_root_mean_squared_error: 1.2850\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 13.0777 - root_mean_squared_error: 1.2746 - val_loss: 12.9674 - val_root_mean_squared_error: 1.2410\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 12.9263 - root_mean_squared_error: 1.2312 - val_loss: 12.8203 - val_root_mean_squared_error: 1.1984\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 12.7811 - root_mean_squared_error: 1.1893 - val_loss: 12.6792 - val_root_mean_squared_error: 1.1574\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 12.6419 - root_mean_squared_error: 1.1489 - val_loss: 12.5436 - val_root_mean_squared_error: 1.1178\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 12.5078 - root_mean_squared_error: 1.1099 - val_loss: 12.4133 - val_root_mean_squared_error: 1.0797\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 12.3793 - root_mean_squared_error: 1.0725 - val_loss: 12.2879 - val_root_mean_squared_error: 1.0429\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 12.2553 - root_mean_squared_error: 1.0362 - val_loss: 12.1673 - val_root_mean_squared_error: 1.0075\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 12.1358 - root_mean_squared_error: 1.0013 - val_loss: 12.0509 - val_root_mean_squared_error: 0.9734\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 12.0212 - root_mean_squared_error: 0.9681 - val_loss: 11.9384 - val_root_mean_squared_error: 0.9405\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.9093 - root_mean_squared_error: 0.9354 - val_loss: 11.8301 - val_root_mean_squared_error: 0.9091\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 11.8023 - root_mean_squared_error: 0.9046 - val_loss: 11.7252 - val_root_mean_squared_error: 0.8787\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.6984 - root_mean_squared_error: 0.8748 - val_loss: 11.6235 - val_root_mean_squared_error: 0.8495\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.5977 - root_mean_squared_error: 0.8462 - val_loss: 11.5248 - val_root_mean_squared_error: 0.8214\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 11.4999 - root_mean_squared_error: 0.8187 - val_loss: 11.4290 - val_root_mean_squared_error: 0.7945\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 11.4050 - root_mean_squared_error: 0.7923 - val_loss: 11.3359 - val_root_mean_squared_error: 0.7686\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 11.3124 - root_mean_squared_error: 0.7668 - val_loss: 11.2455 - val_root_mean_squared_error: 0.7440\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 11.2227 - root_mean_squared_error: 0.7427 - val_loss: 11.1572 - val_root_mean_squared_error: 0.7203\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 11.1351 - root_mean_squared_error: 0.7197 - val_loss: 11.0708 - val_root_mean_squared_error: 0.6975\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 11.0492 - root_mean_squared_error: 0.6972 - val_loss: 10.9866 - val_root_mean_squared_error: 0.6757\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 10.9656 - root_mean_squared_error: 0.6760 - val_loss: 10.9040 - val_root_mean_squared_error: 0.6547\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 10.8835 - root_mean_squared_error: 0.6554 - val_loss: 10.8233 - val_root_mean_squared_error: 0.6347\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 10.8030 - root_mean_squared_error: 0.6358 - val_loss: 10.7441 - val_root_mean_squared_error: 0.6157\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 10.7245 - root_mean_squared_error: 0.6174 - val_loss: 10.6663 - val_root_mean_squared_error: 0.5973\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.6469 - root_mean_squared_error: 0.5994 - val_loss: 10.5899 - val_root_mean_squared_error: 0.5800\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 10.5707 - root_mean_squared_error: 0.5824 - val_loss: 10.5148 - val_root_mean_squared_error: 0.5634\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 10.4960 - root_mean_squared_error: 0.5662 - val_loss: 10.4408 - val_root_mean_squared_error: 0.5473\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 10.4223 - root_mean_squared_error: 0.5506 - val_loss: 10.3677 - val_root_mean_squared_error: 0.5318\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 10.3495 - root_mean_squared_error: 0.5355 - val_loss: 10.2956 - val_root_mean_squared_error: 0.5171\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.2777 - root_mean_squared_error: 0.5212 - val_loss: 10.2247 - val_root_mean_squared_error: 0.5032\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.2069 - root_mean_squared_error: 0.5076 - val_loss: 10.1547 - val_root_mean_squared_error: 0.4900\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.1370 - root_mean_squared_error: 0.4947 - val_loss: 10.0855 - val_root_mean_squared_error: 0.4773\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.0681 - root_mean_squared_error: 0.4824 - val_loss: 10.0171 - val_root_mean_squared_error: 0.4651\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 9.9999 - root_mean_squared_error: 0.4704 - val_loss: 9.9496 - val_root_mean_squared_error: 0.4535\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 9.9324 - root_mean_squared_error: 0.4591 - val_loss: 9.8827 - val_root_mean_squared_error: 0.4423\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 9.8658 - root_mean_squared_error: 0.4482 - val_loss: 9.8165 - val_root_mean_squared_error: 0.4314\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.7736 - root_mean_squared_error: 0.3784\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.7736 - root_mean_squared_error: 0.3784\n",
            "MODEL EVALUATION:  [9.77359390258789, 0.3783944845199585]\n",
            "Number of epochs: 40 learning rate: 0.0001 Activation Function: sigmoid\n",
            "Model number:  565\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 56ms/step - loss: 1.6961 - root_mean_squared_error: 0.3956 - val_loss: 1.6618 - val_root_mean_squared_error: 0.3556\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6543 - root_mean_squared_error: 0.3489 - val_loss: 1.6243 - val_root_mean_squared_error: 0.3101\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6192 - root_mean_squared_error: 0.3067 - val_loss: 1.5933 - val_root_mean_squared_error: 0.2704\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5896 - root_mean_squared_error: 0.2696 - val_loss: 1.5682 - val_root_mean_squared_error: 0.2379\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5663 - root_mean_squared_error: 0.2414 - val_loss: 1.5476 - val_root_mean_squared_error: 0.2128\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.5470 - root_mean_squared_error: 0.2201 - val_loss: 1.5306 - val_root_mean_squared_error: 0.1951\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.5307 - root_mean_squared_error: 0.2053 - val_loss: 1.5161 - val_root_mean_squared_error: 0.1841\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5165 - root_mean_squared_error: 0.1963 - val_loss: 1.5031 - val_root_mean_squared_error: 0.1778\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.5036 - root_mean_squared_error: 0.1908 - val_loss: 1.4909 - val_root_mean_squared_error: 0.1744\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4915 - root_mean_squared_error: 0.1880 - val_loss: 1.4792 - val_root_mean_squared_error: 0.1726\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4799 - root_mean_squared_error: 0.1868 - val_loss: 1.4677 - val_root_mean_squared_error: 0.1716\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4684 - root_mean_squared_error: 0.1858 - val_loss: 1.4563 - val_root_mean_squared_error: 0.1712\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4571 - root_mean_squared_error: 0.1855 - val_loss: 1.4451 - val_root_mean_squared_error: 0.1710\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4458 - root_mean_squared_error: 0.1853 - val_loss: 1.4340 - val_root_mean_squared_error: 0.1709\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4347 - root_mean_squared_error: 0.1853 - val_loss: 1.4229 - val_root_mean_squared_error: 0.1710\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4237 - root_mean_squared_error: 0.1852 - val_loss: 1.4119 - val_root_mean_squared_error: 0.1708\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4128 - root_mean_squared_error: 0.1851 - val_loss: 1.4010 - val_root_mean_squared_error: 0.1708\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.4019 - root_mean_squared_error: 0.1851 - val_loss: 1.3902 - val_root_mean_squared_error: 0.1708\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3911 - root_mean_squared_error: 0.1852 - val_loss: 1.3795 - val_root_mean_squared_error: 0.1709\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3804 - root_mean_squared_error: 0.1852 - val_loss: 1.3688 - val_root_mean_squared_error: 0.1708\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.3698 - root_mean_squared_error: 0.1851 - val_loss: 1.3582 - val_root_mean_squared_error: 0.1707\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3592 - root_mean_squared_error: 0.1850 - val_loss: 1.3477 - val_root_mean_squared_error: 0.1707\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3487 - root_mean_squared_error: 0.1850 - val_loss: 1.3373 - val_root_mean_squared_error: 0.1706\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3383 - root_mean_squared_error: 0.1849 - val_loss: 1.3269 - val_root_mean_squared_error: 0.1706\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3279 - root_mean_squared_error: 0.1848 - val_loss: 1.3166 - val_root_mean_squared_error: 0.1705\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3176 - root_mean_squared_error: 0.1847 - val_loss: 1.3063 - val_root_mean_squared_error: 0.1705\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.3074 - root_mean_squared_error: 0.1847 - val_loss: 1.2961 - val_root_mean_squared_error: 0.1705\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.2972 - root_mean_squared_error: 0.1848 - val_loss: 1.2860 - val_root_mean_squared_error: 0.1705\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.2871 - root_mean_squared_error: 0.1848 - val_loss: 1.2759 - val_root_mean_squared_error: 0.1705\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2771 - root_mean_squared_error: 0.1848 - val_loss: 1.2659 - val_root_mean_squared_error: 0.1705\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2671 - root_mean_squared_error: 0.1846 - val_loss: 1.2560 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.2572 - root_mean_squared_error: 0.1845 - val_loss: 1.2462 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.2473 - root_mean_squared_error: 0.1844 - val_loss: 1.2364 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.2376 - root_mean_squared_error: 0.1844 - val_loss: 1.2266 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.2279 - root_mean_squared_error: 0.1844 - val_loss: 1.2170 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.2182 - root_mean_squared_error: 0.1845 - val_loss: 1.2073 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.2087 - root_mean_squared_error: 0.1846 - val_loss: 1.1978 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.1991 - root_mean_squared_error: 0.1846 - val_loss: 1.1883 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.1897 - root_mean_squared_error: 0.1846 - val_loss: 1.1789 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.1803 - root_mean_squared_error: 0.1847 - val_loss: 1.1696 - val_root_mean_squared_error: 0.1704\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1584 - root_mean_squared_error: 0.1336\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1584 - root_mean_squared_error: 0.1336\n",
            "MODEL EVALUATION:  [1.1583938598632812, 0.1336248815059662]\n",
            "Number of epochs: 40 learning rate: 0.0001 Activation Function: sigmoid\n",
            "Model number:  566\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 44ms/step - loss: 0.1092 - root_mean_squared_error: 0.3305 - val_loss: 0.0911 - val_root_mean_squared_error: 0.3018\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0846 - root_mean_squared_error: 0.2909 - val_loss: 0.0694 - val_root_mean_squared_error: 0.2635\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0664 - root_mean_squared_error: 0.2576 - val_loss: 0.0532 - val_root_mean_squared_error: 0.2307\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0516 - root_mean_squared_error: 0.2272 - val_loss: 0.0425 - val_root_mean_squared_error: 0.2062\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0435 - root_mean_squared_error: 0.2086 - val_loss: 0.0355 - val_root_mean_squared_error: 0.1885\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0378 - root_mean_squared_error: 0.1944 - val_loss: 0.0318 - val_root_mean_squared_error: 0.1782\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0353 - root_mean_squared_error: 0.1878 - val_loss: 0.0299 - val_root_mean_squared_error: 0.1730\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0343 - root_mean_squared_error: 0.1851 - val_loss: 0.0293 - val_root_mean_squared_error: 0.1711\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0339 - root_mean_squared_error: 0.1842 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1707\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0341 - root_mean_squared_error: 0.1848 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1707\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0342 - root_mean_squared_error: 0.1848 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1707\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0341 - root_mean_squared_error: 0.1847 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1705\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0340 - root_mean_squared_error: 0.1845 - val_loss: 0.0291 - val_root_mean_squared_error: 0.1705\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0340 - root_mean_squared_error: 0.1844 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0340 - root_mean_squared_error: 0.1843 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0339 - root_mean_squared_error: 0.1842 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1704\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0339 - root_mean_squared_error: 0.1841 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0339 - root_mean_squared_error: 0.1842 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1703\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0339 - root_mean_squared_error: 0.1840 - val_loss: 0.0290 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0339 - root_mean_squared_error: 0.1840 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1701\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0338 - root_mean_squared_error: 0.1839 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1700\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0338 - root_mean_squared_error: 0.1839 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1699\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0338 - root_mean_squared_error: 0.1838 - val_loss: 0.0289 - val_root_mean_squared_error: 0.1699\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0338 - root_mean_squared_error: 0.1839 - val_loss: 0.0288 - val_root_mean_squared_error: 0.1698\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0337 - root_mean_squared_error: 0.1837 - val_loss: 0.0288 - val_root_mean_squared_error: 0.1698\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0337 - root_mean_squared_error: 0.1836 - val_loss: 0.0288 - val_root_mean_squared_error: 0.1698\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0337 - root_mean_squared_error: 0.1835 - val_loss: 0.0288 - val_root_mean_squared_error: 0.1698\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0337 - root_mean_squared_error: 0.1835 - val_loss: 0.0288 - val_root_mean_squared_error: 0.1697\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0336 - root_mean_squared_error: 0.1834 - val_loss: 0.0288 - val_root_mean_squared_error: 0.1697\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0336 - root_mean_squared_error: 0.1833 - val_loss: 0.0288 - val_root_mean_squared_error: 0.1696\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0336 - root_mean_squared_error: 0.1833 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1695\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0336 - root_mean_squared_error: 0.1832 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1694\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0335 - root_mean_squared_error: 0.1831 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1693\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0335 - root_mean_squared_error: 0.1831 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1692\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1692\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0335 - root_mean_squared_error: 0.1829 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1692\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0334 - root_mean_squared_error: 0.1828 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1691\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0286 - val_root_mean_squared_error: 0.1690\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0334 - root_mean_squared_error: 0.1827 - val_loss: 0.0285 - val_root_mean_squared_error: 0.1688\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0334 - root_mean_squared_error: 0.1826 - val_loss: 0.0285 - val_root_mean_squared_error: 0.1687\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0188 - root_mean_squared_error: 0.1369\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.0188 - root_mean_squared_error: 0.1369\n",
            "MODEL EVALUATION:  [0.018752848729491234, 0.13694104552268982]\n",
            "Number of epochs: 40 learning rate: 0.0001 Activation Function: sigmoid\n",
            "Model number:  567\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 52ms/step - loss: 11.8034 - root_mean_squared_error: 0.4438 - val_loss: 11.7379 - val_root_mean_squared_error: 0.4093\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 11.7119 - root_mean_squared_error: 0.4058 - val_loss: 11.6471 - val_root_mean_squared_error: 0.3691\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.6239 - root_mean_squared_error: 0.3699 - val_loss: 11.5613 - val_root_mean_squared_error: 0.3334\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.5412 - root_mean_squared_error: 0.3389 - val_loss: 11.4793 - val_root_mean_squared_error: 0.3002\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.4606 - root_mean_squared_error: 0.3093 - val_loss: 11.4010 - val_root_mean_squared_error: 0.2721\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.3835 - root_mean_squared_error: 0.2848 - val_loss: 11.3256 - val_root_mean_squared_error: 0.2483\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.3088 - root_mean_squared_error: 0.2639 - val_loss: 11.2525 - val_root_mean_squared_error: 0.2285\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.2357 - root_mean_squared_error: 0.2463 - val_loss: 11.1812 - val_root_mean_squared_error: 0.2132\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.1646 - root_mean_squared_error: 0.2330 - val_loss: 11.1111 - val_root_mean_squared_error: 0.2007\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.0942 - root_mean_squared_error: 0.2216 - val_loss: 11.0418 - val_root_mean_squared_error: 0.1919\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.0248 - root_mean_squared_error: 0.2136 - val_loss: 10.9732 - val_root_mean_squared_error: 0.1851\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.9560 - root_mean_squared_error: 0.2075 - val_loss: 10.9049 - val_root_mean_squared_error: 0.1798\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 10.8876 - root_mean_squared_error: 0.2027 - val_loss: 10.8371 - val_root_mean_squared_error: 0.1762\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.8198 - root_mean_squared_error: 0.1991 - val_loss: 10.7696 - val_root_mean_squared_error: 0.1728\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.7521 - root_mean_squared_error: 0.1959 - val_loss: 10.7023 - val_root_mean_squared_error: 0.1702\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.6848 - root_mean_squared_error: 0.1934 - val_loss: 10.6353 - val_root_mean_squared_error: 0.1682\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.6177 - root_mean_squared_error: 0.1914 - val_loss: 10.5685 - val_root_mean_squared_error: 0.1667\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.5509 - root_mean_squared_error: 0.1900 - val_loss: 10.5019 - val_root_mean_squared_error: 0.1655\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.4843 - root_mean_squared_error: 0.1886 - val_loss: 10.4356 - val_root_mean_squared_error: 0.1643\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.4179 - root_mean_squared_error: 0.1872 - val_loss: 10.3694 - val_root_mean_squared_error: 0.1630\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 10.3517 - root_mean_squared_error: 0.1860 - val_loss: 10.3034 - val_root_mean_squared_error: 0.1619\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.2858 - root_mean_squared_error: 0.1850 - val_loss: 10.2377 - val_root_mean_squared_error: 0.1612\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.2201 - root_mean_squared_error: 0.1840 - val_loss: 10.1722 - val_root_mean_squared_error: 0.1602\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.1546 - root_mean_squared_error: 0.1828 - val_loss: 10.1069 - val_root_mean_squared_error: 0.1590\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 10.0893 - root_mean_squared_error: 0.1816 - val_loss: 10.0418 - val_root_mean_squared_error: 0.1579\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 10.0241 - root_mean_squared_error: 0.1805 - val_loss: 9.9769 - val_root_mean_squared_error: 0.1573\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 9.9592 - root_mean_squared_error: 0.1800 - val_loss: 9.9121 - val_root_mean_squared_error: 0.1568\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 9.8945 - root_mean_squared_error: 0.1792 - val_loss: 9.8476 - val_root_mean_squared_error: 0.1560\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 9.8300 - root_mean_squared_error: 0.1783 - val_loss: 9.7833 - val_root_mean_squared_error: 0.1554\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 9.7657 - root_mean_squared_error: 0.1775 - val_loss: 9.7192 - val_root_mean_squared_error: 0.1547\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 9.7016 - root_mean_squared_error: 0.1770 - val_loss: 9.6553 - val_root_mean_squared_error: 0.1543\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 9.6377 - root_mean_squared_error: 0.1763 - val_loss: 9.5916 - val_root_mean_squared_error: 0.1536\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 9.5740 - root_mean_squared_error: 0.1755 - val_loss: 9.5280 - val_root_mean_squared_error: 0.1531\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 9.5103 - root_mean_squared_error: 0.1749 - val_loss: 9.4645 - val_root_mean_squared_error: 0.1526\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 9.4469 - root_mean_squared_error: 0.1742 - val_loss: 9.4013 - val_root_mean_squared_error: 0.1521\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 9.3836 - root_mean_squared_error: 0.1735 - val_loss: 9.3382 - val_root_mean_squared_error: 0.1514\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 9.3206 - root_mean_squared_error: 0.1725 - val_loss: 9.2753 - val_root_mean_squared_error: 0.1504\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 9.2576 - root_mean_squared_error: 0.1715 - val_loss: 9.2125 - val_root_mean_squared_error: 0.1496\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 9.1949 - root_mean_squared_error: 0.1706 - val_loss: 9.1500 - val_root_mean_squared_error: 0.1488\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 9.1324 - root_mean_squared_error: 0.1696 - val_loss: 9.0878 - val_root_mean_squared_error: 0.1479\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.0794 - root_mean_squared_error: 0.1161\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 9.0794 - root_mean_squared_error: 0.1161\n",
            "MODEL EVALUATION:  [9.079408645629883, 0.11605896055698395]\n",
            "Number of epochs: 40 learning rate: 0.0001 Activation Function: relu\n",
            "Model number:  568\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 52ms/step - loss: 1.6665 - root_mean_squared_error: 0.3702 - val_loss: 1.6276 - val_root_mean_squared_error: 0.3225\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.6285 - root_mean_squared_error: 0.3298 - val_loss: 1.5924 - val_root_mean_squared_error: 0.2804\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.5954 - root_mean_squared_error: 0.2923 - val_loss: 1.5646 - val_root_mean_squared_error: 0.2464\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.5691 - root_mean_squared_error: 0.2630 - val_loss: 1.5420 - val_root_mean_squared_error: 0.2197\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.5473 - root_mean_squared_error: 0.2398 - val_loss: 1.5227 - val_root_mean_squared_error: 0.1981\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5280 - root_mean_squared_error: 0.2204 - val_loss: 1.5058 - val_root_mean_squared_error: 0.1809\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.5111 - root_mean_squared_error: 0.2051 - val_loss: 1.4906 - val_root_mean_squared_error: 0.1673\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4953 - root_mean_squared_error: 0.1919 - val_loss: 1.4767 - val_root_mean_squared_error: 0.1569\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4811 - root_mean_squared_error: 0.1822 - val_loss: 1.4636 - val_root_mean_squared_error: 0.1487\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4675 - root_mean_squared_error: 0.1737 - val_loss: 1.4511 - val_root_mean_squared_error: 0.1423\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4546 - root_mean_squared_error: 0.1671 - val_loss: 1.4390 - val_root_mean_squared_error: 0.1370\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4423 - root_mean_squared_error: 0.1619 - val_loss: 1.4272 - val_root_mean_squared_error: 0.1326\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4302 - root_mean_squared_error: 0.1573 - val_loss: 1.4156 - val_root_mean_squared_error: 0.1287\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4182 - root_mean_squared_error: 0.1530 - val_loss: 1.4041 - val_root_mean_squared_error: 0.1255\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4067 - root_mean_squared_error: 0.1498 - val_loss: 1.3929 - val_root_mean_squared_error: 0.1229\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3953 - root_mean_squared_error: 0.1471 - val_loss: 1.3817 - val_root_mean_squared_error: 0.1205\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3840 - root_mean_squared_error: 0.1445 - val_loss: 1.3708 - val_root_mean_squared_error: 0.1188\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3729 - root_mean_squared_error: 0.1423 - val_loss: 1.3601 - val_root_mean_squared_error: 0.1174\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3618 - root_mean_squared_error: 0.1400 - val_loss: 1.3493 - val_root_mean_squared_error: 0.1157\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3509 - root_mean_squared_error: 0.1382 - val_loss: 1.3386 - val_root_mean_squared_error: 0.1141\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3401 - root_mean_squared_error: 0.1365 - val_loss: 1.3276 - val_root_mean_squared_error: 0.1115\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3293 - root_mean_squared_error: 0.1348 - val_loss: 1.3171 - val_root_mean_squared_error: 0.1100\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3187 - root_mean_squared_error: 0.1332 - val_loss: 1.3067 - val_root_mean_squared_error: 0.1093\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.3081 - root_mean_squared_error: 0.1317 - val_loss: 1.2962 - val_root_mean_squared_error: 0.1075\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2976 - root_mean_squared_error: 0.1302 - val_loss: 1.2860 - val_root_mean_squared_error: 0.1067\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.2873 - root_mean_squared_error: 0.1288 - val_loss: 1.2758 - val_root_mean_squared_error: 0.1057\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.2769 - root_mean_squared_error: 0.1273 - val_loss: 1.2656 - val_root_mean_squared_error: 0.1044\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.2667 - root_mean_squared_error: 0.1261 - val_loss: 1.2554 - val_root_mean_squared_error: 0.1030\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.2565 - root_mean_squared_error: 0.1249 - val_loss: 1.2453 - val_root_mean_squared_error: 0.1017\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.2464 - root_mean_squared_error: 0.1237 - val_loss: 1.2354 - val_root_mean_squared_error: 0.1012\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2364 - root_mean_squared_error: 0.1226 - val_loss: 1.2256 - val_root_mean_squared_error: 0.1004\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.2265 - root_mean_squared_error: 0.1215 - val_loss: 1.2158 - val_root_mean_squared_error: 0.0997\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.2166 - root_mean_squared_error: 0.1204 - val_loss: 1.2061 - val_root_mean_squared_error: 0.0988\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.2069 - root_mean_squared_error: 0.1194 - val_loss: 1.1965 - val_root_mean_squared_error: 0.0985\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.1972 - root_mean_squared_error: 0.1184 - val_loss: 1.1867 - val_root_mean_squared_error: 0.0968\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.1875 - root_mean_squared_error: 0.1176 - val_loss: 1.1772 - val_root_mean_squared_error: 0.0959\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.1780 - root_mean_squared_error: 0.1170 - val_loss: 1.1677 - val_root_mean_squared_error: 0.0951\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.1685 - root_mean_squared_error: 0.1161 - val_loss: 1.1584 - val_root_mean_squared_error: 0.0950\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.1591 - root_mean_squared_error: 0.1154 - val_loss: 1.1492 - val_root_mean_squared_error: 0.0950\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.1498 - root_mean_squared_error: 0.1148 - val_loss: 1.1400 - val_root_mean_squared_error: 0.0947\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.1410 - root_mean_squared_error: 0.1002\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 1.1410 - root_mean_squared_error: 0.1002\n",
            "MODEL EVALUATION:  [1.1410423517227173, 0.10015671700239182]\n",
            "Number of epochs: 40 learning rate: 0.0001 Activation Function: relu\n",
            "Model number:  569\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 50ms/step - loss: 0.2696 - root_mean_squared_error: 0.5192 - val_loss: 0.2374 - val_root_mean_squared_error: 0.4873\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2365 - root_mean_squared_error: 0.4863 - val_loss: 0.2089 - val_root_mean_squared_error: 0.4570\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2110 - root_mean_squared_error: 0.4594 - val_loss: 0.1872 - val_root_mean_squared_error: 0.4327\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1906 - root_mean_squared_error: 0.4366 - val_loss: 0.1691 - val_root_mean_squared_error: 0.4112\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1734 - root_mean_squared_error: 0.4165 - val_loss: 0.1529 - val_root_mean_squared_error: 0.3911\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1581 - root_mean_squared_error: 0.3976 - val_loss: 0.1385 - val_root_mean_squared_error: 0.3722\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1443 - root_mean_squared_error: 0.3799 - val_loss: 0.1255 - val_root_mean_squared_error: 0.3543\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1318 - root_mean_squared_error: 0.3631 - val_loss: 0.1137 - val_root_mean_squared_error: 0.3372\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1207 - root_mean_squared_error: 0.3474 - val_loss: 0.1027 - val_root_mean_squared_error: 0.3205\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.1100 - root_mean_squared_error: 0.3317 - val_loss: 0.0925 - val_root_mean_squared_error: 0.3041\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.1000 - root_mean_squared_error: 0.3162 - val_loss: 0.0828 - val_root_mean_squared_error: 0.2877\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0908 - root_mean_squared_error: 0.3014 - val_loss: 0.0732 - val_root_mean_squared_error: 0.2706\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0816 - root_mean_squared_error: 0.2856 - val_loss: 0.0644 - val_root_mean_squared_error: 0.2537\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0731 - root_mean_squared_error: 0.2703 - val_loss: 0.0561 - val_root_mean_squared_error: 0.2369\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0648 - root_mean_squared_error: 0.2546 - val_loss: 0.0484 - val_root_mean_squared_error: 0.2201\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0570 - root_mean_squared_error: 0.2388 - val_loss: 0.0410 - val_root_mean_squared_error: 0.2026\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0494 - root_mean_squared_error: 0.2224 - val_loss: 0.0344 - val_root_mean_squared_error: 0.1854\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0430 - root_mean_squared_error: 0.2075 - val_loss: 0.0287 - val_root_mean_squared_error: 0.1694\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0371 - root_mean_squared_error: 0.1926 - val_loss: 0.0244 - val_root_mean_squared_error: 0.1562\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0326 - root_mean_squared_error: 0.1805 - val_loss: 0.0211 - val_root_mean_squared_error: 0.1454\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0288 - root_mean_squared_error: 0.1697 - val_loss: 0.0188 - val_root_mean_squared_error: 0.1370\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0259 - root_mean_squared_error: 0.1608 - val_loss: 0.0172 - val_root_mean_squared_error: 0.1310\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0238 - root_mean_squared_error: 0.1541 - val_loss: 0.0162 - val_root_mean_squared_error: 0.1272\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0223 - root_mean_squared_error: 0.1495 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1249\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0212 - root_mean_squared_error: 0.1456 - val_loss: 0.0153 - val_root_mean_squared_error: 0.1235\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0204 - root_mean_squared_error: 0.1428 - val_loss: 0.0149 - val_root_mean_squared_error: 0.1221\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0197 - root_mean_squared_error: 0.1403 - val_loss: 0.0145 - val_root_mean_squared_error: 0.1204\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0191 - root_mean_squared_error: 0.1383 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1183\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0185 - root_mean_squared_error: 0.1360 - val_loss: 0.0135 - val_root_mean_squared_error: 0.1164\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0179 - root_mean_squared_error: 0.1339 - val_loss: 0.0131 - val_root_mean_squared_error: 0.1143\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0173 - root_mean_squared_error: 0.1316 - val_loss: 0.0125 - val_root_mean_squared_error: 0.1120\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0167 - root_mean_squared_error: 0.1292 - val_loss: 0.0120 - val_root_mean_squared_error: 0.1098\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0162 - root_mean_squared_error: 0.1272 - val_loss: 0.0116 - val_root_mean_squared_error: 0.1075\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0156 - root_mean_squared_error: 0.1251 - val_loss: 0.0112 - val_root_mean_squared_error: 0.1060\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0151 - root_mean_squared_error: 0.1230 - val_loss: 0.0110 - val_root_mean_squared_error: 0.1048\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0146 - root_mean_squared_error: 0.1210 - val_loss: 0.0106 - val_root_mean_squared_error: 0.1029\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0142 - root_mean_squared_error: 0.1190 - val_loss: 0.0102 - val_root_mean_squared_error: 0.1011\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0137 - root_mean_squared_error: 0.1171 - val_loss: 0.0099 - val_root_mean_squared_error: 0.0995\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0132 - root_mean_squared_error: 0.1151 - val_loss: 0.0095 - val_root_mean_squared_error: 0.0977\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0128 - root_mean_squared_error: 0.1130 - val_loss: 0.0092 - val_root_mean_squared_error: 0.0959\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0091 - root_mean_squared_error: 0.0954\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.0091 - root_mean_squared_error: 0.0954\n",
            "MODEL EVALUATION:  [0.009108870290219784, 0.09544040262699127]\n",
            "Number of epochs: 40 learning rate: 0.0001 Activation Function: relu\n",
            "Model number:  570\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 58ms/step - loss: 15.3463 - root_mean_squared_error: 1.9210 - val_loss: 15.3052 - val_root_mean_squared_error: 1.9107\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 15.3209 - root_mean_squared_error: 1.9152 - val_loss: 15.2800 - val_root_mean_squared_error: 1.9049\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 15.2957 - root_mean_squared_error: 1.9094 - val_loss: 15.2548 - val_root_mean_squared_error: 1.8991\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 15.2705 - root_mean_squared_error: 1.9036 - val_loss: 15.2297 - val_root_mean_squared_error: 1.8933\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 15.2453 - root_mean_squared_error: 1.8978 - val_loss: 15.2047 - val_root_mean_squared_error: 1.8875\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 15.2203 - root_mean_squared_error: 1.8920 - val_loss: 15.1798 - val_root_mean_squared_error: 1.8818\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 15.1955 - root_mean_squared_error: 1.8862 - val_loss: 15.1550 - val_root_mean_squared_error: 1.8760\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 15.1706 - root_mean_squared_error: 1.8805 - val_loss: 15.1303 - val_root_mean_squared_error: 1.8702\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 15.1459 - root_mean_squared_error: 1.8747 - val_loss: 15.1057 - val_root_mean_squared_error: 1.8645\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 15.1213 - root_mean_squared_error: 1.8690 - val_loss: 15.0812 - val_root_mean_squared_error: 1.8588\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 15.0967 - root_mean_squared_error: 1.8633 - val_loss: 15.0568 - val_root_mean_squared_error: 1.8531\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 15.0724 - root_mean_squared_error: 1.8576 - val_loss: 15.0325 - val_root_mean_squared_error: 1.8474\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 15.0480 - root_mean_squared_error: 1.8519 - val_loss: 15.0083 - val_root_mean_squared_error: 1.8417\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 15.0238 - root_mean_squared_error: 1.8462 - val_loss: 14.9842 - val_root_mean_squared_error: 1.8360\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 14.9997 - root_mean_squared_error: 1.8405 - val_loss: 14.9602 - val_root_mean_squared_error: 1.8303\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 14.9757 - root_mean_squared_error: 1.8349 - val_loss: 14.9363 - val_root_mean_squared_error: 1.8247\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.9517 - root_mean_squared_error: 1.8293 - val_loss: 14.9124 - val_root_mean_squared_error: 1.8190\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.9278 - root_mean_squared_error: 1.8236 - val_loss: 14.8888 - val_root_mean_squared_error: 1.8134\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.9041 - root_mean_squared_error: 1.8180 - val_loss: 14.8651 - val_root_mean_squared_error: 1.8078\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.8805 - root_mean_squared_error: 1.8124 - val_loss: 14.8416 - val_root_mean_squared_error: 1.8022\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 14.8569 - root_mean_squared_error: 1.8068 - val_loss: 14.8181 - val_root_mean_squared_error: 1.7966\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 14.8335 - root_mean_squared_error: 1.8012 - val_loss: 14.7948 - val_root_mean_squared_error: 1.7910\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.8102 - root_mean_squared_error: 1.7957 - val_loss: 14.7715 - val_root_mean_squared_error: 1.7854\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.7868 - root_mean_squared_error: 1.7901 - val_loss: 14.7484 - val_root_mean_squared_error: 1.7799\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.7637 - root_mean_squared_error: 1.7845 - val_loss: 14.7253 - val_root_mean_squared_error: 1.7743\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 14.7406 - root_mean_squared_error: 1.7790 - val_loss: 14.7024 - val_root_mean_squared_error: 1.7688\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 14.7177 - root_mean_squared_error: 1.7735 - val_loss: 14.6795 - val_root_mean_squared_error: 1.7633\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 14.6947 - root_mean_squared_error: 1.7680 - val_loss: 14.6568 - val_root_mean_squared_error: 1.7578\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.6720 - root_mean_squared_error: 1.7625 - val_loss: 14.6341 - val_root_mean_squared_error: 1.7523\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 14.6493 - root_mean_squared_error: 1.7570 - val_loss: 14.6115 - val_root_mean_squared_error: 1.7468\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.6267 - root_mean_squared_error: 1.7516 - val_loss: 14.5890 - val_root_mean_squared_error: 1.7414\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.6042 - root_mean_squared_error: 1.7461 - val_loss: 14.5666 - val_root_mean_squared_error: 1.7359\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 14.5817 - root_mean_squared_error: 1.7407 - val_loss: 14.5443 - val_root_mean_squared_error: 1.7305\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.5594 - root_mean_squared_error: 1.7352 - val_loss: 14.5221 - val_root_mean_squared_error: 1.7250\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 14.5372 - root_mean_squared_error: 1.7298 - val_loss: 14.4999 - val_root_mean_squared_error: 1.7196\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 14.5150 - root_mean_squared_error: 1.7244 - val_loss: 14.4779 - val_root_mean_squared_error: 1.7142\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.4930 - root_mean_squared_error: 1.7190 - val_loss: 14.4560 - val_root_mean_squared_error: 1.7088\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.4711 - root_mean_squared_error: 1.7136 - val_loss: 14.4341 - val_root_mean_squared_error: 1.7034\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 14.4491 - root_mean_squared_error: 1.7082 - val_loss: 14.4123 - val_root_mean_squared_error: 1.6981\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 14.4273 - root_mean_squared_error: 1.7029 - val_loss: 14.3906 - val_root_mean_squared_error: 1.6927\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 14.2419 - root_mean_squared_error: 1.6482\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 14.2419 - root_mean_squared_error: 1.6482\n",
            "MODEL EVALUATION:  [14.241887092590332, 1.6481865644454956]\n",
            "Number of epochs: 40 learning rate: 1e-05 Activation Function: sigmoid\n",
            "Model number:  571\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 55ms/step - loss: 3.3974 - root_mean_squared_error: 1.3616 - val_loss: 3.3677 - val_root_mean_squared_error: 1.3508\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.3820 - root_mean_squared_error: 1.3561 - val_loss: 3.3524 - val_root_mean_squared_error: 1.3452\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.3667 - root_mean_squared_error: 1.3505 - val_loss: 3.3372 - val_root_mean_squared_error: 1.3396\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.3515 - root_mean_squared_error: 1.3450 - val_loss: 3.3221 - val_root_mean_squared_error: 1.3341\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.3363 - root_mean_squared_error: 1.3395 - val_loss: 3.3070 - val_root_mean_squared_error: 1.3286\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.3213 - root_mean_squared_error: 1.3340 - val_loss: 3.2920 - val_root_mean_squared_error: 1.3230\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.3062 - root_mean_squared_error: 1.3284 - val_loss: 3.2772 - val_root_mean_squared_error: 1.3175\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 3.2914 - root_mean_squared_error: 1.3229 - val_loss: 3.2624 - val_root_mean_squared_error: 1.3120\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.2765 - root_mean_squared_error: 1.3174 - val_loss: 3.2476 - val_root_mean_squared_error: 1.3065\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.2618 - root_mean_squared_error: 1.3119 - val_loss: 3.2330 - val_root_mean_squared_error: 1.3010\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.2472 - root_mean_squared_error: 1.3065 - val_loss: 3.2185 - val_root_mean_squared_error: 1.2955\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.2325 - root_mean_squared_error: 1.3009 - val_loss: 3.2041 - val_root_mean_squared_error: 1.2900\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.2182 - root_mean_squared_error: 1.2955 - val_loss: 3.1897 - val_root_mean_squared_error: 1.2846\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.2037 - root_mean_squared_error: 1.2901 - val_loss: 3.1754 - val_root_mean_squared_error: 1.2791\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.1894 - root_mean_squared_error: 1.2846 - val_loss: 3.1612 - val_root_mean_squared_error: 1.2737\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.1752 - root_mean_squared_error: 1.2792 - val_loss: 3.1471 - val_root_mean_squared_error: 1.2682\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 3.1611 - root_mean_squared_error: 1.2738 - val_loss: 3.1330 - val_root_mean_squared_error: 1.2628\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.1470 - root_mean_squared_error: 1.2684 - val_loss: 3.1191 - val_root_mean_squared_error: 1.2574\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.1331 - root_mean_squared_error: 1.2630 - val_loss: 3.1052 - val_root_mean_squared_error: 1.2520\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 3.1191 - root_mean_squared_error: 1.2576 - val_loss: 3.0915 - val_root_mean_squared_error: 1.2466\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 3.1054 - root_mean_squared_error: 1.2523 - val_loss: 3.0777 - val_root_mean_squared_error: 1.2412\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 3.0916 - root_mean_squared_error: 1.2469 - val_loss: 3.0641 - val_root_mean_squared_error: 1.2359\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.0780 - root_mean_squared_error: 1.2415 - val_loss: 3.0506 - val_root_mean_squared_error: 1.2305\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 3.0644 - root_mean_squared_error: 1.2362 - val_loss: 3.0372 - val_root_mean_squared_error: 1.2252\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.0510 - root_mean_squared_error: 1.2309 - val_loss: 3.0238 - val_root_mean_squared_error: 1.2199\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.0376 - root_mean_squared_error: 1.2255 - val_loss: 3.0105 - val_root_mean_squared_error: 1.2145\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.0243 - root_mean_squared_error: 1.2203 - val_loss: 2.9973 - val_root_mean_squared_error: 1.2092\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 3.0111 - root_mean_squared_error: 1.2149 - val_loss: 2.9842 - val_root_mean_squared_error: 1.2039\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.9979 - root_mean_squared_error: 1.2097 - val_loss: 2.9712 - val_root_mean_squared_error: 1.1986\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.9849 - root_mean_squared_error: 1.2044 - val_loss: 2.9582 - val_root_mean_squared_error: 1.1933\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.9719 - root_mean_squared_error: 1.1991 - val_loss: 2.9453 - val_root_mean_squared_error: 1.1881\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.9590 - root_mean_squared_error: 1.1939 - val_loss: 2.9325 - val_root_mean_squared_error: 1.1828\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.9462 - root_mean_squared_error: 1.1886 - val_loss: 2.9198 - val_root_mean_squared_error: 1.1776\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 2.9335 - root_mean_squared_error: 1.1834 - val_loss: 2.9071 - val_root_mean_squared_error: 1.1723\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.9208 - root_mean_squared_error: 1.1782 - val_loss: 2.8946 - val_root_mean_squared_error: 1.1671\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 2.9082 - root_mean_squared_error: 1.1729 - val_loss: 2.8821 - val_root_mean_squared_error: 1.1619\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 2.8957 - root_mean_squared_error: 1.1677 - val_loss: 2.8697 - val_root_mean_squared_error: 1.1567\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 2.8832 - root_mean_squared_error: 1.1626 - val_loss: 2.8574 - val_root_mean_squared_error: 1.1515\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.8709 - root_mean_squared_error: 1.1574 - val_loss: 2.8452 - val_root_mean_squared_error: 1.1463\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 2.8587 - root_mean_squared_error: 1.1522 - val_loss: 2.8330 - val_root_mean_squared_error: 1.1411\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.7307 - root_mean_squared_error: 1.0954\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 2.7307 - root_mean_squared_error: 1.0954\n",
            "MODEL EVALUATION:  [2.73067569732666, 1.095374345779419]\n",
            "Number of epochs: 40 learning rate: 1e-05 Activation Function: sigmoid\n",
            "Model number:  572\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 43ms/step - loss: 1.9253 - root_mean_squared_error: 1.3876 - val_loss: 1.8949 - val_root_mean_squared_error: 1.3765\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.9076 - root_mean_squared_error: 1.3812 - val_loss: 1.8772 - val_root_mean_squared_error: 1.3701\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.8901 - root_mean_squared_error: 1.3748 - val_loss: 1.8597 - val_root_mean_squared_error: 1.3637\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.8725 - root_mean_squared_error: 1.3684 - val_loss: 1.8423 - val_root_mean_squared_error: 1.3573\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.8551 - root_mean_squared_error: 1.3620 - val_loss: 1.8250 - val_root_mean_squared_error: 1.3509\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.8378 - root_mean_squared_error: 1.3556 - val_loss: 1.8079 - val_root_mean_squared_error: 1.3446\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.8207 - root_mean_squared_error: 1.3493 - val_loss: 1.7908 - val_root_mean_squared_error: 1.3382\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.8036 - root_mean_squared_error: 1.3430 - val_loss: 1.7739 - val_root_mean_squared_error: 1.3319\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7867 - root_mean_squared_error: 1.3367 - val_loss: 1.7571 - val_root_mean_squared_error: 1.3256\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7699 - root_mean_squared_error: 1.3304 - val_loss: 1.7404 - val_root_mean_squared_error: 1.3193\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7533 - root_mean_squared_error: 1.3241 - val_loss: 1.7239 - val_root_mean_squared_error: 1.3130\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7367 - root_mean_squared_error: 1.3178 - val_loss: 1.7074 - val_root_mean_squared_error: 1.3067\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.7203 - root_mean_squared_error: 1.3116 - val_loss: 1.6911 - val_root_mean_squared_error: 1.3004\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.7039 - root_mean_squared_error: 1.3053 - val_loss: 1.6750 - val_root_mean_squared_error: 1.2942\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.6877 - root_mean_squared_error: 1.2991 - val_loss: 1.6589 - val_root_mean_squared_error: 1.2880\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.6717 - root_mean_squared_error: 1.2929 - val_loss: 1.6429 - val_root_mean_squared_error: 1.2818\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6558 - root_mean_squared_error: 1.2868 - val_loss: 1.6271 - val_root_mean_squared_error: 1.2756\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6398 - root_mean_squared_error: 1.2805 - val_loss: 1.6114 - val_root_mean_squared_error: 1.2694\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.6241 - root_mean_squared_error: 1.2744 - val_loss: 1.5958 - val_root_mean_squared_error: 1.2632\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6085 - root_mean_squared_error: 1.2683 - val_loss: 1.5803 - val_root_mean_squared_error: 1.2571\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5931 - root_mean_squared_error: 1.2622 - val_loss: 1.5649 - val_root_mean_squared_error: 1.2510\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5776 - root_mean_squared_error: 1.2560 - val_loss: 1.5496 - val_root_mean_squared_error: 1.2448\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5624 - root_mean_squared_error: 1.2500 - val_loss: 1.5344 - val_root_mean_squared_error: 1.2387\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5471 - root_mean_squared_error: 1.2438 - val_loss: 1.5194 - val_root_mean_squared_error: 1.2327\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5322 - root_mean_squared_error: 1.2378 - val_loss: 1.5045 - val_root_mean_squared_error: 1.2266\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5172 - root_mean_squared_error: 1.2318 - val_loss: 1.4897 - val_root_mean_squared_error: 1.2205\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.5025 - root_mean_squared_error: 1.2257 - val_loss: 1.4750 - val_root_mean_squared_error: 1.2145\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.4877 - root_mean_squared_error: 1.2197 - val_loss: 1.4605 - val_root_mean_squared_error: 1.2085\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 1.4732 - root_mean_squared_error: 1.2138 - val_loss: 1.4460 - val_root_mean_squared_error: 1.2025\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.4587 - root_mean_squared_error: 1.2078 - val_loss: 1.4317 - val_root_mean_squared_error: 1.1965\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.4443 - root_mean_squared_error: 1.2018 - val_loss: 1.4175 - val_root_mean_squared_error: 1.1906\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4301 - root_mean_squared_error: 1.1959 - val_loss: 1.4034 - val_root_mean_squared_error: 1.1846\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.4160 - root_mean_squared_error: 1.1900 - val_loss: 1.3893 - val_root_mean_squared_error: 1.1787\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.4020 - root_mean_squared_error: 1.1841 - val_loss: 1.3754 - val_root_mean_squared_error: 1.1728\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3880 - root_mean_squared_error: 1.1781 - val_loss: 1.3616 - val_root_mean_squared_error: 1.1669\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3742 - root_mean_squared_error: 1.1723 - val_loss: 1.3479 - val_root_mean_squared_error: 1.1610\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 1.3605 - root_mean_squared_error: 1.1664 - val_loss: 1.3343 - val_root_mean_squared_error: 1.1551\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3470 - root_mean_squared_error: 1.1606 - val_loss: 1.3208 - val_root_mean_squared_error: 1.1493\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.3335 - root_mean_squared_error: 1.1548 - val_loss: 1.3075 - val_root_mean_squared_error: 1.1434\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.3201 - root_mean_squared_error: 1.1490 - val_loss: 1.2942 - val_root_mean_squared_error: 1.1376\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1924 - root_mean_squared_error: 1.0920\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1924 - root_mean_squared_error: 1.0920\n",
            "MODEL EVALUATION:  [1.1923596858978271, 1.0919522047042847]\n",
            "Number of epochs: 40 learning rate: 1e-05 Activation Function: sigmoid\n",
            "Model number:  573\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 46ms/step - loss: 11.8465 - root_mean_squared_error: 0.3264 - val_loss: 11.8319 - val_root_mean_squared_error: 0.3093\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 11.8382 - root_mean_squared_error: 0.3232 - val_loss: 11.8233 - val_root_mean_squared_error: 0.3057\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.8298 - root_mean_squared_error: 0.3200 - val_loss: 11.8148 - val_root_mean_squared_error: 0.3021\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.8214 - root_mean_squared_error: 0.3168 - val_loss: 11.8063 - val_root_mean_squared_error: 0.2985\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 11.8131 - root_mean_squared_error: 0.3137 - val_loss: 11.7978 - val_root_mean_squared_error: 0.2950\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 11.8048 - root_mean_squared_error: 0.3106 - val_loss: 11.7895 - val_root_mean_squared_error: 0.2916\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 11.7967 - root_mean_squared_error: 0.3077 - val_loss: 11.7811 - val_root_mean_squared_error: 0.2880\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 11.7884 - root_mean_squared_error: 0.3046 - val_loss: 11.7728 - val_root_mean_squared_error: 0.2847\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.7802 - root_mean_squared_error: 0.3016 - val_loss: 11.7646 - val_root_mean_squared_error: 0.2815\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.7722 - root_mean_squared_error: 0.2989 - val_loss: 11.7564 - val_root_mean_squared_error: 0.2782\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.7641 - root_mean_squared_error: 0.2960 - val_loss: 11.7482 - val_root_mean_squared_error: 0.2751\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.7560 - root_mean_squared_error: 0.2932 - val_loss: 11.7401 - val_root_mean_squared_error: 0.2720\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.7480 - root_mean_squared_error: 0.2905 - val_loss: 11.7320 - val_root_mean_squared_error: 0.2690\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 11.7400 - root_mean_squared_error: 0.2878 - val_loss: 11.7240 - val_root_mean_squared_error: 0.2660\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.7321 - root_mean_squared_error: 0.2852 - val_loss: 11.7160 - val_root_mean_squared_error: 0.2630\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.7241 - root_mean_squared_error: 0.2826 - val_loss: 11.7080 - val_root_mean_squared_error: 0.2601\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.7163 - root_mean_squared_error: 0.2801 - val_loss: 11.7001 - val_root_mean_squared_error: 0.2573\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 11.7084 - root_mean_squared_error: 0.2776 - val_loss: 11.6922 - val_root_mean_squared_error: 0.2544\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.7006 - root_mean_squared_error: 0.2751 - val_loss: 11.6843 - val_root_mean_squared_error: 0.2517\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.6928 - root_mean_squared_error: 0.2727 - val_loss: 11.6765 - val_root_mean_squared_error: 0.2490\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.6850 - root_mean_squared_error: 0.2704 - val_loss: 11.6687 - val_root_mean_squared_error: 0.2464\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 11.6773 - root_mean_squared_error: 0.2681 - val_loss: 11.6609 - val_root_mean_squared_error: 0.2440\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 11.6695 - root_mean_squared_error: 0.2659 - val_loss: 11.6532 - val_root_mean_squared_error: 0.2416\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.6619 - root_mean_squared_error: 0.2638 - val_loss: 11.6455 - val_root_mean_squared_error: 0.2391\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 11.6543 - root_mean_squared_error: 0.2617 - val_loss: 11.6378 - val_root_mean_squared_error: 0.2366\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 11.6466 - root_mean_squared_error: 0.2595 - val_loss: 11.6301 - val_root_mean_squared_error: 0.2342\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 11.6389 - root_mean_squared_error: 0.2575 - val_loss: 11.6224 - val_root_mean_squared_error: 0.2319\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.6314 - root_mean_squared_error: 0.2554 - val_loss: 11.6148 - val_root_mean_squared_error: 0.2296\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.6238 - root_mean_squared_error: 0.2535 - val_loss: 11.6072 - val_root_mean_squared_error: 0.2273\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.6162 - root_mean_squared_error: 0.2515 - val_loss: 11.5997 - val_root_mean_squared_error: 0.2252\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.6087 - root_mean_squared_error: 0.2496 - val_loss: 11.5921 - val_root_mean_squared_error: 0.2230\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 11.6012 - root_mean_squared_error: 0.2477 - val_loss: 11.5846 - val_root_mean_squared_error: 0.2210\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.5937 - root_mean_squared_error: 0.2459 - val_loss: 11.5771 - val_root_mean_squared_error: 0.2189\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 11.5862 - root_mean_squared_error: 0.2441 - val_loss: 11.5696 - val_root_mean_squared_error: 0.2169\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 11.5787 - root_mean_squared_error: 0.2423 - val_loss: 11.5622 - val_root_mean_squared_error: 0.2149\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.5713 - root_mean_squared_error: 0.2406 - val_loss: 11.5547 - val_root_mean_squared_error: 0.2130\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.5639 - root_mean_squared_error: 0.2390 - val_loss: 11.5473 - val_root_mean_squared_error: 0.2112\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.5565 - root_mean_squared_error: 0.2374 - val_loss: 11.5399 - val_root_mean_squared_error: 0.2094\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.5491 - root_mean_squared_error: 0.2358 - val_loss: 11.5326 - val_root_mean_squared_error: 0.2077\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 11.5417 - root_mean_squared_error: 0.2343 - val_loss: 11.5252 - val_root_mean_squared_error: 0.2060\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 11.5119 - root_mean_squared_error: 0.1705\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 11.5119 - root_mean_squared_error: 0.1705\n",
            "MODEL EVALUATION:  [11.511883735656738, 0.17052774131298065]\n",
            "Number of epochs: 40 learning rate: 1e-05 Activation Function: relu\n",
            "Model number:  574\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 60ms/step - loss: 1.7491 - root_mean_squared_error: 0.4516 - val_loss: 1.7390 - val_root_mean_squared_error: 0.4409\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.7436 - root_mean_squared_error: 0.4465 - val_loss: 1.7331 - val_root_mean_squared_error: 0.4353\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.7381 - root_mean_squared_error: 0.4414 - val_loss: 1.7274 - val_root_mean_squared_error: 0.4297\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 1.7327 - root_mean_squared_error: 0.4363 - val_loss: 1.7217 - val_root_mean_squared_error: 0.4243\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.7274 - root_mean_squared_error: 0.4313 - val_loss: 1.7162 - val_root_mean_squared_error: 0.4189\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7221 - root_mean_squared_error: 0.4262 - val_loss: 1.7109 - val_root_mean_squared_error: 0.4136\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7171 - root_mean_squared_error: 0.4215 - val_loss: 1.7055 - val_root_mean_squared_error: 0.4082\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7120 - root_mean_squared_error: 0.4166 - val_loss: 1.7002 - val_root_mean_squared_error: 0.4029\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.7070 - root_mean_squared_error: 0.4117 - val_loss: 1.6951 - val_root_mean_squared_error: 0.3977\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.7021 - root_mean_squared_error: 0.4069 - val_loss: 1.6900 - val_root_mean_squared_error: 0.3925\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6973 - root_mean_squared_error: 0.4021 - val_loss: 1.6851 - val_root_mean_squared_error: 0.3875\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6927 - root_mean_squared_error: 0.3976 - val_loss: 1.6803 - val_root_mean_squared_error: 0.3824\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6882 - root_mean_squared_error: 0.3931 - val_loss: 1.6755 - val_root_mean_squared_error: 0.3774\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.6836 - root_mean_squared_error: 0.3884 - val_loss: 1.6708 - val_root_mean_squared_error: 0.3725\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6792 - root_mean_squared_error: 0.3840 - val_loss: 1.6663 - val_root_mean_squared_error: 0.3676\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6748 - root_mean_squared_error: 0.3795 - val_loss: 1.6618 - val_root_mean_squared_error: 0.3628\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 1.6705 - root_mean_squared_error: 0.3751 - val_loss: 1.6574 - val_root_mean_squared_error: 0.3581\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 1.6663 - root_mean_squared_error: 0.3708 - val_loss: 1.6531 - val_root_mean_squared_error: 0.3534\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6622 - root_mean_squared_error: 0.3665 - val_loss: 1.6489 - val_root_mean_squared_error: 0.3488\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6581 - root_mean_squared_error: 0.3622 - val_loss: 1.6448 - val_root_mean_squared_error: 0.3442\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6541 - root_mean_squared_error: 0.3580 - val_loss: 1.6406 - val_root_mean_squared_error: 0.3396\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6501 - root_mean_squared_error: 0.3538 - val_loss: 1.6366 - val_root_mean_squared_error: 0.3351\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6463 - root_mean_squared_error: 0.3497 - val_loss: 1.6327 - val_root_mean_squared_error: 0.3307\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.6424 - root_mean_squared_error: 0.3456 - val_loss: 1.6289 - val_root_mean_squared_error: 0.3264\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.6388 - root_mean_squared_error: 0.3417 - val_loss: 1.6251 - val_root_mean_squared_error: 0.3221\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.6351 - root_mean_squared_error: 0.3378 - val_loss: 1.6215 - val_root_mean_squared_error: 0.3178\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.6315 - root_mean_squared_error: 0.3338 - val_loss: 1.6179 - val_root_mean_squared_error: 0.3137\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 1.6280 - root_mean_squared_error: 0.3300 - val_loss: 1.6143 - val_root_mean_squared_error: 0.3096\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.6246 - root_mean_squared_error: 0.3263 - val_loss: 1.6109 - val_root_mean_squared_error: 0.3055\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 1.6211 - root_mean_squared_error: 0.3225 - val_loss: 1.6075 - val_root_mean_squared_error: 0.3015\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 1.6178 - root_mean_squared_error: 0.3188 - val_loss: 1.6041 - val_root_mean_squared_error: 0.2976\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 1.6145 - root_mean_squared_error: 0.3152 - val_loss: 1.6008 - val_root_mean_squared_error: 0.2936\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.6113 - root_mean_squared_error: 0.3116 - val_loss: 1.5976 - val_root_mean_squared_error: 0.2899\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6081 - root_mean_squared_error: 0.3081 - val_loss: 1.5945 - val_root_mean_squared_error: 0.2862\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6050 - root_mean_squared_error: 0.3046 - val_loss: 1.5914 - val_root_mean_squared_error: 0.2825\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.6020 - root_mean_squared_error: 0.3013 - val_loss: 1.5884 - val_root_mean_squared_error: 0.2788\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5990 - root_mean_squared_error: 0.2979 - val_loss: 1.5854 - val_root_mean_squared_error: 0.2752\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5960 - root_mean_squared_error: 0.2945 - val_loss: 1.5825 - val_root_mean_squared_error: 0.2717\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 1.5932 - root_mean_squared_error: 0.2914 - val_loss: 1.5796 - val_root_mean_squared_error: 0.2682\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 1.5903 - root_mean_squared_error: 0.2882 - val_loss: 1.5768 - val_root_mean_squared_error: 0.2648\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 1.5555 - root_mean_squared_error: 0.2211\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 1.5555 - root_mean_squared_error: 0.2211\n",
            "MODEL EVALUATION:  [1.5555368661880493, 0.22107015550136566]\n",
            "Number of epochs: 40 learning rate: 1e-05 Activation Function: relu\n",
            "Model number:  575\n",
            "Epoch 1/40\n",
            "6/6 [==============================] - 1s 43ms/step - loss: 0.3896 - root_mean_squared_error: 0.6242 - val_loss: 0.3956 - val_root_mean_squared_error: 0.6289\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3828 - root_mean_squared_error: 0.6187 - val_loss: 0.3881 - val_root_mean_squared_error: 0.6229\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3761 - root_mean_squared_error: 0.6133 - val_loss: 0.3807 - val_root_mean_squared_error: 0.6170\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3694 - root_mean_squared_error: 0.6078 - val_loss: 0.3735 - val_root_mean_squared_error: 0.6112\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3629 - root_mean_squared_error: 0.6024 - val_loss: 0.3664 - val_root_mean_squared_error: 0.6053\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.3566 - root_mean_squared_error: 0.5972 - val_loss: 0.3595 - val_root_mean_squared_error: 0.5995\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.3504 - root_mean_squared_error: 0.5919 - val_loss: 0.3526 - val_root_mean_squared_error: 0.5938\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3441 - root_mean_squared_error: 0.5866 - val_loss: 0.3458 - val_root_mean_squared_error: 0.5881\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3381 - root_mean_squared_error: 0.5814 - val_loss: 0.3392 - val_root_mean_squared_error: 0.5824\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3321 - root_mean_squared_error: 0.5763 - val_loss: 0.3328 - val_root_mean_squared_error: 0.5769\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3265 - root_mean_squared_error: 0.5714 - val_loss: 0.3264 - val_root_mean_squared_error: 0.5713\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3205 - root_mean_squared_error: 0.5661 - val_loss: 0.3202 - val_root_mean_squared_error: 0.5659\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.3149 - root_mean_squared_error: 0.5612 - val_loss: 0.3141 - val_root_mean_squared_error: 0.5605\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3095 - root_mean_squared_error: 0.5563 - val_loss: 0.3081 - val_root_mean_squared_error: 0.5551\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.3041 - root_mean_squared_error: 0.5514 - val_loss: 0.3022 - val_root_mean_squared_error: 0.5497\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2987 - root_mean_squared_error: 0.5466 - val_loss: 0.2965 - val_root_mean_squared_error: 0.5445\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2936 - root_mean_squared_error: 0.5419 - val_loss: 0.2908 - val_root_mean_squared_error: 0.5393\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2884 - root_mean_squared_error: 0.5370 - val_loss: 0.2853 - val_root_mean_squared_error: 0.5341\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.2834 - root_mean_squared_error: 0.5324 - val_loss: 0.2799 - val_root_mean_squared_error: 0.5290\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2785 - root_mean_squared_error: 0.5278 - val_loss: 0.2745 - val_root_mean_squared_error: 0.5239\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2736 - root_mean_squared_error: 0.5231 - val_loss: 0.2693 - val_root_mean_squared_error: 0.5189\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2690 - root_mean_squared_error: 0.5187 - val_loss: 0.2640 - val_root_mean_squared_error: 0.5138\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2643 - root_mean_squared_error: 0.5141 - val_loss: 0.2589 - val_root_mean_squared_error: 0.5088\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2597 - root_mean_squared_error: 0.5096 - val_loss: 0.2539 - val_root_mean_squared_error: 0.5039\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.2552 - root_mean_squared_error: 0.5051 - val_loss: 0.2490 - val_root_mean_squared_error: 0.4990\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2508 - root_mean_squared_error: 0.5008 - val_loss: 0.2441 - val_root_mean_squared_error: 0.4941\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.2464 - root_mean_squared_error: 0.4964 - val_loss: 0.2394 - val_root_mean_squared_error: 0.4893\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2422 - root_mean_squared_error: 0.4921 - val_loss: 0.2348 - val_root_mean_squared_error: 0.4846\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2381 - root_mean_squared_error: 0.4879 - val_loss: 0.2302 - val_root_mean_squared_error: 0.4798\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2340 - root_mean_squared_error: 0.4837 - val_loss: 0.2258 - val_root_mean_squared_error: 0.4752\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.2299 - root_mean_squared_error: 0.4794 - val_loss: 0.2214 - val_root_mean_squared_error: 0.4706\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.2260 - root_mean_squared_error: 0.4754 - val_loss: 0.2171 - val_root_mean_squared_error: 0.4660\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2221 - root_mean_squared_error: 0.4713 - val_loss: 0.2129 - val_root_mean_squared_error: 0.4614\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2182 - root_mean_squared_error: 0.4671 - val_loss: 0.2087 - val_root_mean_squared_error: 0.4568\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2144 - root_mean_squared_error: 0.4631 - val_loss: 0.2046 - val_root_mean_squared_error: 0.4523\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2107 - root_mean_squared_error: 0.4590 - val_loss: 0.2006 - val_root_mean_squared_error: 0.4479\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2070 - root_mean_squared_error: 0.4550 - val_loss: 0.1966 - val_root_mean_squared_error: 0.4434\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.2033 - root_mean_squared_error: 0.4509 - val_loss: 0.1928 - val_root_mean_squared_error: 0.4390\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1999 - root_mean_squared_error: 0.4471 - val_loss: 0.1889 - val_root_mean_squared_error: 0.4346\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1963 - root_mean_squared_error: 0.4431 - val_loss: 0.1852 - val_root_mean_squared_error: 0.4303\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1315 - root_mean_squared_error: 0.3626\n",
            "2/2 [==============================] - 0s 7ms/step - loss: 0.1315 - root_mean_squared_error: 0.3626\n",
            "MODEL EVALUATION:  [0.13148626685142517, 0.3626103401184082]\n",
            "Number of epochs: 40 learning rate: 1e-05 Activation Function: relu\n",
            "Model number:  576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameter_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9w7JB6HkVId",
        "outputId": "da9506d6-0924-4fa9-9c7b-303233a16903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Hidden Layes: 1 Number of epochs: 10 learning rate: 1 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 1 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 1 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 1 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 1 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 1 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.3 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.3 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.3 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.3 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.3 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.3 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.1 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.1 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.1 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.1 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.1 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.1 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.01 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.01 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.01 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.01 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.01 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.01 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.03 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.03 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.03 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.03 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.03 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.03 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.001 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.001 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.001 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.001 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.001 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.001 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.0001 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.0001 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.0001 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.0001 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.0001 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 0.0001 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 1e-05 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 1e-05 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 1e-05 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 1e-05 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 1e-05 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 10 learning rate: 1e-05 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 1 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 1 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 1 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 1 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 1 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 1 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.3 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.3 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.3 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.3 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.3 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.3 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.1 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.1 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.1 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.1 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.1 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.1 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.01 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.01 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.01 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.01 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.01 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.01 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.03 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.03 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.03 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.03 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.03 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.03 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.001 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.001 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.001 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.001 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.001 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.001 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.0001 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.0001 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.0001 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.0001 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.0001 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 0.0001 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 1e-05 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 1e-05 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 1e-05 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 1e-05 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 1e-05 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 20 learning rate: 1e-05 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 1 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 1 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 1 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 1 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 1 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 1 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.3 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.3 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.3 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.3 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.3 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.3 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.1 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.1 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.1 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.1 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.1 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.1 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.01 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.01 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.01 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.01 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.01 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.01 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.03 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.03 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.03 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.03 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.03 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.03 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.001 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.001 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.001 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.001 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.001 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.001 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.0001 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.0001 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.0001 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.0001 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.0001 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 0.0001 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 1e-05 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 1e-05 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 1e-05 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 1e-05 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 1e-05 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 30 learning rate: 1e-05 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 1 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 1 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 1 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 1 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 1 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 1 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.3 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.3 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.3 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.3 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.3 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.3 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.1 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.1 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.1 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.1 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.1 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.1 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.01 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.01 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.01 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.01 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.01 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.01 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.03 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.03 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.03 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.03 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.03 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.03 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.001 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.001 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.001 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.001 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.001 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.001 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.0001 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.0001 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.0001 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.0001 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.0001 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 0.0001 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 1e-05 Activation Function: sigmoidRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 1e-05 Activation Function: sigmoidRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 1e-05 Activation Function: sigmoidRegularizer: None',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 1e-05 Activation Function: reluRegularizer: l1',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 1e-05 Activation Function: reluRegularizer: l2',\n",
              " 'Hidden Layes: 1 Number of epochs: 40 learning rate: 1e-05 Activation Function: reluRegularizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 1 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 1 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 1 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 1 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 1 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 1 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.3 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.3 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.3 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.3 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.3 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.3 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.1 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.1 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.1 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.1 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.1 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.1 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.01 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.01 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.01 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.01 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.01 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.01 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.03 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.03 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.03 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.03 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.03 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.03 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.001 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.001 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.001 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.001 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.001 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.001 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.0001 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.0001 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.0001 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.0001 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.0001 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 0.0001 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 1e-05 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 1e-05 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 1e-05 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 1e-05 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 1e-05 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 10 learning rate: 1e-05 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 1 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 1 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 1 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 1 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 1 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 1 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.3 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.3 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.3 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.3 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.3 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.3 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.1 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.1 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.1 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.1 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.1 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.1 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.01 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.01 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.01 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.01 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.01 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.01 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.03 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.03 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.03 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.03 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.03 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.03 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.001 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.001 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.001 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.001 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.001 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.001 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.0001 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.0001 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.0001 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.0001 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.0001 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 0.0001 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 1e-05 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 1e-05 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 1e-05 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 1e-05 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 1e-05 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 20 learning rate: 1e-05 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 1 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 1 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 1 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 1 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 1 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 1 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.3 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.3 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.3 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.3 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.3 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.3 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.1 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.1 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.1 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.1 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.1 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.1 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.01 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.01 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.01 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.01 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.01 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.01 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.03 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.03 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.03 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.03 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.03 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.03 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.001 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.001 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.001 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.001 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.001 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.001 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.0001 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.0001 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.0001 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.0001 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.0001 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 0.0001 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 1e-05 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 1e-05 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 1e-05 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 1e-05 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 1e-05 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 30 learning rate: 1e-05 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 1 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 1 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 1 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 1 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 1 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 1 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.3 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.3 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.3 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.3 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.3 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.3 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.1 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.1 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.1 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.1 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.1 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.1 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.01 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.01 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.01 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.01 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.01 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.01 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.03 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.03 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.03 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.03 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.03 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.03 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.001 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.001 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.001 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.001 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.001 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.001 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.0001 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.0001 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.0001 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.0001 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.0001 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 0.0001 Activation Function: relu Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 1e-05 Activation Function: sigmoid Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 1e-05 Activation Function: sigmoid Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 1e-05 Activation Function: sigmoid Regulizer: None',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 1e-05 Activation Function: relu Regulizer: l1',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 1e-05 Activation Function: relu Regulizer: l2',\n",
              " 'Hidden Layers: 2 Number of epochs: 40 learning rate: 1e-05 Activation Function: relu Regulizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 1 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 1 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 1 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 1 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 1 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 1 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.3 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.3 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.3 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.3 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.3 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.3 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.1 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.1 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.1 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.1 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.1 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.1 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.01 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.01 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.01 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.01 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.01 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.01 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.03 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.03 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.03 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.03 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.03 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.03 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.001 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.001 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.001 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.001 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.001 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.001 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.0001 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.0001 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.0001 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.0001 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.0001 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 0.0001 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 1e-05 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 1e-05 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 1e-05 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 1e-05 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 1e-05 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 10 learning rate: 1e-05 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 1 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 1 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 1 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 1 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 1 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 1 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.3 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.3 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.3 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.3 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.3 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.3 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.1 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.1 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.1 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.1 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.1 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.1 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.01 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.01 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.01 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.01 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.01 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.01 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.03 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.03 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.03 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.03 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.03 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.03 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.001 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.001 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.001 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.001 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.001 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.001 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.0001 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.0001 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.0001 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.0001 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.0001 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 0.0001 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 1e-05 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 1e-05 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 1e-05 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 1e-05 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 1e-05 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 20 learning rate: 1e-05 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 1 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 1 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 1 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 1 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 1 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 1 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.3 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.3 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.3 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.3 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.3 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.3 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.1 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.1 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.1 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.1 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.1 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.1 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.01 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.01 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.01 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.01 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.01 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.01 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.03 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.03 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.03 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.03 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.03 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.03 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.001 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.001 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.001 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.001 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.001 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.001 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.0001 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.0001 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.0001 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.0001 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.0001 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 0.0001 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 1e-05 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 1e-05 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 1e-05 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 1e-05 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 1e-05 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 30 learning rate: 1e-05 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 1 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 1 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 1 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 1 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 1 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 1 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.3 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.3 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.3 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.3 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.3 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.3 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.1 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.1 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.1 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.1 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.1 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.1 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.01 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.01 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.01 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.01 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.01 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.01 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.03 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.03 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.03 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.03 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.03 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.03 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.001 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.001 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.001 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.001 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.001 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.001 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.0001 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.0001 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.0001 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.0001 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.0001 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 0.0001 Activation Function: relu Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 1e-05 Activation Function: sigmoid Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 1e-05 Activation Function: sigmoid Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 1e-05 Activation Function: sigmoid Regularizer: None',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 1e-05 Activation Function: relu Regularizer: l1',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 1e-05 Activation Function: relu Regularizer: l2',\n",
              " 'hidden layers: 3 Number of epochs: 40 learning rate: 1e-05 Activation Function: relu Regularizer: None']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzSrqMUvsVIy",
        "outputId": "96611984-98ab-4da7-ac37-12d5c6efb19b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[59.07469940185547, 0.47266024351119995],\n",
              " [3.5590267181396484, 0.1422288417816162],\n",
              " [0.2765538692474365, 0.5258839130401611],\n",
              " [61.674991607666016, 0.4064732491970062],\n",
              " [233.1490020751953, 1.3775484561920166],\n",
              " [2.5946145057678223, 1.6107807159423828],\n",
              " [14.038047790527344, 0.20870499312877655],\n",
              " [1.5320100784301758, 0.3648952543735504],\n",
              " [0.04856380447745323, 0.22037196159362793],\n",
              " [11.264670372009277, 0.15860983729362488],\n",
              " [8.763766288757324, 0.10365648567676544],\n",
              " [0.029850339516997337, 0.17277251183986664],\n",
              " [0.7528824806213379, 0.23252065479755402],\n",
              " [0.18733638525009155, 0.1404411643743515],\n",
              " [0.02525193803012371, 0.15890859067440033],\n",
              " [0.5168471932411194, 0.08957147598266602],\n",
              " [0.48737597465515137, 0.10396230965852737],\n",
              " [0.011541446670889854, 0.10743112862110138],\n",
              " [0.04934576526284218, 0.1335228979587555],\n",
              " [0.016137002035975456, 0.08332689851522446],\n",
              " [0.020600011572241783, 0.1435270458459854],\n",
              " [0.05579178407788277, 0.10447411239147186],\n",
              " [0.0191484447568655, 0.055682338774204254],\n",
              " [0.009678151458501816, 0.09837759286165237],\n",
              " [0.08100701123476028, 0.13822637498378754],\n",
              " [0.03124227002263069, 0.1191558986902237],\n",
              " [0.008696083910763264, 0.09325279295444489],\n",
              " [0.09608475118875504, 0.11795204132795334],\n",
              " [0.01194434892386198, 0.046567101031541824],\n",
              " [0.01079885195940733, 0.10391752421855927],\n",
              " [0.9593997597694397, 0.13427291810512543],\n",
              " [0.15555383265018463, 0.12022019177675247],\n",
              " [0.013405066914856434, 0.11578024923801422],\n",
              " [1.191154956817627, 0.11545354872941971],\n",
              " [0.17803630232810974, 0.11072167754173279],\n",
              " [0.007721060421317816, 0.0878695622086525],\n",
              " [1.7784502506256104, 0.1999892294406891],\n",
              " [0.3156546652317047, 0.2509446144104004],\n",
              " [0.023305512964725494, 0.15266142785549164],\n",
              " [1.7543880939483643, 0.1342266947031021],\n",
              " [0.26413023471832275, 0.15663029253482819],\n",
              " [0.018614642322063446, 0.13643549382686615],\n",
              " [1.855177402496338, 0.1369166523218155],\n",
              " [0.42773568630218506, 0.41630303859710693],\n",
              " [3.112788438796997, 1.7643096446990967],\n",
              " [2.0805671215057373, 0.5266812443733215],\n",
              " [0.4015551507472992, 0.3916636109352112],\n",
              " [0.10620153695344925, 0.3258857727050781],\n",
              " [14.685837745666504, 0.08617100119590759],\n",
              " [0.024501336738467216, 0.1304614543914795],\n",
              " [0.020564792677760124, 0.1434043049812317],\n",
              " [47.65497589111328, 0.3365110456943512],\n",
              " [141.0963134765625, 0.13632187247276306],\n",
              " [0.09711823612451553, 0.3116379976272583],\n",
              " [2.7087550163269043, 0.34808292984962463],\n",
              " [0.1325109601020813, 0.18235695362091064],\n",
              " [0.019333824515342712, 0.13904611766338348],\n",
              " [7.178500652313232, 0.08788065612316132],\n",
              " [5.47981595993042, 0.1376723200082779],\n",
              " [0.006780691910535097, 0.08234495669603348],\n",
              " [0.13922886550426483, 0.1486084908246994],\n",
              " [0.017294934019446373, 0.09499900043010712],\n",
              " [0.019075000658631325, 0.13811227679252625],\n",
              " [0.15826177597045898, 0.046256788074970245],\n",
              " [0.1195649728178978, 0.047732435166835785],\n",
              " [0.0031983957160264254, 0.056554362177848816],\n",
              " [0.04205910861492157, 0.13391347229480743],\n",
              " [0.013638775795698166, 0.08427204936742783],\n",
              " [0.001513841561973095, 0.03890811651945114],\n",
              " [0.035841912031173706, 0.05191939324140549],\n",
              " [0.004658623598515987, 0.029162708669900894],\n",
              " [0.0014160965802147985, 0.03763105720281601],\n",
              " [0.0768325924873352, 0.13413166999816895],\n",
              " [0.014184619300067425, 0.08780952543020248],\n",
              " [0.0050108907744288445, 0.07078764587640762],\n",
              " [0.0735812857747078, 0.03909504786133766],\n",
              " [0.012505614198744297, 0.08292025327682495],\n",
              " [0.005915543530136347, 0.07691256701946259],\n",
              " [0.36293870210647583, 0.1348860114812851],\n",
              " [0.06153745576739311, 0.11349299550056458],\n",
              " [0.007523075677454472, 0.08673566579818726],\n",
              " [0.5312450528144836, 0.08405310660600662],\n",
              " [0.10484336316585541, 0.08420345932245255],\n",
              " [0.0025211467873305082, 0.05021102353930473],\n",
              " [1.6135175228118896, 0.12846830487251282],\n",
              " [0.2417539358139038, 0.12448686361312866],\n",
              " [0.02036835253238678, 0.14271773397922516],\n",
              " [1.7234177589416504, 0.13860495388507843],\n",
              " [0.2517811954021454, 0.12438470870256424],\n",
              " [0.014607015065848827, 0.12085948139429092],\n",
              " [1.8698310852050781, 0.14026769995689392],\n",
              " [2.0261876583099365, 1.331816554069519],\n",
              " [1.0157320499420166, 1.0078353881835938],\n",
              " [2.111372470855713, 0.5139662027359009],\n",
              " [0.5738001465797424, 0.561099112033844],\n",
              " [0.13484106957912445, 0.3672071099281311],\n",
              " [27.428810119628906, 0.13409720361232758],\n",
              " [0.02718108333647251, 0.160394087433815],\n",
              " [0.019257567822933197, 0.1387716382741928],\n",
              " [42.8440055847168, 0.13722136616706848],\n",
              " [183.7078399658203, 0.13729093968868256],\n",
              " [0.050976287573575974, 0.22577929496765137],\n",
              " [1.013599157333374, 0.20743438601493835],\n",
              " [0.03869367763400078, 0.12554135918617249],\n",
              " [0.01850145496428013, 0.13602004945278168],\n",
              " [4.288007736206055, 0.08661501109600067],\n",
              " [2.2802107334136963, 0.05515822768211365],\n",
              " [0.0015325212152674794, 0.039147429168224335],\n",
              " [0.13206863403320312, 0.13378232717514038],\n",
              " [0.013582182116806507, 0.0831575095653534],\n",
              " [0.01669645868241787, 0.12921477854251862],\n",
              " [0.13168948888778687, 0.025572678074240685],\n",
              " [0.015028786845505238, 0.030484460294246674],\n",
              " [0.0021554140839725733, 0.0464264377951622],\n",
              " [0.044526372104883194, 0.14448705315589905],\n",
              " [0.012830706313252449, 0.07958336919546127],\n",
              " [0.003011411754414439, 0.054876331239938736],\n",
              " [0.03194534033536911, 0.048930563032627106],\n",
              " [0.0066598146222531796, 0.06223944202065468],\n",
              " [0.0006689778529107571, 0.025864606723189354],\n",
              " [0.08334624767303467, 0.1654735505580902],\n",
              " [0.021624574437737465, 0.1222430020570755],\n",
              " [0.0021267859265208244, 0.046117089688777924],\n",
              " [0.07055288553237915, 0.02406327798962593],\n",
              " [0.01737220026552677, 0.11878004670143127],\n",
              " [0.0027051011566072702, 0.052010588347911835],\n",
              " [0.05616943910717964, 0.13858619332313538],\n",
              " [0.10600878298282623, 0.11742035299539566],\n",
              " [0.00627165287733078, 0.07919377088546753],\n",
              " [0.06251036375761032, 0.09101246297359467],\n",
              " [0.06614477932453156, 0.06178383529186249],\n",
              " [0.0017298775492236018, 0.04159179702401161],\n",
              " [1.6252341270446777, 0.16730087995529175],\n",
              " [0.26127323508262634, 0.14233402907848358],\n",
              " [0.013244356028735638, 0.11508412659168243],\n",
              " [1.6110599040985107, 0.1413160264492035],\n",
              " [0.2402791529893875, 0.1266183704137802],\n",
              " [0.014697303995490074, 0.12123243510723114],\n",
              " [1.844016432762146, 0.1528664380311966],\n",
              " [0.2794838845729828, 0.14957295358181],\n",
              " [0.058462969958782196, 0.24179117381572723],\n",
              " [2.109926223754883, 0.4904898703098297],\n",
              " [0.2743275761604309, 0.134561225771904],\n",
              " [0.03870922327041626, 0.1967466026544571],\n",
              " [25.81133460998535, 0.13622403144836426],\n",
              " [0.0389130599796772, 0.13145768642425537],\n",
              " [0.01956210844218731, 0.13986460864543915],\n",
              " [59.50111770629883, 0.18887877464294434],\n",
              " [117.56021118164062, 0.13809259235858917],\n",
              " [0.01911868155002594, 0.1382703185081482],\n",
              " [0.2731422185897827, 0.1368255764245987],\n",
              " [0.014578704722225666, 0.09081996977329254],\n",
              " [0.01848066784441471, 0.13594362139701843],\n",
              " [1.4861013889312744, 0.13731597363948822],\n",
              " [1.8532283306121826, 0.13779540359973907],\n",
              " [0.005516311153769493, 0.07427187263965607],\n",
              " [0.1653251051902771, 0.15885329246520996],\n",
              " [0.01376325823366642, 0.08443694561719894],\n",
              " [0.011145640164613724, 0.10557291656732559],\n",
              " [0.1514958292245865, 0.060196928679943085],\n",
              " [0.008118610829114914, 0.05722421407699585],\n",
              " [0.019482748582959175, 0.1395806223154068],\n",
              " [0.052082594484090805, 0.16028699278831482],\n",
              " [0.016685187816619873, 0.09928911924362183],\n",
              " [0.00045567526831291616, 0.021346552297472954],\n",
              " [0.028256520628929138, 0.02623993717133999],\n",
              " [0.004477266222238541, 0.04543168470263481],\n",
              " [0.0005607891362160444, 0.02368098683655262],\n",
              " [0.08302849531173706, 0.14610303938388824],\n",
              " [0.026256509125232697, 0.13981495797634125],\n",
              " [0.0007960055372677743, 0.02821356989443302],\n",
              " [0.06882599741220474, 0.01867864467203617],\n",
              " [0.00397235294803977, 0.03332612290978432],\n",
              " [0.001528324792161584, 0.03909379616379738],\n",
              " [0.0273691788315773, 0.13905833661556244],\n",
              " [0.02088441699743271, 0.10120618343353271],\n",
              " [0.00325080007314682, 0.057015787810087204],\n",
              " [0.07149157673120499, 0.09343202412128448],\n",
              " [0.022325556725263596, 0.03801247477531433],\n",
              " [0.0024324078112840652, 0.049319446086883545],\n",
              " [1.5067373514175415, 0.12545719742774963],\n",
              " [0.21850842237472534, 0.12141154706478119],\n",
              " [0.02161852829158306, 0.14703240990638733],\n",
              " [1.6154470443725586, 0.09595540165901184],\n",
              " [0.23990708589553833, 0.11743446439504623],\n",
              " [0.013399453833699226, 0.11575601249933243],\n",
              " [2.1582727432250977, 0.5589451193809509],\n",
              " [1.1145557165145874, 0.9310054779052734],\n",
              " [0.35281145572662354, 0.5939793586730957],\n",
              " [1.8327785730361938, 0.2910643517971039],\n",
              " [0.5588677525520325, 0.5553064942359924],\n",
              " [0.26509833335876465, 0.5148770213127136],\n",
              " [265.3207702636719, 2.118762493133545],\n",
              " [252.3318328857422, 3.8354742527008057],\n",
              " [0.04862289875745773, 0.22050601243972778],\n",
              " [334.3611145019531, 7.696405410766602],\n",
              " [1555.6781005859375, 4.897826671600342],\n",
              " [22.70490837097168, 4.76496696472168],\n",
              " [36.062808990478516, 0.9316325187683105],\n",
              " [12.566128730773926, 0.21124620735645294],\n",
              " [0.024760225787758827, 0.15735381841659546],\n",
              " [64.72015380859375, 0.6404320597648621],\n",
              " [97.68505859375, 0.25941962003707886],\n",
              " [0.0678694099187851, 0.26051756739616394],\n",
              " [13.363092422485352, 0.5636060833930969],\n",
              " [0.5235886573791504, 0.14666223526000977],\n",
              " [0.03747687116265297, 0.19358943402767181],\n",
              " [4.754405975341797, 0.22910349071025848],\n",
              " [3.9617035388946533, 0.22157010436058044],\n",
              " [0.02154630981385708, 0.1467866152524948],\n",
              " [0.1785912662744522, 0.13376285135746002],\n",
              " [0.21925382316112518, 0.127853661775589],\n",
              " [0.013460173271596432, 0.11601798981428146],\n",
              " [0.18489111959934235, 0.13913092017173767],\n",
              " [0.035699427127838135, 0.07106848806142807],\n",
              " [0.0064111934043467045, 0.08006992936134338],\n",
              " [0.3676625192165375, 0.13971929252147675],\n",
              " [0.08876261860132217, 0.13576334714889526],\n",
              " [0.014499020762741566, 0.12041188031435013],\n",
              " [0.43022581934928894, 0.14265519380569458],\n",
              " [0.12417005002498627, 0.07815130800008774],\n",
              " [0.016923777759075165, 0.13009141385555267],\n",
              " [4.163272857666016, 0.1406247466802597],\n",
              " [0.6146196126937866, 0.13528038561344147],\n",
              " [0.015534085221588612, 0.12463580816984177],\n",
              " [4.339360237121582, 0.10722290724515915],\n",
              " [0.5491881966590881, 0.09577517956495285],\n",
              " [0.007828691974282265, 0.0884798988699913],\n",
              " [8.722649574279785, 0.1365412026643753],\n",
              " [1.113830804824829, 0.15042848885059357],\n",
              " [0.01705930382013321, 0.13061127066612244],\n",
              " [8.55254077911377, 0.101898193359375],\n",
              " [1.0503507852554321, 0.12128180265426636],\n",
              " [0.013117844238877296, 0.11453315615653992],\n",
              " [9.027685165405273, 0.25616568326950073],\n",
              " [1.2247449159622192, 0.3219435513019562],\n",
              " [0.06475094705820084, 0.2544620633125305],\n",
              " [9.547028541564941, 0.6178475618362427],\n",
              " [1.2890231609344482, 0.4411570131778717],\n",
              " [0.14151446521282196, 0.3761840760707855],\n",
              " [139.5478973388672, 4.215269088745117],\n",
              " [270.4620666503906, 9.786015510559082],\n",
              " [0.024570530280470848, 0.1567499041557312],\n",
              " [288.744140625, 1.3949416875839233],\n",
              " [1449.5633544921875, 1.2772473096847534],\n",
              " [0.019576851278543472, 0.1399172991514206],\n",
              " [23.038686752319336, 0.3219592273235321],\n",
              " [2.4915611743927, 0.9129540920257568],\n",
              " [0.01936502754688263, 0.13915827870368958],\n",
              " [68.35726165771484, 0.19113804399967194],\n",
              " [59.28615951538086, 0.11787877231836319],\n",
              " [0.017489824444055557, 0.13224910199642181],\n",
              " [0.7764895558357239, 0.1313779205083847],\n",
              " [0.05812560394406319, 0.15591055154800415],\n",
              " [0.019695227965712547, 0.1403396874666214],\n",
              " [1.4132776260375977, 0.056715160608291626],\n",
              " [2.66581654548645, 0.1465451568365097],\n",
              " [0.02061784826219082, 0.14358916878700256],\n",
              " [0.11271025240421295, 0.13131986558437347],\n",
              " [0.03167622163891792, 0.14743909239768982],\n",
              " [0.00876625906676054, 0.09362830221652985],\n",
              " [0.1410493403673172, 0.13424676656723022],\n",
              " [0.014332589693367481, 0.05791841819882393],\n",
              " [0.00244912994094193, 0.04948868602514267],\n",
              " [0.33750197291374207, 0.15269844233989716],\n",
              " [0.019618043676018715, 0.1391063779592514],\n",
              " [0.016508769243955612, 0.12848645448684692],\n",
              " [0.3788701593875885, 0.11436186730861664],\n",
              " [0.01885194331407547, 0.07645754516124725],\n",
              " [0.005962681956589222, 0.07721840590238571],\n",
              " [1.2879283428192139, 0.13333085179328918],\n",
              " [0.6131141781806946, 0.13248015940189362],\n",
              " [0.014760870486497879, 0.12149431556463242],\n",
              " [1.3242439031600952, 0.12255223840475082],\n",
              " [0.18713809549808502, 0.07089721411466599],\n",
              " [0.003810633672401309, 0.06173032894730568],\n",
              " [8.10892105102539, 0.1338609755039215],\n",
              " [1.0768465995788574, 0.12951643764972687],\n",
              " [0.01834934391081333, 0.1354597508907318],\n",
              " [8.062039375305176, 0.1308240443468094],\n",
              " [0.9660343527793884, 0.11162657290697098],\n",
              " [0.015558270737528801, 0.12473279982805252],\n",
              " [8.962830543518066, 0.12686672806739807],\n",
              " [2.7583131790161133, 1.2853472232818604],\n",
              " [0.019410867244005203, 0.139322891831398],\n",
              " [9.03235149383545, 0.16909149289131165],\n",
              " [1.151556372642517, 0.2789057195186615],\n",
              " [0.0280727781355381, 0.16754932701587677],\n",
              " [106.91002655029297, 0.13175539672374725],\n",
              " [105.19291687011719, 0.30340132117271423],\n",
              " [0.018184758722782135, 0.13485087454319],\n",
              " [289.9335021972656, 1.4649003744125366],\n",
              " [1383.697021484375, 2.4249041080474854],\n",
              " [0.01763550005853176, 0.1327987164258957],\n",
              " [5.8970136642456055, 0.13192714750766754],\n",
              " [0.2506590783596039, 0.1553923338651657],\n",
              " [0.017631499096751213, 0.1327836513519287],\n",
              " [46.47417068481445, 0.13839714229106903],\n",
              " [75.1675796508789, 0.16949352622032166],\n",
              " [0.02058224380016327, 0.14346513152122498],\n",
              " [0.6731122136116028, 0.22887882590293884],\n",
              " [0.03733142465353012, 0.17752468585968018],\n",
              " [0.01712118647992611, 0.13084794580936432],\n",
              " [2.829515218734741, 0.08032923936843872],\n",
              " [1.0373553037643433, 0.10607226938009262],\n",
              " [0.0008935810765251517, 0.029892826452851295],\n",
              " [0.12276563793420792, 0.13908691704273224],\n",
              " [0.024896053597331047, 0.13157987594604492],\n",
              " [0.00869076419621706, 0.09322426468133926],\n",
              " [0.1377210170030594, 0.13657322525978088],\n",
              " [0.009763546288013458, 0.04446520283818245],\n",
              " [0.0004302588349673897, 0.02074268087744713],\n",
              " [0.3131328523159027, 0.13750386238098145],\n",
              " [0.048711877316236496, 0.2197348028421402],\n",
              " [0.0163235142827034, 0.1277635097503662],\n",
              " [0.4103057384490967, 0.1370319426059723],\n",
              " [0.01167283859103918, 0.04749089851975441],\n",
              " [0.0016306033357977867, 0.04038073122501373],\n",
              " [0.08482841402292252, 0.13873706758022308],\n",
              " [0.13898630440235138, 0.12779714167118073],\n",
              " [0.010289403609931469, 0.10143669694662094],\n",
              " [0.15931658446788788, 0.13275711238384247],\n",
              " [0.08905912190675735, 0.06312819570302963],\n",
              " [0.0026254712138324976, 0.05123935267329216],\n",
              " [8.335301399230957, 0.18536365032196045],\n",
              " [0.9773996472358704, 0.13903087377548218],\n",
              " [0.01761634647846222, 0.13272657990455627],\n",
              " [7.4841485023498535, 0.1234142854809761],\n",
              " [0.8401731252670288, 0.09451176226139069],\n",
              " [0.012901270762085915, 0.1135837584733963],\n",
              " [12.8225679397583, 1.9343690872192383],\n",
              " [1.753445029258728, 0.8115467429161072],\n",
              " [0.06739643961191177, 0.2596082389354706],\n",
              " [9.150444984436035, 0.35380634665489197],\n",
              " [1.2056708335876465, 0.34910809993743896],\n",
              " [0.08989153057336807, 0.2998191714286804],\n",
              " [72.9891586303711, 0.13918113708496094],\n",
              " [52.9349250793457, 0.4792290925979614],\n",
              " [0.02943561039865017, 0.1715680956840515],\n",
              " [227.2699432373047, 1.2632588148117065],\n",
              " [1118.8759765625, 2.317969799041748],\n",
              " [0.04832325503230095, 0.21982550621032715],\n",
              " [2.192885637283325, 0.22988831996917725],\n",
              " [0.02769441343843937, 0.13012343645095825],\n",
              " [0.020594527944922447, 0.1435079425573349],\n",
              " [53.4808464050293, 0.06555337458848953],\n",
              " [39.39698028564453, 0.09976715594530106],\n",
              " [0.024334890767931938, 0.1559964418411255],\n",
              " [0.7655382752418518, 0.13658936321735382],\n",
              " [0.024905342608690262, 0.15180674195289612],\n",
              " [0.017347440123558044, 0.13170967996120453],\n",
              " [1.1336749792099, 0.020330417901277542],\n",
              " [0.35666945576667786, 0.06328143924474716],\n",
              " [0.0012359223328530788, 0.03515568748116493],\n",
              " [0.1184614822268486, 0.1306050568819046],\n",
              " [0.025967618450522423, 0.15919242799282074],\n",
              " [0.0068906876258552074, 0.08301016688346863],\n",
              " [0.13976453244686127, 0.1396443396806717],\n",
              " [0.010167532600462437, 0.04528995230793953],\n",
              " [0.00036619609454646707, 0.019136250019073486],\n",
              " [0.2996335029602051, 0.13191759586334229],\n",
              " [0.029642587527632713, 0.16983738541603088],\n",
              " [0.018777912482619286, 0.13703252375125885],\n",
              " [0.39037346839904785, 0.1377028077840805],\n",
              " [0.019607966765761375, 0.0971531942486763],\n",
              " [0.0004566037387121469, 0.02136828750371933],\n",
              " [0.03246898576617241, 0.13865698873996735],\n",
              " [0.13910914957523346, 0.13520652055740356],\n",
              " [0.01084633357822895, 0.10414573550224304],\n",
              " [0.03694949671626091, 0.13822932541370392],\n",
              " [0.07157764583826065, 0.06767112761735916],\n",
              " [0.0011545380111783743, 0.03397849202156067],\n",
              " [7.838250637054443, 0.12984895706176758],\n",
              " [0.8635746836662292, 0.1354866325855255],\n",
              " [0.018541667610406876, 0.13616779446601868],\n",
              " [6.961958885192871, 0.10806398838758469],\n",
              " [0.7974327206611633, 0.10113739967346191],\n",
              " [0.00942174717783928, 0.09706568717956543],\n",
              " [8.816634178161621, 0.16754932701587677],\n",
              " [1.1737345457077026, 0.27198946475982666],\n",
              " [0.9510094523429871, 0.9751971364021301],\n",
              " [8.949612617492676, 0.1944323480129242],\n",
              " [1.1258383989334106, 0.23725135624408722],\n",
              " [0.06324336677789688, 0.2514823377132416],\n",
              " [82.03377532958984, 4.055019855499268],\n",
              " [55.96886444091797, 1.6253668069839478],\n",
              " [0.09964896738529205, 0.31567224860191345],\n",
              " [293.24798583984375, 2.1079437732696533],\n",
              " [2062.585205078125, 4.922005653381348],\n",
              " [29.590120315551758, 5.439680099487305],\n",
              " [6.3404340744018555, 0.31105074286460876],\n",
              " [17.33025550842285, 3.9848406314849854],\n",
              " [0.022347286343574524, 0.149490088224411],\n",
              " [83.92878723144531, 0.1303093433380127],\n",
              " [135.47581481933594, 0.2191811054944992],\n",
              " [0.04841364175081253, 0.2200310081243515],\n",
              " [1.463220238685608, 0.14632844924926758],\n",
              " [0.08456378430128098, 0.18089421093463898],\n",
              " [0.024061381816864014, 0.15511731803417206],\n",
              " [8.605308532714844, 0.15118710696697235],\n",
              " [5.254930019378662, 0.11958024650812149],\n",
              " [0.013941716402769089, 0.11807504296302795],\n",
              " [0.25237712264060974, 0.13757818937301636],\n",
              " [0.09194904565811157, 0.15328074991703033],\n",
              " [0.016340509057044983, 0.12782999873161316],\n",
              " [0.22539952397346497, 0.135232076048851],\n",
              " [0.03218350186944008, 0.06969545036554337],\n",
              " [0.0039465646259486675, 0.06282168626785278],\n",
              " [0.4854901432991028, 0.14036187529563904],\n",
              " [0.04836929589509964, 0.13729792833328247],\n",
              " [0.01803319901227951, 0.1342877447605133],\n",
              " [0.5306702256202698, 0.13648256659507751],\n",
              " [0.09845513850450516, 0.13149456679821014],\n",
              " [0.0065957168117165565, 0.08121401816606522],\n",
              " [6.2237019538879395, 0.1332811713218689],\n",
              " [0.9179781079292297, 0.13353252410888672],\n",
              " [0.02102568745613098, 0.1450023651123047],\n",
              " [5.748494625091553, 0.11430317908525467],\n",
              " [0.7641088366508484, 0.10408519953489304],\n",
              " [0.009287296794354916, 0.0963706225156784],\n",
              " [12.230949401855469, 0.9840131998062134],\n",
              " [1.450282096862793, 0.13517838716506958],\n",
              " [0.30580615997314453, 0.5529974102973938],\n",
              " [11.031156539916992, 0.1999933272600174],\n",
              " [1.4621069431304932, 0.1884758472442627],\n",
              " [0.014458420686423779, 0.12024317681789398],\n",
              " [11.626333236694336, 0.2812213897705078],\n",
              " [1.5783443450927734, 0.26799654960632324],\n",
              " [1.269126057624817, 1.1265548467636108],\n",
              " [11.784777641296387, 0.37308186292648315],\n",
              " [1.6518408060073853, 0.3558746874332428],\n",
              " [0.36480847001075745, 0.6039937734603882],\n",
              " [62.744537353515625, 0.5513589978218079],\n",
              " [27.148300170898438, 0.6827821135520935],\n",
              " [0.017602862790226936, 0.13267578184604645],\n",
              " [364.8086853027344, 1.2920314073562622],\n",
              " [1832.0711669921875, 3.7860066890716553],\n",
              " [23.55137062072754, 4.852975368499756],\n",
              " [3.689042806625366, 0.18345306813716888],\n",
              " [2.2021758556365967, 0.15153928101062775],\n",
              " [0.018809238448739052, 0.13714677095413208],\n",
              " [84.7243423461914, 0.20955587923526764],\n",
              " [122.43528747558594, 0.8525003790855408],\n",
              " [0.017419064417481422, 0.13198129832744598],\n",
              " [1.358186960220337, 0.1798052340745926],\n",
              " [0.022536631673574448, 0.13939036428928375],\n",
              " [0.019426722079515457, 0.13937976956367493],\n",
              " [2.2886574268341064, 0.13147297501564026],\n",
              " [3.935321569442749, 0.14447638392448425],\n",
              " [0.014434036798775196, 0.12014173716306686],\n",
              " [0.1583506464958191, 0.1375587284564972],\n",
              " [0.04474613815546036, 0.20563551783561707],\n",
              " [0.011115601286292076, 0.10543055087327957],\n",
              " [0.16633164882659912, 0.13732831180095673],\n",
              " [0.01823652908205986, 0.06133219599723816],\n",
              " [0.001168424147181213, 0.034182220697402954],\n",
              " [0.45659953355789185, 0.14196456968784332],\n",
              " [0.027497978881001472, 0.16218115389347076],\n",
              " [0.017538702115416527, 0.13243377208709717],\n",
              " [0.45697417855262756, 0.13543081283569336],\n",
              " [0.024054372683167458, 0.06404371559619904],\n",
              " [0.0022612144239246845, 0.04755222797393799],\n",
              " [1.8770085573196411, 0.13774555921554565],\n",
              " [0.3088231086730957, 0.13472339510917664],\n",
              " [0.01342318207025528, 0.11585845798254013],\n",
              " [2.1142079830169678, 0.12211351841688156],\n",
              " [0.3123713433742523, 0.07787749171257019],\n",
              " [0.00193939043674618, 0.04403851181268692],\n",
              " [10.647377967834473, 0.31756213307380676],\n",
              " [1.4696506261825562, 0.19418835639953613],\n",
              " [0.017470818012952805, 0.1321772187948227],\n",
              " [10.286674499511719, 0.11932311952114105],\n",
              " [1.323693871498108, 0.1164436787366867],\n",
              " [0.01276346854865551, 0.11297552287578583],\n",
              " [11.795734405517578, 0.5088502764701843],\n",
              " [2.281419038772583, 0.864158570766449],\n",
              " [0.08888118714094162, 0.29812946915626526],\n",
              " [11.61413860321045, 0.3672473728656769],\n",
              " [1.5318750143051147, 0.18006542325019836],\n",
              " [0.01958593912422657, 0.139949768781662],\n",
              " [18.395931243896484, 0.29035377502441406],\n",
              " [11.57678508758545, 0.589089035987854],\n",
              " [0.01752825453877449, 0.13239431381225586],\n",
              " [339.008544921875, 3.6790919303894043],\n",
              " [1753.5970458984375, 6.557147979736328],\n",
              " [12.249171257019043, 3.4998815059661865],\n",
              " [3.588103771209717, 0.1448705494403839],\n",
              " [0.02153974585235119, 0.1302390843629837],\n",
              " [0.019238924607634544, 0.13870444893836975],\n",
              " [63.71489334106445, 0.13833245635032654],\n",
              " [101.91923522949219, 0.1396917998790741],\n",
              " [0.6772616505622864, 0.8229590654373169],\n",
              " [1.2465801239013672, 0.13162533938884735],\n",
              " [0.04373167082667351, 0.20659984648227692],\n",
              " [0.017563490197062492, 0.13252732157707214],\n",
              " [1.401841163635254, 0.054450225085020065],\n",
              " [1.7465201616287231, 0.10885442048311234],\n",
              " [0.0025677811354398727, 0.05067327991127968],\n",
              " [0.16214899718761444, 0.14516697824001312],\n",
              " [0.01756930910050869, 0.13033804297447205],\n",
              " [0.007822342216968536, 0.08844400942325592],\n",
              " [0.16630227863788605, 0.1341063529253006],\n",
              " [0.019544579088687897, 0.06464351713657379],\n",
              " [0.0022950798738747835, 0.047906991094350815],\n",
              " [0.4415431320667267, 0.1315407007932663],\n",
              " [0.017137041315436363, 0.13025203347206116],\n",
              " [0.018326500430703163, 0.13537541031837463],\n",
              " [0.4934539198875427, 0.13985928893089294],\n",
              " [0.01891024224460125, 0.06618423014879227],\n",
              " [0.0015326660359278321, 0.03914928063750267],\n",
              " [0.4565593898296356, 0.1373482048511505],\n",
              " [0.13114826381206512, 0.13397912681102753],\n",
              " [0.01748986542224884, 0.13224925100803375],\n",
              " [0.4632444381713867, 0.13347163796424866],\n",
              " [0.18816393613815308, 0.08626881241798401],\n",
              " [0.0018651754362508655, 0.04318767786026001],\n",
              " [9.880043983459473, 0.1665683537721634],\n",
              " [1.1988849639892578, 0.13813498616218567],\n",
              " [0.018566885963082314, 0.13626036047935486],\n",
              " [9.72256088256836, 0.1171860471367836],\n",
              " [1.2742373943328857, 0.12273101508617401],\n",
              " [0.008656986057758331, 0.09304292500019073],\n",
              " [14.022122383117676, 1.5666983127593994],\n",
              " [1.5229620933532715, 0.15143118798732758],\n",
              " [1.5198121070861816, 1.2328065633773804],\n",
              " [11.444098472595215, 0.20417118072509766],\n",
              " [1.6720514297485352, 0.40888962149620056],\n",
              " [0.027365468442440033, 0.165425106883049],\n",
              " [12.569160461425781, 0.27560925483703613],\n",
              " [11.697490692138672, 0.32013681530952454],\n",
              " [0.02352888323366642, 0.1533912718296051],\n",
              " [276.831298828125, 2.199028253555298],\n",
              " [1810.593505859375, 5.564717769622803],\n",
              " [20.047300338745117, 4.477421283721924],\n",
              " [3.509256362915039, 0.13045841455459595],\n",
              " [0.02732621319591999, 0.15602844953536987],\n",
              " [0.033462099730968475, 0.1829264909029007],\n",
              " [71.42269134521484, 0.13983449339866638],\n",
              " [113.66956329345703, 0.43376410007476807],\n",
              " [0.018651088699698448, 0.13656899333000183],\n",
              " [1.2766269445419312, 0.13080459833145142],\n",
              " [0.034523844718933105, 0.18558116257190704],\n",
              " [0.01837162673473358, 0.13554197549819946],\n",
              " [1.3609254360198975, 0.15072913467884064],\n",
              " [2.742279291152954, 0.12614066898822784],\n",
              " [0.0003560284967534244, 0.018868718296289444],\n",
              " [0.15861208736896515, 0.1319083273410797],\n",
              " [0.02239665947854519, 0.14877517521381378],\n",
              " [0.0011865539709106088, 0.034446392208337784],\n",
              " [0.16668392717838287, 0.13892023265361786],\n",
              " [0.013413460925221443, 0.048486754298210144],\n",
              " [0.0006594410515390337, 0.025679584592580795],\n",
              " [0.4367882013320923, 0.184648796916008],\n",
              " [0.018266068771481514, 0.13441601395606995],\n",
              " [0.00248651672154665, 0.049864985048770905],\n",
              " [0.478104829788208, 0.14074793457984924],\n",
              " [0.0175797026604414, 0.06839028000831604],\n",
              " [0.0005529909394681454, 0.02351575903594494],\n",
              " [0.11282704770565033, 0.13941337168216705],\n",
              " [0.0880294069647789, 0.13588495552539825],\n",
              " [0.015949832275509834, 0.1262926459312439],\n",
              " [0.08671426773071289, 0.13681647181510925],\n",
              " [0.06489070504903793, 0.06581295281648636],\n",
              " [0.0014517651870846748, 0.03810203820466995],\n",
              " [9.77359390258789, 0.3783944845199585],\n",
              " [1.1583938598632812, 0.1336248815059662],\n",
              " [0.018752848729491234, 0.13694104552268982],\n",
              " [9.079408645629883, 0.11605896055698395],\n",
              " [1.1410423517227173, 0.10015671700239182],\n",
              " [0.009108870290219784, 0.09544040262699127],\n",
              " [14.241887092590332, 1.6481865644454956],\n",
              " [2.73067569732666, 1.095374345779419],\n",
              " [1.1923596858978271, 1.0919522047042847],\n",
              " [11.511883735656738, 0.17052774131298065],\n",
              " [1.5555368661880493, 0.22107015550136566],\n",
              " [0.13148626685142517, 0.3626103401184082]]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_p = pd.DataFrame(parameter_list,columns = [\"Parameters\"])\n",
        "df_p.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pbQbLQ2TsXDZ",
        "outputId": "dc2231db-4731-431a-8ea7-d11cef89c460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Parameters\n",
              "0  Hidden Layes: 1 Number of epochs: 10 learning ...\n",
              "1  Hidden Layes: 1 Number of epochs: 10 learning ...\n",
              "2  Hidden Layes: 1 Number of epochs: 10 learning ...\n",
              "3  Hidden Layes: 1 Number of epochs: 10 learning ...\n",
              "4  Hidden Layes: 1 Number of epochs: 10 learning ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e21fc257-e95d-45ed-8327-5d9780204ba0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Parameters</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hidden Layes: 1 Number of epochs: 10 learning ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hidden Layes: 1 Number of epochs: 10 learning ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hidden Layes: 1 Number of epochs: 10 learning ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hidden Layes: 1 Number of epochs: 10 learning ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hidden Layes: 1 Number of epochs: 10 learning ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e21fc257-e95d-45ed-8327-5d9780204ba0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e21fc257-e95d-45ed-8327-5d9780204ba0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e21fc257-e95d-45ed-8327-5d9780204ba0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_r = pd.DataFrame(result_list,columns = [\"rmse\",\"v_rmse\"])\n",
        "df_r.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8x1DcKL4sj2b",
        "outputId": "e135d254-4fc5-48bb-8cbf-aadde5c6cadf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         rmse    v_rmse\n",
              "0   59.074699  0.472660\n",
              "1    3.559027  0.142229\n",
              "2    0.276554  0.525884\n",
              "3   61.674992  0.406473\n",
              "4  233.149002  1.377548"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-96b2a298-122a-48de-9355-d487b6240f09\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rmse</th>\n",
              "      <th>v_rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>59.074699</td>\n",
              "      <td>0.472660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.559027</td>\n",
              "      <td>0.142229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.276554</td>\n",
              "      <td>0.525884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>61.674992</td>\n",
              "      <td>0.406473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>233.149002</td>\n",
              "      <td>1.377548</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-96b2a298-122a-48de-9355-d487b6240f09')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-96b2a298-122a-48de-9355-d487b6240f09 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-96b2a298-122a-48de-9355-d487b6240f09');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df_p, df_r], axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "SkQQIzW2ssUw",
        "outputId": "b5a20ae9-b3e9-41f9-adc7-4fec7d55859e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                          Parameters        rmse    v_rmse\n",
              "0  Hidden Layes: 1 Number of epochs: 10 learning ...   59.074699  0.472660\n",
              "1  Hidden Layes: 1 Number of epochs: 10 learning ...    3.559027  0.142229\n",
              "2  Hidden Layes: 1 Number of epochs: 10 learning ...    0.276554  0.525884\n",
              "3  Hidden Layes: 1 Number of epochs: 10 learning ...   61.674992  0.406473\n",
              "4  Hidden Layes: 1 Number of epochs: 10 learning ...  233.149002  1.377548"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4443001-4cf3-418e-bdae-3d4b5e5d335c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Parameters</th>\n",
              "      <th>rmse</th>\n",
              "      <th>v_rmse</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hidden Layes: 1 Number of epochs: 10 learning ...</td>\n",
              "      <td>59.074699</td>\n",
              "      <td>0.472660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Hidden Layes: 1 Number of epochs: 10 learning ...</td>\n",
              "      <td>3.559027</td>\n",
              "      <td>0.142229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hidden Layes: 1 Number of epochs: 10 learning ...</td>\n",
              "      <td>0.276554</td>\n",
              "      <td>0.525884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hidden Layes: 1 Number of epochs: 10 learning ...</td>\n",
              "      <td>61.674992</td>\n",
              "      <td>0.406473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hidden Layes: 1 Number of epochs: 10 learning ...</td>\n",
              "      <td>233.149002</td>\n",
              "      <td>1.377548</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4443001-4cf3-418e-bdae-3d4b5e5d335c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d4443001-4cf3-418e-bdae-3d4b5e5d335c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d4443001-4cf3-418e-bdae-3d4b5e5d335c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['rmse'].min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-rsMqSQsuYg",
        "outputId": "d2709d03-996d-49dc-e57c-f9a7a3c7986c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0003560284967534244"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df[df['rmse'] == df['rmse'].min()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AcQW4blFszJp",
        "outputId": "467b3204-11f0-417b-a00a-cbbc21e6e487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                            Parameters      rmse    v_rmse\n",
            "545  hidden layers: 3 Number of epochs: 40 learning...  0.000356  0.018869\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kOFRix_1s6wF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Parameters'].iloc[545]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4u2K7k643n6A",
        "outputId": "93f179c6-bf85-438d-9e9a-6649943b09b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hidden layers: 3 Number of epochs: 40 learning rate: 0.1 Activation Function: relu Regularizer: None'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The most optimal paramenters are as follows\n",
        "hidden layers: 3 Number of epochs: 40 learning rate: 0.1 Activation Function: relu Regularizer: None\n",
        "Creating a model to visualize the training and validation loss of the above decribed parameters against the epoches."
      ],
      "metadata": {
        "id": "WjLzsQKb7b0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = tf.keras.Sequential()\n",
        "model3.add(tf.keras.layers.InputLayer(input_shape=14, name='inputLayer'))\n",
        "model3.add(tf.keras.layers.Dense(128,activation='relu', name='hiddenLayer-1'))\n",
        "model3.add(tf.keras.layers.Dense(64,activation='relu', name='hiddenLayer-2'))\n",
        "model3.add(tf.keras.layers.Dense(32,activation ='relu', name='hiddenLayer-3'))\n",
        "model3.add(tf.keras.layers.Dense(1,name='outputLayer'))\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
        "model3.compile(loss = \"mse\", optimizer = opt, metrics = [tf.keras.metrics.RootMeanSquaredError()])\n",
        "history = model3.fit(x_train,y_train,epochs=40,validation_split=0.15)\n",
        "#result_list.append(model3.evaluate(x_test, y_test))\n",
        "print('MODEL EVALUATION: ', model3.evaluate(x_test, y_test))\n",
        "\n",
        "#print the models    \n",
        "sns.set_style(\"darkgrid\")\n",
        "#get the details form the history object\n",
        "acc = history.history['root_mean_squared_error']\n",
        "val_acc = history.history['val_root_mean_squared_error']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.figure()\n",
        "#Train and validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-imxoi797PXX",
        "outputId": "d64b3970-d08b-4cc8-d565-477c861af8e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "6/6 [==============================] - 2s 65ms/step - loss: 457.1295 - root_mean_squared_error: 21.3806 - val_loss: 0.1297 - val_root_mean_squared_error: 0.3601\n",
            "Epoch 2/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0659 - root_mean_squared_error: 0.2567 - val_loss: 0.0512 - val_root_mean_squared_error: 0.2263\n",
            "Epoch 3/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0337 - root_mean_squared_error: 0.1836 - val_loss: 0.0357 - val_root_mean_squared_error: 0.1890\n",
            "Epoch 4/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0313 - root_mean_squared_error: 0.1770 - val_loss: 0.0156 - val_root_mean_squared_error: 0.1248\n",
            "Epoch 5/40\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0233 - root_mean_squared_error: 0.1526 - val_loss: 0.0233 - val_root_mean_squared_error: 0.1527\n",
            "Epoch 6/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0219 - root_mean_squared_error: 0.1480 - val_loss: 0.0140 - val_root_mean_squared_error: 0.1185\n",
            "Epoch 7/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0138 - root_mean_squared_error: 0.1175 - val_loss: 0.0105 - val_root_mean_squared_error: 0.1025\n",
            "Epoch 8/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0116 - root_mean_squared_error: 0.1075 - val_loss: 0.0071 - val_root_mean_squared_error: 0.0844\n",
            "Epoch 9/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0139 - root_mean_squared_error: 0.1180 - val_loss: 0.0093 - val_root_mean_squared_error: 0.0966\n",
            "Epoch 10/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0096 - root_mean_squared_error: 0.0981 - val_loss: 0.0055 - val_root_mean_squared_error: 0.0743\n",
            "Epoch 11/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0095 - root_mean_squared_error: 0.0976 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0734\n",
            "Epoch 12/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0093 - root_mean_squared_error: 0.0966 - val_loss: 0.0070 - val_root_mean_squared_error: 0.0838\n",
            "Epoch 13/40\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0093 - root_mean_squared_error: 0.0965 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0676\n",
            "Epoch 14/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0075 - root_mean_squared_error: 0.0866 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0704\n",
            "Epoch 15/40\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0078 - root_mean_squared_error: 0.0883 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0635\n",
            "Epoch 16/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0058 - root_mean_squared_error: 0.0762 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0603\n",
            "Epoch 17/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0063 - root_mean_squared_error: 0.0796 - val_loss: 0.0046 - val_root_mean_squared_error: 0.0678\n",
            "Epoch 18/40\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0063 - root_mean_squared_error: 0.0796 - val_loss: 0.0089 - val_root_mean_squared_error: 0.0943\n",
            "Epoch 19/40\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0057 - root_mean_squared_error: 0.0753 - val_loss: 0.0054 - val_root_mean_squared_error: 0.0735\n",
            "Epoch 20/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0056 - root_mean_squared_error: 0.0748 - val_loss: 0.0044 - val_root_mean_squared_error: 0.0661\n",
            "Epoch 21/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0044 - root_mean_squared_error: 0.0660 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0586\n",
            "Epoch 22/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0040 - root_mean_squared_error: 0.0635 - val_loss: 0.0034 - val_root_mean_squared_error: 0.0581\n",
            "Epoch 23/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0032 - root_mean_squared_error: 0.0564 - val_loss: 0.0029 - val_root_mean_squared_error: 0.0537\n",
            "Epoch 24/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0033 - root_mean_squared_error: 0.0577 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0431\n",
            "Epoch 25/40\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0042 - root_mean_squared_error: 0.0645 - val_loss: 0.0024 - val_root_mean_squared_error: 0.0494\n",
            "Epoch 26/40\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0032 - root_mean_squared_error: 0.0565 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0409\n",
            "Epoch 27/40\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0025 - root_mean_squared_error: 0.0501 - val_loss: 0.0020 - val_root_mean_squared_error: 0.0445\n",
            "Epoch 28/40\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0030 - root_mean_squared_error: 0.0552 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0409\n",
            "Epoch 29/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0026 - root_mean_squared_error: 0.0513 - val_loss: 0.0036 - val_root_mean_squared_error: 0.0602\n",
            "Epoch 30/40\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0033 - root_mean_squared_error: 0.0572 - val_loss: 0.0027 - val_root_mean_squared_error: 0.0521\n",
            "Epoch 31/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0024 - root_mean_squared_error: 0.0495 - val_loss: 9.8199e-04 - val_root_mean_squared_error: 0.0313\n",
            "Epoch 32/40\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 0.0017 - root_mean_squared_error: 0.0417 - val_loss: 0.0012 - val_root_mean_squared_error: 0.0340\n",
            "Epoch 33/40\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0016 - root_mean_squared_error: 0.0398 - val_loss: 0.0012 - val_root_mean_squared_error: 0.0352\n",
            "Epoch 34/40\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0017 - root_mean_squared_error: 0.0408 - val_loss: 0.0012 - val_root_mean_squared_error: 0.0343\n",
            "Epoch 35/40\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0015 - root_mean_squared_error: 0.0381 - val_loss: 5.3809e-04 - val_root_mean_squared_error: 0.0232\n",
            "Epoch 36/40\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 0.0018 - root_mean_squared_error: 0.0420 - val_loss: 8.0267e-04 - val_root_mean_squared_error: 0.0283\n",
            "Epoch 37/40\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0020 - root_mean_squared_error: 0.0448 - val_loss: 7.1219e-04 - val_root_mean_squared_error: 0.0267\n",
            "Epoch 38/40\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0013 - root_mean_squared_error: 0.0365 - val_loss: 7.1212e-04 - val_root_mean_squared_error: 0.0267\n",
            "Epoch 39/40\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0015 - root_mean_squared_error: 0.0386 - val_loss: 0.0053 - val_root_mean_squared_error: 0.0729\n",
            "Epoch 40/40\n",
            "6/6 [==============================] - 0s 5ms/step - loss: 0.0025 - root_mean_squared_error: 0.0496 - val_loss: 0.0014 - val_root_mean_squared_error: 0.0368\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 9.6048e-04 - root_mean_squared_error: 0.0310\n",
            "MODEL EVALUATION:  [0.0009604794322513044, 0.030991602689027786]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hence the most optimal hyper parameters are as follows\n",
        "\n",
        "#### Hidden layers: 3 Number of epochs: 40 learning rate: 0.1 Activation Function: relu Regularizer: None\n",
        "\n",
        "##### Above we have also plotted the graphy regarding the training and validation loss for the most optimal hyperparameters"
      ],
      "metadata": {
        "id": "P6U_7AAn-XE4"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WjG74aak-X1y"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}